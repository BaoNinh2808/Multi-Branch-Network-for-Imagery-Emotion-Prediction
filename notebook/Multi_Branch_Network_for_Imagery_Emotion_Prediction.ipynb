{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "R5R5aurA4GCt",
        "mOtPSs-j5Lx7",
        "WRgaNN-k43K0",
        "Na07bDEI6tXj",
        "B3sEJzsC46AU",
        "64NB2FNbr7Gy",
        "rVWB5vvjsDrG"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center> Multi-Branch Network for Imagery Emotion Prediction </center></h1>\n",
        "<center> Using various source information, including faces, bodies, and scene contexts to predict both discrete and continuous emotions in an image</center>"
      ],
      "metadata": {
        "id": "qmEwEwwKI0KH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Connect to Google Drive:"
      ],
      "metadata": {
        "id": "KjwY_LzQMQah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linking Google drive to use preprocessed data\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "#/content/drive/My Drive//"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0PDx6Y2MVYr",
        "outputId": "473a88f5-a2dc-433c-c68c-b70b3000add7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. General Import:"
      ],
      "metadata": {
        "id": "hhmiYqp1MZDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import scipy.io\n",
        "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HazWZ1jlMeJS",
        "outputId": "fe0de169-3d66-4e3d-da04-d6f1d527196e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define global variables\n",
        "\n",
        "isSwinT = False   #variable for checking if using SwinT backbone\n",
        "isBFER = False     #variable for checking if using B-FER backbone\n",
        "num_context_features = 0  #store number of features that Context Feature Extraction branch extract\n",
        "num_body_features = 0     #store number of features that Body Feature Extraction branch extract\n",
        "num_face_features = 0     #store number of features that Face Feature Extraction branch extract"
      ],
      "metadata": {
        "id": "tbm3DxyfgoIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#III. MODEL"
      ],
      "metadata": {
        "id": "XIoL9Yflagqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The behind image shows the architecture of our proposed **Multi-Branch Network (MBN)**. The network is divided into two main parts. The first part extracts features from the body, the face, and context of the image, referred to as **body image**, **face image**, and **context image**. It consists of three branches to exploit emotions from subjects and background. We remark that the face region is extracted from the body image. The second part is a fusion network combining the features extracted from the three branches to predict the discrete emotions and VAD values of each person in the image."
      ],
      "metadata": {
        "id": "Z9bSb7yBaokj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://raw.githubusercontent.com/BaoNinh2808/Server-Client/main/Proposed%20Method.png\" width = \"90%\">"
      ],
      "metadata": {
        "id": "g0k7pc6PbsVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our proposed network consists of three feature extraction branches, utilizing different deep learning models trained on suitable datasets to efficiently make predictions on human and scene images.\n",
        "\n",
        "You can see the picture to know about what backbone you can choose.\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/BaoNinh2808/Server-Client/main/model_options.png\" width = \"90%\">\n",
        "\n"
      ],
      "metadata": {
        "id": "GQvFS1bPcDlq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's Choose Backbone for Each Branch:** For each branch just choose one.\n",
        "\n",
        "If you run automatically all cell, we will assign backbone for you. The default is:  \n",
        "*   Context Branch: Resnet-50(Places365)\n",
        "*   Body Branch:    SwinT(Retrain on Emotic)\n",
        "*   Face Branch:    B-FER\n",
        "\n",
        "The combination of these backbones also give the best result in all combinations."
      ],
      "metadata": {
        "id": "IjgQu5Da3z3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 . Body Branch:\n"
      ],
      "metadata": {
        "id": "R5R5aurA4GCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. Resnet-18 (ImageNet weight):"
      ],
      "metadata": {
        "id": "mOtPSs-j5Lx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_body = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "print (summary(model_body, (3,224,224), device=\"cpu\"))"
      ],
      "metadata": {
        "id": "nuq52OK_5DYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b103eb45-2d1c-45e8-98f2-40c4b654eaa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 141MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 107.96\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_body_features = list(model_body.children())[-1].in_features"
      ],
      "metadata": {
        "id": "flgg-Wd_wlnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. Resnet-50 (ImageNet weight)"
      ],
      "metadata": {
        "id": "2jUvcq7a5Wqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_body = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "print (summary(model_body, (3,224,224), device=\"cpu\"))"
      ],
      "metadata": {
        "id": "qF3Rga2u5vxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc46387-f196-4f8e-f2d7-555bc852cbd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 144MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 25,557,032\n",
            "Trainable params: 25,557,032\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 286.56\n",
            "Params size (MB): 97.49\n",
            "Estimated Total Size (MB): 384.62\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_body_features = list(model_body.children())[-1].in_features"
      ],
      "metadata": {
        "id": "6xQgAuHewnMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. Resnet-50 (Emotic weight)"
      ],
      "metadata": {
        "id": "Vmg6YIovjGem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_body = torch.load('/content/drive/MyDrive/VA-prediction/models/body_train_lr001_b24_crossEtropy/model1.pth')\n",
        "print (summary(model_body, (3,128,128), device=\"cpu\"))"
      ],
      "metadata": {
        "id": "Hn2SiP8_jO4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "800a973a-f689-4451-c7aa-45cc10ddfba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
            "              ReLU-3           [-1, 64, 64, 64]               0\n",
            "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
            "            Conv2d-5           [-1, 64, 32, 32]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "              ReLU-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "             ReLU-10           [-1, 64, 32, 32]               0\n",
            "           Conv2d-11          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 32, 32]             512\n",
            "           Conv2d-13          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 32, 32]             512\n",
            "             ReLU-15          [-1, 256, 32, 32]               0\n",
            "       Bottleneck-16          [-1, 256, 32, 32]               0\n",
            "           Conv2d-17           [-1, 64, 32, 32]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 32, 32]             128\n",
            "             ReLU-19           [-1, 64, 32, 32]               0\n",
            "           Conv2d-20           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 32, 32]             128\n",
            "             ReLU-22           [-1, 64, 32, 32]               0\n",
            "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
            "             ReLU-25          [-1, 256, 32, 32]               0\n",
            "       Bottleneck-26          [-1, 256, 32, 32]               0\n",
            "           Conv2d-27           [-1, 64, 32, 32]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 32, 32]             128\n",
            "             ReLU-29           [-1, 64, 32, 32]               0\n",
            "           Conv2d-30           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 32, 32]             128\n",
            "             ReLU-32           [-1, 64, 32, 32]               0\n",
            "           Conv2d-33          [-1, 256, 32, 32]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 32, 32]             512\n",
            "             ReLU-35          [-1, 256, 32, 32]               0\n",
            "       Bottleneck-36          [-1, 256, 32, 32]               0\n",
            "           Conv2d-37          [-1, 128, 32, 32]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
            "             ReLU-39          [-1, 128, 32, 32]               0\n",
            "           Conv2d-40          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 16, 16]             256\n",
            "             ReLU-42          [-1, 128, 16, 16]               0\n",
            "           Conv2d-43          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 16, 16]           1,024\n",
            "           Conv2d-45          [-1, 512, 16, 16]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-47          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
            "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
            "             ReLU-51          [-1, 128, 16, 16]               0\n",
            "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
            "             ReLU-54          [-1, 128, 16, 16]               0\n",
            "           Conv2d-55          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-57          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-58          [-1, 512, 16, 16]               0\n",
            "           Conv2d-59          [-1, 128, 16, 16]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 16, 16]             256\n",
            "             ReLU-61          [-1, 128, 16, 16]               0\n",
            "           Conv2d-62          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 16, 16]             256\n",
            "             ReLU-64          [-1, 128, 16, 16]               0\n",
            "           Conv2d-65          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-67          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-68          [-1, 512, 16, 16]               0\n",
            "           Conv2d-69          [-1, 128, 16, 16]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 16, 16]             256\n",
            "             ReLU-71          [-1, 128, 16, 16]               0\n",
            "           Conv2d-72          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 16, 16]             256\n",
            "             ReLU-74          [-1, 128, 16, 16]               0\n",
            "           Conv2d-75          [-1, 512, 16, 16]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-77          [-1, 512, 16, 16]               0\n",
            "       Bottleneck-78          [-1, 512, 16, 16]               0\n",
            "           Conv2d-79          [-1, 256, 16, 16]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 16, 16]             512\n",
            "             ReLU-81          [-1, 256, 16, 16]               0\n",
            "           Conv2d-82            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
            "             ReLU-84            [-1, 256, 8, 8]               0\n",
            "           Conv2d-85           [-1, 1024, 8, 8]         262,144\n",
            "      BatchNorm2d-86           [-1, 1024, 8, 8]           2,048\n",
            "           Conv2d-87           [-1, 1024, 8, 8]         524,288\n",
            "      BatchNorm2d-88           [-1, 1024, 8, 8]           2,048\n",
            "             ReLU-89           [-1, 1024, 8, 8]               0\n",
            "       Bottleneck-90           [-1, 1024, 8, 8]               0\n",
            "           Conv2d-91            [-1, 256, 8, 8]         262,144\n",
            "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
            "             ReLU-93            [-1, 256, 8, 8]               0\n",
            "           Conv2d-94            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
            "             ReLU-96            [-1, 256, 8, 8]               0\n",
            "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
            "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
            "             ReLU-99           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-100           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-101            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-102            [-1, 256, 8, 8]             512\n",
            "            ReLU-103            [-1, 256, 8, 8]               0\n",
            "          Conv2d-104            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-105            [-1, 256, 8, 8]             512\n",
            "            ReLU-106            [-1, 256, 8, 8]               0\n",
            "          Conv2d-107           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-108           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-109           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-110           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-111            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-112            [-1, 256, 8, 8]             512\n",
            "            ReLU-113            [-1, 256, 8, 8]               0\n",
            "          Conv2d-114            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-115            [-1, 256, 8, 8]             512\n",
            "            ReLU-116            [-1, 256, 8, 8]               0\n",
            "          Conv2d-117           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-118           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-119           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-120           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-121            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-122            [-1, 256, 8, 8]             512\n",
            "            ReLU-123            [-1, 256, 8, 8]               0\n",
            "          Conv2d-124            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-125            [-1, 256, 8, 8]             512\n",
            "            ReLU-126            [-1, 256, 8, 8]               0\n",
            "          Conv2d-127           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-128           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-129           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-130           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-131            [-1, 256, 8, 8]         262,144\n",
            "     BatchNorm2d-132            [-1, 256, 8, 8]             512\n",
            "            ReLU-133            [-1, 256, 8, 8]               0\n",
            "          Conv2d-134            [-1, 256, 8, 8]         589,824\n",
            "     BatchNorm2d-135            [-1, 256, 8, 8]             512\n",
            "            ReLU-136            [-1, 256, 8, 8]               0\n",
            "          Conv2d-137           [-1, 1024, 8, 8]         262,144\n",
            "     BatchNorm2d-138           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-139           [-1, 1024, 8, 8]               0\n",
            "      Bottleneck-140           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-141            [-1, 512, 8, 8]         524,288\n",
            "     BatchNorm2d-142            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-143            [-1, 512, 8, 8]               0\n",
            "          Conv2d-144            [-1, 512, 4, 4]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-146            [-1, 512, 4, 4]               0\n",
            "          Conv2d-147           [-1, 2048, 4, 4]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 4, 4]           4,096\n",
            "          Conv2d-149           [-1, 2048, 4, 4]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-151           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-152           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-153            [-1, 512, 4, 4]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-155            [-1, 512, 4, 4]               0\n",
            "          Conv2d-156            [-1, 512, 4, 4]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-158            [-1, 512, 4, 4]               0\n",
            "          Conv2d-159           [-1, 2048, 4, 4]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-161           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-162           [-1, 2048, 4, 4]               0\n",
            "          Conv2d-163            [-1, 512, 4, 4]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-165            [-1, 512, 4, 4]               0\n",
            "          Conv2d-166            [-1, 512, 4, 4]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 4, 4]           1,024\n",
            "            ReLU-168            [-1, 512, 4, 4]               0\n",
            "          Conv2d-169           [-1, 2048, 4, 4]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 4, 4]           4,096\n",
            "            ReLU-171           [-1, 2048, 4, 4]               0\n",
            "      Bottleneck-172           [-1, 2048, 4, 4]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                    [-1, 6]          12,294\n",
            "================================================================\n",
            "Total params: 23,520,326\n",
            "Trainable params: 12,294\n",
            "Non-trainable params: 23,508,032\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 93.58\n",
            "Params size (MB): 89.72\n",
            "Estimated Total Size (MB): 183.49\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_body_features = list(model_body.children())[-1].in_features"
      ],
      "metadata": {
        "id": "65pnN9b2wn98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d. SwinT (ImageNet weight)"
      ],
      "metadata": {
        "id": "fmwzerRK5bDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_body = models.swin_t(weights = 'DEFAULT')\n",
        "print (summary(model_body, (3,128,128), device=\"cpu\"))\n",
        "isSwinT = True"
      ],
      "metadata": {
        "id": "ZP5ilA_E5769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e48de14-3889-4942-e3b9-475808baa84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/swin_t-704ceda3.pth\" to /root/.cache/torch/hub/checkpoints/swin_t-704ceda3.pth\n",
            "100%|██████████| 108M/108M [00:00<00:00, 135MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 32, 32]           4,704\n",
            "           Permute-2           [-1, 32, 32, 96]               0\n",
            "         LayerNorm-3           [-1, 32, 32, 96]             192\n",
            "         LayerNorm-4           [-1, 32, 32, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 32, 32, 96]               0\n",
            "   StochasticDepth-6           [-1, 32, 32, 96]               0\n",
            "         LayerNorm-7           [-1, 32, 32, 96]             192\n",
            "            Linear-8          [-1, 32, 32, 384]          37,248\n",
            "              GELU-9          [-1, 32, 32, 384]               0\n",
            "          Dropout-10          [-1, 32, 32, 384]               0\n",
            "           Linear-11           [-1, 32, 32, 96]          36,960\n",
            "          Dropout-12           [-1, 32, 32, 96]               0\n",
            "  StochasticDepth-13           [-1, 32, 32, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 32, 32, 96]               0\n",
            "        LayerNorm-15           [-1, 32, 32, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 32, 32, 96]               0\n",
            "  StochasticDepth-17           [-1, 32, 32, 96]               0\n",
            "        LayerNorm-18           [-1, 32, 32, 96]             192\n",
            "           Linear-19          [-1, 32, 32, 384]          37,248\n",
            "             GELU-20          [-1, 32, 32, 384]               0\n",
            "          Dropout-21          [-1, 32, 32, 384]               0\n",
            "           Linear-22           [-1, 32, 32, 96]          36,960\n",
            "          Dropout-23           [-1, 32, 32, 96]               0\n",
            "  StochasticDepth-24           [-1, 32, 32, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 32, 32, 96]               0\n",
            "        LayerNorm-26          [-1, 16, 16, 384]             768\n",
            "           Linear-27          [-1, 16, 16, 192]          73,728\n",
            "     PatchMerging-28          [-1, 16, 16, 192]               0\n",
            "        LayerNorm-29          [-1, 16, 16, 192]             384\n",
            "ShiftedWindowAttention-30          [-1, 16, 16, 192]               0\n",
            "  StochasticDepth-31          [-1, 16, 16, 192]               0\n",
            "        LayerNorm-32          [-1, 16, 16, 192]             384\n",
            "           Linear-33          [-1, 16, 16, 768]         148,224\n",
            "             GELU-34          [-1, 16, 16, 768]               0\n",
            "          Dropout-35          [-1, 16, 16, 768]               0\n",
            "           Linear-36          [-1, 16, 16, 192]         147,648\n",
            "          Dropout-37          [-1, 16, 16, 192]               0\n",
            "  StochasticDepth-38          [-1, 16, 16, 192]               0\n",
            "SwinTransformerBlock-39          [-1, 16, 16, 192]               0\n",
            "        LayerNorm-40          [-1, 16, 16, 192]             384\n",
            "ShiftedWindowAttention-41          [-1, 16, 16, 192]               0\n",
            "  StochasticDepth-42          [-1, 16, 16, 192]               0\n",
            "        LayerNorm-43          [-1, 16, 16, 192]             384\n",
            "           Linear-44          [-1, 16, 16, 768]         148,224\n",
            "             GELU-45          [-1, 16, 16, 768]               0\n",
            "          Dropout-46          [-1, 16, 16, 768]               0\n",
            "           Linear-47          [-1, 16, 16, 192]         147,648\n",
            "          Dropout-48          [-1, 16, 16, 192]               0\n",
            "  StochasticDepth-49          [-1, 16, 16, 192]               0\n",
            "SwinTransformerBlock-50          [-1, 16, 16, 192]               0\n",
            "        LayerNorm-51            [-1, 8, 8, 768]           1,536\n",
            "           Linear-52            [-1, 8, 8, 384]         294,912\n",
            "     PatchMerging-53            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-54            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-56            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-57            [-1, 8, 8, 384]             768\n",
            "           Linear-58           [-1, 8, 8, 1536]         591,360\n",
            "             GELU-59           [-1, 8, 8, 1536]               0\n",
            "          Dropout-60           [-1, 8, 8, 1536]               0\n",
            "           Linear-61            [-1, 8, 8, 384]         590,208\n",
            "          Dropout-62            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-63            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-65            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-67            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-68            [-1, 8, 8, 384]             768\n",
            "           Linear-69           [-1, 8, 8, 1536]         591,360\n",
            "             GELU-70           [-1, 8, 8, 1536]               0\n",
            "          Dropout-71           [-1, 8, 8, 1536]               0\n",
            "           Linear-72            [-1, 8, 8, 384]         590,208\n",
            "          Dropout-73            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-74            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-76            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-78            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-79            [-1, 8, 8, 384]             768\n",
            "           Linear-80           [-1, 8, 8, 1536]         591,360\n",
            "             GELU-81           [-1, 8, 8, 1536]               0\n",
            "          Dropout-82           [-1, 8, 8, 1536]               0\n",
            "           Linear-83            [-1, 8, 8, 384]         590,208\n",
            "          Dropout-84            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-85            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-87            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-89            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-90            [-1, 8, 8, 384]             768\n",
            "           Linear-91           [-1, 8, 8, 1536]         591,360\n",
            "             GELU-92           [-1, 8, 8, 1536]               0\n",
            "          Dropout-93           [-1, 8, 8, 1536]               0\n",
            "           Linear-94            [-1, 8, 8, 384]         590,208\n",
            "          Dropout-95            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-96            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-98            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 8, 8, 384]               0\n",
            " StochasticDepth-100            [-1, 8, 8, 384]               0\n",
            "       LayerNorm-101            [-1, 8, 8, 384]             768\n",
            "          Linear-102           [-1, 8, 8, 1536]         591,360\n",
            "            GELU-103           [-1, 8, 8, 1536]               0\n",
            "         Dropout-104           [-1, 8, 8, 1536]               0\n",
            "          Linear-105            [-1, 8, 8, 384]         590,208\n",
            "         Dropout-106            [-1, 8, 8, 384]               0\n",
            " StochasticDepth-107            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 8, 8, 384]               0\n",
            "       LayerNorm-109            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 8, 8, 384]               0\n",
            " StochasticDepth-111            [-1, 8, 8, 384]               0\n",
            "       LayerNorm-112            [-1, 8, 8, 384]             768\n",
            "          Linear-113           [-1, 8, 8, 1536]         591,360\n",
            "            GELU-114           [-1, 8, 8, 1536]               0\n",
            "         Dropout-115           [-1, 8, 8, 1536]               0\n",
            "          Linear-116            [-1, 8, 8, 384]         590,208\n",
            "         Dropout-117            [-1, 8, 8, 384]               0\n",
            " StochasticDepth-118            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 8, 8, 384]               0\n",
            "       LayerNorm-120           [-1, 4, 4, 1536]           3,072\n",
            "          Linear-121            [-1, 4, 4, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 4, 4, 768]               0\n",
            "       LayerNorm-123            [-1, 4, 4, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 4, 4, 768]               0\n",
            " StochasticDepth-125            [-1, 4, 4, 768]               0\n",
            "       LayerNorm-126            [-1, 4, 4, 768]           1,536\n",
            "          Linear-127           [-1, 4, 4, 3072]       2,362,368\n",
            "            GELU-128           [-1, 4, 4, 3072]               0\n",
            "         Dropout-129           [-1, 4, 4, 3072]               0\n",
            "          Linear-130            [-1, 4, 4, 768]       2,360,064\n",
            "         Dropout-131            [-1, 4, 4, 768]               0\n",
            " StochasticDepth-132            [-1, 4, 4, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 4, 4, 768]               0\n",
            "       LayerNorm-134            [-1, 4, 4, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 4, 4, 768]               0\n",
            " StochasticDepth-136            [-1, 4, 4, 768]               0\n",
            "       LayerNorm-137            [-1, 4, 4, 768]           1,536\n",
            "          Linear-138           [-1, 4, 4, 3072]       2,362,368\n",
            "            GELU-139           [-1, 4, 4, 3072]               0\n",
            "         Dropout-140           [-1, 4, 4, 3072]               0\n",
            "          Linear-141            [-1, 4, 4, 768]       2,360,064\n",
            "         Dropout-142            [-1, 4, 4, 768]               0\n",
            " StochasticDepth-143            [-1, 4, 4, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 4, 4, 768]               0\n",
            "       LayerNorm-145            [-1, 4, 4, 768]           1,536\n",
            "         Permute-146            [-1, 768, 4, 4]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "          Linear-149                 [-1, 1000]         769,000\n",
            "================================================================\n",
            "Total params: 19,621,192\n",
            "Trainable params: 19,621,192\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 76.33\n",
            "Params size (MB): 74.85\n",
            "Estimated Total Size (MB): 151.37\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_body_features = list(model_body.children())[-1].in_features"
      ],
      "metadata": {
        "id": "pLh3fmb0wotQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### e. SwinT (Emotic weight)"
      ],
      "metadata": {
        "id": "XZHxYd1OjEmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_body = torch.load(\"/content/drive/MyDrive/VA-prediction/models/SwinT_EMOTIC.pth\", map_location=lambda storage, loc: storage)\n",
        "print (summary(model_body, (3,128,128), device=\"cpu\"))\n",
        "isSwinT = True"
      ],
      "metadata": {
        "id": "gFZfWxtIjfMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3464060d-4346-4b6e-b72e-9d09cab024b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 32, 32]           4,704\n",
            "           Permute-2           [-1, 32, 32, 96]               0\n",
            "         LayerNorm-3           [-1, 32, 32, 96]             192\n",
            "         LayerNorm-4           [-1, 32, 32, 96]             192\n",
            "ShiftedWindowAttention-5           [-1, 32, 32, 96]               0\n",
            "   StochasticDepth-6           [-1, 32, 32, 96]               0\n",
            "         LayerNorm-7           [-1, 32, 32, 96]             192\n",
            "            Linear-8          [-1, 32, 32, 384]          37,248\n",
            "              GELU-9          [-1, 32, 32, 384]               0\n",
            "          Dropout-10          [-1, 32, 32, 384]               0\n",
            "           Linear-11           [-1, 32, 32, 96]          36,960\n",
            "          Dropout-12           [-1, 32, 32, 96]               0\n",
            "  StochasticDepth-13           [-1, 32, 32, 96]               0\n",
            "SwinTransformerBlock-14           [-1, 32, 32, 96]               0\n",
            "        LayerNorm-15           [-1, 32, 32, 96]             192\n",
            "ShiftedWindowAttention-16           [-1, 32, 32, 96]               0\n",
            "  StochasticDepth-17           [-1, 32, 32, 96]               0\n",
            "        LayerNorm-18           [-1, 32, 32, 96]             192\n",
            "           Linear-19          [-1, 32, 32, 384]          37,248\n",
            "             GELU-20          [-1, 32, 32, 384]               0\n",
            "          Dropout-21          [-1, 32, 32, 384]               0\n",
            "           Linear-22           [-1, 32, 32, 96]          36,960\n",
            "          Dropout-23           [-1, 32, 32, 96]               0\n",
            "  StochasticDepth-24           [-1, 32, 32, 96]               0\n",
            "SwinTransformerBlock-25           [-1, 32, 32, 96]               0\n",
            "        LayerNorm-26          [-1, 16, 16, 384]             768\n",
            "           Linear-27          [-1, 16, 16, 192]          73,728\n",
            "     PatchMerging-28          [-1, 16, 16, 192]               0\n",
            "        LayerNorm-29          [-1, 16, 16, 192]             384\n",
            "ShiftedWindowAttention-30          [-1, 16, 16, 192]               0\n",
            "  StochasticDepth-31          [-1, 16, 16, 192]               0\n",
            "        LayerNorm-32          [-1, 16, 16, 192]             384\n",
            "           Linear-33          [-1, 16, 16, 768]         148,224\n",
            "             GELU-34          [-1, 16, 16, 768]               0\n",
            "          Dropout-35          [-1, 16, 16, 768]               0\n",
            "           Linear-36          [-1, 16, 16, 192]         147,648\n",
            "          Dropout-37          [-1, 16, 16, 192]               0\n",
            "  StochasticDepth-38          [-1, 16, 16, 192]               0\n",
            "SwinTransformerBlock-39          [-1, 16, 16, 192]               0\n",
            "        LayerNorm-40          [-1, 16, 16, 192]             384\n",
            "ShiftedWindowAttention-41          [-1, 16, 16, 192]               0\n",
            "  StochasticDepth-42          [-1, 16, 16, 192]               0\n",
            "        LayerNorm-43          [-1, 16, 16, 192]             384\n",
            "           Linear-44          [-1, 16, 16, 768]         148,224\n",
            "             GELU-45          [-1, 16, 16, 768]               0\n",
            "          Dropout-46          [-1, 16, 16, 768]               0\n",
            "           Linear-47          [-1, 16, 16, 192]         147,648\n",
            "          Dropout-48          [-1, 16, 16, 192]               0\n",
            "  StochasticDepth-49          [-1, 16, 16, 192]               0\n",
            "SwinTransformerBlock-50          [-1, 16, 16, 192]               0\n",
            "        LayerNorm-51            [-1, 8, 8, 768]           1,536\n",
            "           Linear-52            [-1, 8, 8, 384]         294,912\n",
            "     PatchMerging-53            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-54            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-55            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-56            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-57            [-1, 8, 8, 384]             768\n",
            "           Linear-58           [-1, 8, 8, 1536]         591,360\n",
            "             GELU-59           [-1, 8, 8, 1536]               0\n",
            "          Dropout-60           [-1, 8, 8, 1536]               0\n",
            "           Linear-61            [-1, 8, 8, 384]         590,208\n",
            "          Dropout-62            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-63            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-64            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-65            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-66            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-67            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-68            [-1, 8, 8, 384]             768\n",
            "           Linear-69           [-1, 8, 8, 1536]         591,360\n",
            "             GELU-70           [-1, 8, 8, 1536]               0\n",
            "          Dropout-71           [-1, 8, 8, 1536]               0\n",
            "           Linear-72            [-1, 8, 8, 384]         590,208\n",
            "          Dropout-73            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-74            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-75            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-76            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-77            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-78            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-79            [-1, 8, 8, 384]             768\n",
            "           Linear-80           [-1, 8, 8, 1536]         591,360\n",
            "             GELU-81           [-1, 8, 8, 1536]               0\n",
            "          Dropout-82           [-1, 8, 8, 1536]               0\n",
            "           Linear-83            [-1, 8, 8, 384]         590,208\n",
            "          Dropout-84            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-85            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-86            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-87            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-88            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-89            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-90            [-1, 8, 8, 384]             768\n",
            "           Linear-91           [-1, 8, 8, 1536]         591,360\n",
            "             GELU-92           [-1, 8, 8, 1536]               0\n",
            "          Dropout-93           [-1, 8, 8, 1536]               0\n",
            "           Linear-94            [-1, 8, 8, 384]         590,208\n",
            "          Dropout-95            [-1, 8, 8, 384]               0\n",
            "  StochasticDepth-96            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-97            [-1, 8, 8, 384]               0\n",
            "        LayerNorm-98            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-99            [-1, 8, 8, 384]               0\n",
            " StochasticDepth-100            [-1, 8, 8, 384]               0\n",
            "       LayerNorm-101            [-1, 8, 8, 384]             768\n",
            "          Linear-102           [-1, 8, 8, 1536]         591,360\n",
            "            GELU-103           [-1, 8, 8, 1536]               0\n",
            "         Dropout-104           [-1, 8, 8, 1536]               0\n",
            "          Linear-105            [-1, 8, 8, 384]         590,208\n",
            "         Dropout-106            [-1, 8, 8, 384]               0\n",
            " StochasticDepth-107            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-108            [-1, 8, 8, 384]               0\n",
            "       LayerNorm-109            [-1, 8, 8, 384]             768\n",
            "ShiftedWindowAttention-110            [-1, 8, 8, 384]               0\n",
            " StochasticDepth-111            [-1, 8, 8, 384]               0\n",
            "       LayerNorm-112            [-1, 8, 8, 384]             768\n",
            "          Linear-113           [-1, 8, 8, 1536]         591,360\n",
            "            GELU-114           [-1, 8, 8, 1536]               0\n",
            "         Dropout-115           [-1, 8, 8, 1536]               0\n",
            "          Linear-116            [-1, 8, 8, 384]         590,208\n",
            "         Dropout-117            [-1, 8, 8, 384]               0\n",
            " StochasticDepth-118            [-1, 8, 8, 384]               0\n",
            "SwinTransformerBlock-119            [-1, 8, 8, 384]               0\n",
            "       LayerNorm-120           [-1, 4, 4, 1536]           3,072\n",
            "          Linear-121            [-1, 4, 4, 768]       1,179,648\n",
            "    PatchMerging-122            [-1, 4, 4, 768]               0\n",
            "       LayerNorm-123            [-1, 4, 4, 768]           1,536\n",
            "ShiftedWindowAttention-124            [-1, 4, 4, 768]               0\n",
            " StochasticDepth-125            [-1, 4, 4, 768]               0\n",
            "       LayerNorm-126            [-1, 4, 4, 768]           1,536\n",
            "          Linear-127           [-1, 4, 4, 3072]       2,362,368\n",
            "            GELU-128           [-1, 4, 4, 3072]               0\n",
            "         Dropout-129           [-1, 4, 4, 3072]               0\n",
            "          Linear-130            [-1, 4, 4, 768]       2,360,064\n",
            "         Dropout-131            [-1, 4, 4, 768]               0\n",
            " StochasticDepth-132            [-1, 4, 4, 768]               0\n",
            "SwinTransformerBlock-133            [-1, 4, 4, 768]               0\n",
            "       LayerNorm-134            [-1, 4, 4, 768]           1,536\n",
            "ShiftedWindowAttention-135            [-1, 4, 4, 768]               0\n",
            " StochasticDepth-136            [-1, 4, 4, 768]               0\n",
            "       LayerNorm-137            [-1, 4, 4, 768]           1,536\n",
            "          Linear-138           [-1, 4, 4, 3072]       2,362,368\n",
            "            GELU-139           [-1, 4, 4, 3072]               0\n",
            "         Dropout-140           [-1, 4, 4, 3072]               0\n",
            "          Linear-141            [-1, 4, 4, 768]       2,360,064\n",
            "         Dropout-142            [-1, 4, 4, 768]               0\n",
            " StochasticDepth-143            [-1, 4, 4, 768]               0\n",
            "SwinTransformerBlock-144            [-1, 4, 4, 768]               0\n",
            "       LayerNorm-145            [-1, 4, 4, 768]           1,536\n",
            "         Permute-146            [-1, 768, 4, 4]               0\n",
            "AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n",
            "         Flatten-148                  [-1, 768]               0\n",
            "          Linear-149                    [-1, 6]           4,614\n",
            "================================================================\n",
            "Total params: 18,856,806\n",
            "Trainable params: 4,614\n",
            "Non-trainable params: 18,852,192\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 76.32\n",
            "Params size (MB): 71.93\n",
            "Estimated Total Size (MB): 148.44\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_body_features = list(model_body.children())[-1].in_features"
      ],
      "metadata": {
        "id": "oQyCQXxHwpS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 . Context Branch:"
      ],
      "metadata": {
        "id": "WRgaNN-k43K0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. Resnet-18 (Places365 weight)"
      ],
      "metadata": {
        "id": "Na07bDEI6tXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Resnet18 model trained on places dataset.\n",
        "store_path = \"./places\"\n",
        "if not os.path.exists(store_path):\n",
        "    os.mkdir(store_path)\n",
        "\n",
        "file_path = \"./places/resnet18_places365.pth.tar\"\n",
        "if not os.path.exists(file_path):\n",
        "    !wget http://places2.csail.mit.edu/models_places365/resnet18_places365.pth.tar -O ./places/resnet18_places365.pth.tar"
      ],
      "metadata": {
        "id": "uZuctwQp47OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81031c9-d2df-49c7-d3e3-2ce5bfde3ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-21 14:12:51--  http://places2.csail.mit.edu/models_places365/resnet18_places365.pth.tar\n",
            "Resolving places2.csail.mit.edu (places2.csail.mit.edu)... 128.52.132.120\n",
            "Connecting to places2.csail.mit.edu (places2.csail.mit.edu)|128.52.132.120|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45506139 (43M) [application/x-tar]\n",
            "Saving to: ‘./places/resnet18_places365.pth.tar’\n",
            "\n",
            "./places/resnet18_p 100%[===================>]  43.40M  55.6MB/s    in 0.8s    \n",
            "\n",
            "2023-11-21 14:12:52 (55.6 MB/s) - ‘./places/resnet18_places365.pth.tar’ saved [45506139/45506139]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the architecture to use\n",
        "arch = 'resnet18'\n",
        "model_weight = os.path.join('./places', 'resnet18_places365.pth.tar')\n",
        "\n",
        "# create the network architecture\n",
        "model = models.__dict__[arch](num_classes=365)\n",
        "\n",
        "#model_weight = '%s_places365.pth.tar' % arch\n",
        "\n",
        "checkpoint = torch.load(model_weight, map_location=lambda storage, loc: storage) # model trained in GPU could be deployed in CPU machine like this!\n",
        "state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()} # the data parallel layer will add 'module' before each layer name\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "model.cpu()\n",
        "torch.save(model.state_dict(), './places/resnet18_state_dict.pth')\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE68e7nF6xtq",
        "outputId": "4c71d066-7c5d-4e4c-c7c8-8e6a594baf2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path_places = './places'\n",
        "\n",
        "model_context = models.__dict__[arch](num_classes=365)\n",
        "context_state_dict = torch.load(os.path.join(model_path_places, 'resnet18_state_dict.pth'))\n",
        "model_context.load_state_dict(context_state_dict)\n",
        "print (summary(model_context, (3,224,224), device=\"cpu\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6O7y5I866ux",
        "outputId": "a9643658-9a6d-4ed2-d005-963d7719b772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                  [-1, 365]         187,245\n",
            "================================================================\n",
            "Total params: 11,363,757\n",
            "Trainable params: 11,363,757\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 43.35\n",
            "Estimated Total Size (MB): 106.71\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_context_features = list(model_context.children())[-1].in_features"
      ],
      "metadata": {
        "id": "Fc2NBN0QwsKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. Resnet-50 (Places365 weight)"
      ],
      "metadata": {
        "id": "jW9owD416_92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Resnet50 model trained on places dataset\n",
        "store_path = \"./places\"\n",
        "if not os.path.exists(store_path):\n",
        "    os.mkdir(store_path)\n",
        "\n",
        "file_path = \"./places/resnet50_places365.pth.tar\"\n",
        "if not os.path.exists(file_path):\n",
        "    !wget http://places2.csail.mit.edu/models_places365/resnet50_places365.pth.tar -O ./places/resnet50_places365.pth.tar"
      ],
      "metadata": {
        "id": "-F0nw0wX7GqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628cd982-f681-4968-db69-f456725fd483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-21 14:12:53--  http://places2.csail.mit.edu/models_places365/resnet50_places365.pth.tar\n",
            "Resolving places2.csail.mit.edu (places2.csail.mit.edu)... 128.52.132.120\n",
            "Connecting to places2.csail.mit.edu (places2.csail.mit.edu)|128.52.132.120|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 97270159 (93M) [application/x-tar]\n",
            "Saving to: ‘./places/resnet50_places365.pth.tar’\n",
            "\n",
            "./places/resnet50_p 100%[===================>]  92.76M  70.3MB/s    in 1.3s    \n",
            "\n",
            "2023-11-21 14:12:55 (70.3 MB/s) - ‘./places/resnet50_places365.pth.tar’ saved [97270159/97270159]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the architecture to use\n",
        "arch50 = 'resnet50'\n",
        "model_weight = os.path.join('./places', 'resnet50_places365.pth.tar')\n",
        "\n",
        "# create the network architecture\n",
        "model = models.__dict__[arch50](num_classes=365)\n",
        "\n",
        "#model_weight = '%s_places365.pth.tar' % arch\n",
        "\n",
        "checkpoint = torch.load(model_weight, map_location=lambda storage, loc: storage) # model trained in GPU could be deployed in CPU machine like this!\n",
        "state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()} # the data parallel layer will add 'module' before each layer name\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "model.cpu()\n",
        "torch.save(model.state_dict(), './places/resnet50_state_dict.pth')\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "id": "Tz9HaS3G7Iqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab05116-a5fa-4aa8-e23d-ac11374e4655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path_places = './places'\n",
        "\n",
        "model_context = models.__dict__[arch50](num_classes=365)\n",
        "context_state_dict = torch.load(os.path.join(model_path_places, 'resnet50_state_dict.pth'))\n",
        "model_context.load_state_dict(context_state_dict)\n",
        "\n",
        "print (summary(model_context, (3,224,224), device=\"cpu\"))"
      ],
      "metadata": {
        "id": "fbeTq5Z87MLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d384c5d5-d0dc-45b5-942b-cff4413c291f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                  [-1, 365]         747,885\n",
            "================================================================\n",
            "Total params: 24,255,917\n",
            "Trainable params: 24,255,917\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 286.55\n",
            "Params size (MB): 92.53\n",
            "Estimated Total Size (MB): 379.66\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_context_features = list(model_context.children())[-1].in_features"
      ],
      "metadata": {
        "id": "gR_rwDhXwwTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 . Face Branch:\n",
        "The key to predicting emotion in a human image is facial expression. we employ two pre-trained models on the FER-2013 dataset by [Shangeth](https://github.com/shangeth/Facial-Emotion-Recognition-PyTorch-ONNX) and\n",
        "[Balmukund](https://www.kaggle.com/code/balmukund/fer-2013-pytorch-implementation?fbclid=IwAR3xaZrtY7-RDZiXHGcjf6ytJ5Nk4wMDxGhsQs0pg2R0ul7GNv7lgS3ePI8), denoted by S-FER and B-FER, respectively.\n"
      ],
      "metadata": {
        "id": "B3sEJzsC46AU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64NB2FNbr7Gy"
      },
      "source": [
        "### a. S-FER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEy2A7Chi6Q_"
      },
      "outputs": [],
      "source": [
        "face_model_path = \"/content/drive/MyDrive/VA-prediction/models/FER_trained_model.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgH099-1jSyK"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class Face_Emotion_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Face_Emotion_CNN, self).__init__()\n",
        "    self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
        "    self.cnn2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n",
        "    self.cnn3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "    self.cnn4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "    self.cnn5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "    self.cnn6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "    self.cnn7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(2, 1)\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    self.cnn1_bn = nn.BatchNorm2d(8)\n",
        "    self.cnn2_bn = nn.BatchNorm2d(16)\n",
        "    self.cnn3_bn = nn.BatchNorm2d(32)\n",
        "    self.cnn4_bn = nn.BatchNorm2d(64)\n",
        "    self.cnn5_bn = nn.BatchNorm2d(128)\n",
        "    self.cnn6_bn = nn.BatchNorm2d(256)\n",
        "    self.cnn7_bn = nn.BatchNorm2d(256)\n",
        "    self.fc1 = nn.Linear(1024, 512)\n",
        "    self.fc2 = nn.Linear(512, 256)\n",
        "    self.fc3 = nn.Linear(256, 7)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.pool1(self.cnn1_bn(self.cnn1(x))))\n",
        "    x = self.relu(self.pool1(self.cnn2_bn(self.dropout(self.cnn2(x)))))\n",
        "    x = self.relu(self.pool1(self.cnn3_bn(self.cnn3(x))))\n",
        "    x = self.relu(self.pool1(self.cnn4_bn(self.dropout(self.cnn4(x)))))\n",
        "    x = self.relu(self.pool2(self.cnn5_bn(self.cnn5(x))))\n",
        "    x = self.relu(self.pool2(self.cnn6_bn(self.dropout(self.cnn6(x)))))\n",
        "    x = self.relu(self.pool2(self.cnn7_bn(self.dropout(self.cnn7(x)))))\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.relu(self.dropout(self.fc1(x)))\n",
        "    x = self.relu(self.dropout(self.fc2(x)))\n",
        "    x = self.log_softmax(self.fc3(x))\n",
        "    return x\n",
        "\n",
        "  def count_parameters(self):\n",
        "    return sum(p.numel() for p in self.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtHvLP0vjYEw"
      },
      "outputs": [],
      "source": [
        "def load_trained_model(model_path):\n",
        "    model = Face_Emotion_CNN()\n",
        "    model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage), strict=False)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nYpOWFCY5mX"
      },
      "outputs": [],
      "source": [
        "model_face = load_trained_model(face_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu-ejjUZlfwY",
        "outputId": "8b5b83cc-a0ef-48e1-ab83-735f53a79842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 46, 46]              80\n",
            "       BatchNorm2d-2            [-1, 8, 46, 46]              16\n",
            "         MaxPool2d-3            [-1, 8, 45, 45]               0\n",
            "              ReLU-4            [-1, 8, 45, 45]               0\n",
            "            Conv2d-5           [-1, 16, 43, 43]           1,168\n",
            "           Dropout-6           [-1, 16, 43, 43]               0\n",
            "       BatchNorm2d-7           [-1, 16, 43, 43]              32\n",
            "         MaxPool2d-8           [-1, 16, 42, 42]               0\n",
            "              ReLU-9           [-1, 16, 42, 42]               0\n",
            "           Conv2d-10           [-1, 32, 40, 40]           4,640\n",
            "      BatchNorm2d-11           [-1, 32, 40, 40]              64\n",
            "        MaxPool2d-12           [-1, 32, 39, 39]               0\n",
            "             ReLU-13           [-1, 32, 39, 39]               0\n",
            "           Conv2d-14           [-1, 64, 37, 37]          18,496\n",
            "          Dropout-15           [-1, 64, 37, 37]               0\n",
            "      BatchNorm2d-16           [-1, 64, 37, 37]             128\n",
            "        MaxPool2d-17           [-1, 64, 36, 36]               0\n",
            "             ReLU-18           [-1, 64, 36, 36]               0\n",
            "           Conv2d-19          [-1, 128, 34, 34]          73,856\n",
            "      BatchNorm2d-20          [-1, 128, 34, 34]             256\n",
            "        MaxPool2d-21          [-1, 128, 17, 17]               0\n",
            "             ReLU-22          [-1, 128, 17, 17]               0\n",
            "           Conv2d-23          [-1, 256, 15, 15]         295,168\n",
            "          Dropout-24          [-1, 256, 15, 15]               0\n",
            "      BatchNorm2d-25          [-1, 256, 15, 15]             512\n",
            "        MaxPool2d-26            [-1, 256, 7, 7]               0\n",
            "             ReLU-27            [-1, 256, 7, 7]               0\n",
            "           Conv2d-28            [-1, 256, 5, 5]         590,080\n",
            "          Dropout-29            [-1, 256, 5, 5]               0\n",
            "      BatchNorm2d-30            [-1, 256, 5, 5]             512\n",
            "        MaxPool2d-31            [-1, 256, 2, 2]               0\n",
            "             ReLU-32            [-1, 256, 2, 2]               0\n",
            "           Linear-33                  [-1, 512]         524,800\n",
            "          Dropout-34                  [-1, 512]               0\n",
            "             ReLU-35                  [-1, 512]               0\n",
            "           Linear-36                  [-1, 256]         131,328\n",
            "          Dropout-37                  [-1, 256]               0\n",
            "             ReLU-38                  [-1, 256]               0\n",
            "           Linear-39                    [-1, 7]           1,799\n",
            "       LogSoftmax-40                    [-1, 7]               0\n",
            "================================================================\n",
            "Total params: 1,642,935\n",
            "Trainable params: 1,642,935\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 10.92\n",
            "Params size (MB): 6.27\n",
            "Estimated Total Size (MB): 17.20\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(summary(model_face, (1, 48,48), device=\"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5VggX-XlpGo"
      },
      "outputs": [],
      "source": [
        "class Face_Emotion_CNN_new(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Face_Emotion_CNN_new, self).__init__()\n",
        "    self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
        "    self.cnn2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n",
        "    self.cnn3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "    self.cnn4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "    self.cnn5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "    self.cnn6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "    self.cnn7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(2, 1)\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    self.cnn1_bn = nn.BatchNorm2d(8)\n",
        "    self.cnn2_bn = nn.BatchNorm2d(16)\n",
        "    self.cnn3_bn = nn.BatchNorm2d(32)\n",
        "    self.cnn4_bn = nn.BatchNorm2d(64)\n",
        "    self.cnn5_bn = nn.BatchNorm2d(128)\n",
        "    self.cnn6_bn = nn.BatchNorm2d(256)\n",
        "    self.cnn7_bn = nn.BatchNorm2d(256)\n",
        "    self.fc1 = nn.Linear(1024, 512)\n",
        "    self.fc2 = nn.Linear(512, 256)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.pool1(self.cnn1_bn(self.cnn1(x))))\n",
        "    x = self.relu(self.pool1(self.cnn2_bn(self.dropout(self.cnn2(x)))))\n",
        "    x = self.relu(self.pool1(self.cnn3_bn(self.cnn3(x))))\n",
        "    x = self.relu(self.pool1(self.cnn4_bn(self.dropout(self.cnn4(x)))))\n",
        "    x = self.relu(self.pool2(self.cnn5_bn(self.cnn5(x))))\n",
        "    x = self.relu(self.pool2(self.cnn6_bn(self.dropout(self.cnn6(x)))))\n",
        "    x = self.relu(self.pool2(self.cnn7_bn(self.dropout(self.cnn7(x)))))\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.relu(self.dropout(self.fc1(x)))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "  def count_parameters(self):\n",
        "    return sum(p.numel() for p in self.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTYPiX2li1s1"
      },
      "outputs": [],
      "source": [
        "state_dict = model_face.state_dict()\n",
        "del state_dict['fc3.weight']\n",
        "del state_dict['fc3.bias']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv_n-ClblX8H"
      },
      "outputs": [],
      "source": [
        "model_face = Face_Emotion_CNN_new()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptzfSZAMnOvh",
        "outputId": "2537786b-1fab-48b1-e4a8-dc05e6e1e04b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model_face.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kix2MSADrajH",
        "outputId": "08f5f73e-375e-4bd0-9a46-e87c991584d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 46, 46]              80\n",
            "       BatchNorm2d-2            [-1, 8, 46, 46]              16\n",
            "         MaxPool2d-3            [-1, 8, 45, 45]               0\n",
            "              ReLU-4            [-1, 8, 45, 45]               0\n",
            "            Conv2d-5           [-1, 16, 43, 43]           1,168\n",
            "           Dropout-6           [-1, 16, 43, 43]               0\n",
            "       BatchNorm2d-7           [-1, 16, 43, 43]              32\n",
            "         MaxPool2d-8           [-1, 16, 42, 42]               0\n",
            "              ReLU-9           [-1, 16, 42, 42]               0\n",
            "           Conv2d-10           [-1, 32, 40, 40]           4,640\n",
            "      BatchNorm2d-11           [-1, 32, 40, 40]              64\n",
            "        MaxPool2d-12           [-1, 32, 39, 39]               0\n",
            "             ReLU-13           [-1, 32, 39, 39]               0\n",
            "           Conv2d-14           [-1, 64, 37, 37]          18,496\n",
            "          Dropout-15           [-1, 64, 37, 37]               0\n",
            "      BatchNorm2d-16           [-1, 64, 37, 37]             128\n",
            "        MaxPool2d-17           [-1, 64, 36, 36]               0\n",
            "             ReLU-18           [-1, 64, 36, 36]               0\n",
            "           Conv2d-19          [-1, 128, 34, 34]          73,856\n",
            "      BatchNorm2d-20          [-1, 128, 34, 34]             256\n",
            "        MaxPool2d-21          [-1, 128, 17, 17]               0\n",
            "             ReLU-22          [-1, 128, 17, 17]               0\n",
            "           Conv2d-23          [-1, 256, 15, 15]         295,168\n",
            "          Dropout-24          [-1, 256, 15, 15]               0\n",
            "      BatchNorm2d-25          [-1, 256, 15, 15]             512\n",
            "        MaxPool2d-26            [-1, 256, 7, 7]               0\n",
            "             ReLU-27            [-1, 256, 7, 7]               0\n",
            "           Conv2d-28            [-1, 256, 5, 5]         590,080\n",
            "          Dropout-29            [-1, 256, 5, 5]               0\n",
            "      BatchNorm2d-30            [-1, 256, 5, 5]             512\n",
            "        MaxPool2d-31            [-1, 256, 2, 2]               0\n",
            "             ReLU-32            [-1, 256, 2, 2]               0\n",
            "           Linear-33                  [-1, 512]         524,800\n",
            "          Dropout-34                  [-1, 512]               0\n",
            "             ReLU-35                  [-1, 512]               0\n",
            "           Linear-36                  [-1, 256]         131,328\n",
            "================================================================\n",
            "Total params: 1,641,136\n",
            "Trainable params: 1,641,136\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 10.92\n",
            "Params size (MB): 6.26\n",
            "Estimated Total Size (MB): 17.19\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(summary(model_face, (1, 48,48), device=\"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_face_features = 256"
      ],
      "metadata": {
        "id": "t_W9c1RbwyJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVWB5vvjsDrG"
      },
      "source": [
        "### b. B-FER"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "isBFER = True"
      ],
      "metadata": {
        "id": "1M_akG9NmHp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6BSXEZUspA_"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, dropout):\n",
        "        super(Net, self).__init__()\n",
        "        dropout_value = dropout\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        )\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        )\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 24 RF=7\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        )\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "        )\n",
        "\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(1, 1), padding=1 , bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(512),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        )\n",
        "\n",
        "        # TRANSITION BLOCK 2\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 12 RF=20\n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        )\n",
        "\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        )\n",
        "\n",
        "        # TRANSITION BLOCK 3\n",
        "        self.pool3 = nn.MaxPool2d(2, 2) # output_size =6 RF=32\n",
        "\n",
        "        self.convblock8 = nn.Sequential(\n",
        "             nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=(3, 3), padding=1, bias=False),\n",
        "             nn.ReLU(),\n",
        "             nn.BatchNorm2d(512),\n",
        "             # nn.Dropout(dropout_value)\n",
        "         )\n",
        "\n",
        "        self.convblock9 = nn.Sequential(\n",
        "             nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3, 3), padding=0, bias=False),\n",
        "             nn.ReLU(),\n",
        "             nn.BatchNorm2d(256),\n",
        "             # nn.Dropout(dropout_value)\n",
        "         )\n",
        "        # self.pool2 = nn.MaxPool2d(2, 2) # output_size = 2\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=4)\n",
        "        )\n",
        "        self.convblock10 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=7, kernel_size=(1, 1), padding=0, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.convblock8(x)\n",
        "        x = self.convblock9(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.convblock10(x)\n",
        "        x = x.view(-1, 7)\n",
        "        return F.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6U_ZCGFsJzb"
      },
      "outputs": [],
      "source": [
        "model_face = Net(1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Met5dkWRsJoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c57982-f6af-4c7b-8114-8c8218cfb61a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "model_face.load_state_dict(torch.load(\"/content/drive/MyDrive/VA-prediction/models/FER_2013_Kaggle.pth\", map_location=lambda storage, loc: storage), strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqod4vYRtQzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4593b6-f12b-40e8-da55-00318214ed2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 48, 48]             864\n",
            "              ReLU-2           [-1, 32, 48, 48]               0\n",
            "       BatchNorm2d-3           [-1, 32, 48, 48]              64\n",
            "            Conv2d-4           [-1, 64, 48, 48]          18,432\n",
            "              ReLU-5           [-1, 64, 48, 48]               0\n",
            "       BatchNorm2d-6           [-1, 64, 48, 48]             128\n",
            "         MaxPool2d-7           [-1, 64, 24, 24]               0\n",
            "            Conv2d-8          [-1, 128, 24, 24]          73,728\n",
            "              ReLU-9          [-1, 128, 24, 24]               0\n",
            "      BatchNorm2d-10          [-1, 128, 24, 24]             256\n",
            "           Conv2d-11          [-1, 256, 24, 24]         294,912\n",
            "             ReLU-12          [-1, 256, 24, 24]               0\n",
            "      BatchNorm2d-13          [-1, 256, 24, 24]             512\n",
            "           Conv2d-14          [-1, 512, 26, 26]         131,072\n",
            "             ReLU-15          [-1, 512, 26, 26]               0\n",
            "      BatchNorm2d-16          [-1, 512, 26, 26]           1,024\n",
            "        MaxPool2d-17          [-1, 512, 13, 13]               0\n",
            "           Conv2d-18         [-1, 1024, 13, 13]       4,718,592\n",
            "             ReLU-19         [-1, 1024, 13, 13]               0\n",
            "      BatchNorm2d-20         [-1, 1024, 13, 13]           2,048\n",
            "           Conv2d-21         [-1, 1024, 13, 13]       9,437,184\n",
            "             ReLU-22         [-1, 1024, 13, 13]               0\n",
            "      BatchNorm2d-23         [-1, 1024, 13, 13]           2,048\n",
            "        MaxPool2d-24           [-1, 1024, 6, 6]               0\n",
            "           Conv2d-25            [-1, 512, 6, 6]       4,718,592\n",
            "             ReLU-26            [-1, 512, 6, 6]               0\n",
            "      BatchNorm2d-27            [-1, 512, 6, 6]           1,024\n",
            "           Conv2d-28            [-1, 256, 4, 4]       1,179,648\n",
            "             ReLU-29            [-1, 256, 4, 4]               0\n",
            "      BatchNorm2d-30            [-1, 256, 4, 4]             512\n",
            "        AvgPool2d-31            [-1, 256, 1, 1]               0\n",
            "           Conv2d-32              [-1, 7, 1, 1]           1,792\n",
            "================================================================\n",
            "Total params: 20,582,432\n",
            "Trainable params: 20,582,432\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 27.71\n",
            "Params size (MB): 78.52\n",
            "Estimated Total Size (MB): 106.25\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(summary(model_face, (3, 48,48), device=\"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA1SLRCwtdjV"
      },
      "outputs": [],
      "source": [
        "model_face = nn.Sequential(*(list(model_face.children())[:-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuHhoYddtjyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b0604d-5904-40d6-e638-f1210ff3f3ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 48, 48]             864\n",
            "              ReLU-2           [-1, 32, 48, 48]               0\n",
            "       BatchNorm2d-3           [-1, 32, 48, 48]              64\n",
            "            Conv2d-4           [-1, 64, 48, 48]          18,432\n",
            "              ReLU-5           [-1, 64, 48, 48]               0\n",
            "       BatchNorm2d-6           [-1, 64, 48, 48]             128\n",
            "         MaxPool2d-7           [-1, 64, 24, 24]               0\n",
            "            Conv2d-8          [-1, 128, 24, 24]          73,728\n",
            "              ReLU-9          [-1, 128, 24, 24]               0\n",
            "      BatchNorm2d-10          [-1, 128, 24, 24]             256\n",
            "           Conv2d-11          [-1, 256, 24, 24]         294,912\n",
            "             ReLU-12          [-1, 256, 24, 24]               0\n",
            "      BatchNorm2d-13          [-1, 256, 24, 24]             512\n",
            "           Conv2d-14          [-1, 512, 26, 26]         131,072\n",
            "             ReLU-15          [-1, 512, 26, 26]               0\n",
            "      BatchNorm2d-16          [-1, 512, 26, 26]           1,024\n",
            "        MaxPool2d-17          [-1, 512, 13, 13]               0\n",
            "           Conv2d-18         [-1, 1024, 13, 13]       4,718,592\n",
            "             ReLU-19         [-1, 1024, 13, 13]               0\n",
            "      BatchNorm2d-20         [-1, 1024, 13, 13]           2,048\n",
            "           Conv2d-21         [-1, 1024, 13, 13]       9,437,184\n",
            "             ReLU-22         [-1, 1024, 13, 13]               0\n",
            "      BatchNorm2d-23         [-1, 1024, 13, 13]           2,048\n",
            "        MaxPool2d-24           [-1, 1024, 6, 6]               0\n",
            "           Conv2d-25            [-1, 512, 6, 6]       4,718,592\n",
            "             ReLU-26            [-1, 512, 6, 6]               0\n",
            "      BatchNorm2d-27            [-1, 512, 6, 6]           1,024\n",
            "           Conv2d-28            [-1, 256, 4, 4]       1,179,648\n",
            "             ReLU-29            [-1, 256, 4, 4]               0\n",
            "      BatchNorm2d-30            [-1, 256, 4, 4]             512\n",
            "        AvgPool2d-31            [-1, 256, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 20,580,640\n",
            "Trainable params: 20,580,640\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 27.71\n",
            "Params size (MB): 78.51\n",
            "Estimated Total Size (MB): 106.24\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(summary(model_face, (3, 48,48), device=\"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_face_features = 256"
      ],
      "metadata": {
        "id": "RrcuvpF1w6GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV. Dataset:\n",
        "\n",
        "In this paper, we use the EMOTIC dataset - a database of images of people in real environments, annotated with their apparent emotions. The images are annotated with an extended list of 26 emotion categories combined with the three common continuous dimensions Valence, Arousal and Dominance.\n",
        "\n",
        "It consists of approximately 23,500 images collected from websites, social media, and other public datasets. Each image contains one or many people, and each person is labeled with Gender (Male or Female), Age (adult, kid, or teenager), and VAD (valence-arousal-dominance) values ranging from 0 to 10 and labeled to some of 26 discrete emotion categories. The 26 discrete emotion categories include: *Peace, Affection, Esteem, Anticipation, Engagement, Confidence, Happiness, Pleasure, Excitement, Surprise, Sympathy, Doubt/Confusion, Disconnection, Fatigue, Embarrassment, Yearning, Disapproval, Aversion, Annoyance, Anger, Sensitivity, Sadness, Disquietment, Fear, Pain, Suffering.*"
      ],
      "metadata": {
        "id": "fRVTvEUAM0_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/BaoNinh2808/Server-Client/main/Dataset_Sample.png\" width=\"50%\" height=\"50%\"/>"
      ],
      "metadata": {
        "id": "izyCyxuTznWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 . Data Normalization:"
      ],
      "metadata": {
        "id": "UqQsZv0u2xej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_mean = [0.4690646, 0.4407227, 0.40508908]\n",
        "context_std = [0.2514227, 0.24312855, 0.24266963]\n",
        "\n",
        "body_mean = [0.43832874, 0.3964344, 0.3706214]\n",
        "body_std = [0.24784276, 0.23621225, 0.2323653]\n",
        "\n",
        "if (isSwinT):\n",
        "  body_mean = [0.485, 0.456, 0.406]\n",
        "  body_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "face_mean = [0.507395516207, 0.507395516207, 0.507395516207]\n",
        "face_std = [0.255128989415, 0.255128989415, 0.255128989415]\n",
        "\n",
        "context_norm = [context_mean, context_std]\n",
        "body_norm = [body_mean, body_std]\n",
        "face_norm = [face_mean, face_std]\n",
        "\n",
        "train_transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                     transforms.ToTensor()])\n",
        "\n",
        "face_train_transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "face_test_transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                     transforms.ToTensor()])\n",
        "\n",
        "if (isSwinT):\n",
        "    train_transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                      transforms.Resize(size=[232], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                      transforms.CenterCrop(size=[224]),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "\n",
        "    test_transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                     transforms.Resize(size=[232], interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "                                      transforms.CenterCrop(size=[224]),\n",
        "                                     transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "wt0PrScX2w4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 . Create Class for Preprocessing Data:"
      ],
      "metadata": {
        "id": "DCkTATsr2Csg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Emotic_PreDataset(Dataset):\n",
        "  ''' Custom Emotic dataset class. Use preprocessed data stored in npy files. '''\n",
        "  def __init__(self, x_context, x_body, x_face, y_cat, y_cont, context_transform, body_transform, face_transform, context_norm, body_norm, face_norm):\n",
        "    super(Emotic_PreDataset,self).__init__()\n",
        "    self.x_context = x_context\n",
        "    self.x_body = x_body\n",
        "    self.x_face = x_face\n",
        "    self.y_cat = y_cat\n",
        "    self.y_cont = y_cont\n",
        "    self.context_transform = context_transform\n",
        "    self.body_transform = body_transform\n",
        "    self.face_transform = face_transform\n",
        "    self.context_norm = transforms.Normalize(context_norm[0], context_norm[1])  # Normalizing the context image with context mean and context std\n",
        "    self.body_norm = transforms.Normalize(body_norm[0], body_norm[1])           # Normalizing the body image with body mean and body std\n",
        "    self.face_norm = transforms.Normalize(face_norm[0], face_norm[1])           # Normalizing the face image with face mean and face std\n",
        "  def __len__(self):\n",
        "    return len(self.y_cont)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image_context = self.x_context[index]\n",
        "    image_body = self.x_body[index]\n",
        "    image_face = self.x_face[index]\n",
        "    cat_label = self.y_cat[index]\n",
        "    cont_label = self.y_cont[index]\n",
        "    # , torch.tensor(cat_label, dtype=torch.float32)\n",
        "    return self.context_norm(self.context_transform(image_context)), self.body_norm(self.body_transform(image_body)), self.face_norm(self.face_transform(image_face)), torch.tensor(cat_label, dtype=torch.float32),  torch.tensor(cont_label, dtype=torch.float32)/10.0\n",
        "\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG3hFf5B2H02",
        "outputId": "0e1bd858-4897-4360-ea01-f2c4c9153ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 . Preprocess and Load Data:"
      ],
      "metadata": {
        "id": "UKjZvzwu2IYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Change data_src variable as per your drive\n",
        "data_src = '/content/drive/MyDrive/VA-prediction/dataset'"
      ],
      "metadata": {
        "id": "f61PdiloMx7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "train_context = np.load(os.path.join(data_src,'pre', 'train_context_arr.npy'))\n",
        "train_body = np.load(os.path.join(data_src,'pre','train_body_arr.npy'))\n",
        "\n",
        "train_cat = np.load(os.path.join(data_src,'pre','train_cat_arr.npy'))\n",
        "train_cont = np.load(os.path.join(data_src,'pre','train_cont_arr.npy'))\n",
        "\n",
        "\n",
        "#val\n",
        "val_context = np.load(os.path.join(data_src,'pre','val_context_arr.npy'))\n",
        "val_body = np.load(os.path.join(data_src,'pre','val_body_arr.npy'))\n",
        "\n",
        "val_cat = np.load(os.path.join(data_src,'pre','val_cat_arr.npy'))\n",
        "val_cont = np.load(os.path.join(data_src,'pre','val_cont_arr.npy'))\n",
        "\n",
        "\n",
        "#test\n",
        "test_context = np.load(os.path.join(data_src,'pre','test_context_arr.npy'))\n",
        "test_body = np.load(os.path.join(data_src,'pre','test_body_arr.npy'))\\\n",
        "\n",
        "test_cat = np.load(os.path.join(data_src,'pre','test_cat_arr.npy'))\n",
        "test_cont = np.load(os.path.join(data_src,'pre','test_cont_arr.npy'))\n",
        "\n",
        "#Face data\n",
        "train_face =  np.stack((np.load(os.path.join(data_src,'pre','train_face_arr.npy')),) * 3, axis=-1)\n",
        "val_face = np.stack((np.load(os.path.join(data_src,'pre','val_face_arr.npy')),) * 3, axis=-1)\n",
        "test_face = np.stack((np.load(os.path.join(data_src,'pre','test_face_arr.npy')),) * 3, axis=-1)\n",
        "\n",
        "# Categorical emotion classes\n",
        "cat = ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion', 'Confidence', 'Disapproval', 'Disconnection',\n",
        "       'Disquietment', 'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem', 'Excitement', 'Fatigue', 'Fear',\n",
        "       'Happiness', 'Pain', 'Peace', 'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise', 'Sympathy', 'Yearning']\n",
        "\n",
        "cat2ind = {}\n",
        "ind2cat = {}\n",
        "for idx, emotion in enumerate(cat):\n",
        "  cat2ind[emotion] = idx\n",
        "  ind2cat[idx] = emotion\n",
        "\n",
        "print ('train ', 'context ', train_context.shape, 'body', train_body.shape, 'cat ', train_cat.shape, 'cont', train_cont.shape)\n",
        "print ('val ', 'context ', val_context.shape, 'body', val_body.shape, 'cat ', val_cat.shape, 'cont', val_cont.shape)\n",
        "print ('test ', 'context ', test_context.shape, 'body', test_body.shape, 'cat ', test_cat.shape, 'cont', test_cont.shape)\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "id": "nabGochbOhoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed64372d-7d57-420c-8408-e1c9cd84d9a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  context  (23266, 224, 224, 3) body (23266, 128, 128, 3) cat  (23266, 26) cont (23266, 3)\n",
            "val  context  (3315, 224, 224, 3) body (3315, 128, 128, 3) cat  (3315, 26) cont (3315, 3)\n",
            "test  context  (7203, 224, 224, 3) body (7203, 128, 128, 3) cat  (7203, 26) cont (7203, 3)\n",
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 26\n",
        "\n",
        "train_dataset = Emotic_PreDataset(train_context, train_body, train_face, train_cat, train_cont, \\\n",
        "                                  train_transform, train_transform, face_train_transform, context_norm, body_norm, face_norm)\n",
        "val_dataset = Emotic_PreDataset(val_context, val_body, val_face, val_cat, val_cont, \\\n",
        "                                train_transform, train_transform, face_train_transform, context_norm, body_norm, face_norm)\n",
        "test_dataset = Emotic_PreDataset(test_context, test_body, test_face, test_cat, test_cont, \\\n",
        "                                 test_transform, test_transform, face_test_transform, context_norm, body_norm, face_norm)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
        "\n",
        "print ('train loader ', len(train_loader), 'val loader ', len(val_loader), 'test', len(test_loader))\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4XX-8np2LEc",
        "outputId": "dd4901f4-dbe9-4e8b-c405-c93e24cf56a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loader  894 val loader  128 test 278\n",
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV. Loss Function & Evaluate Metric:"
      ],
      "metadata": {
        "id": "m3qa_SsH_1ao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 . Loss Function:"
      ],
      "metadata": {
        "id": "frTQfdMb_7Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscreteLoss(nn.Module):\n",
        "  ''' Class to measure loss between categorical emotion predictions and labels.'''\n",
        "  def __init__(self, weight_type='mean', device=torch.device('cpu')):\n",
        "    super(DiscreteLoss, self).__init__()\n",
        "    self.weight_type = weight_type\n",
        "    self.device = device\n",
        "    if self.weight_type == 'mean':\n",
        "      self.weights = torch.ones((1,26))/26.0\n",
        "      self.weights = self.weights.to(self.device)\n",
        "    elif self.weight_type == 'static':\n",
        "      self.weights = torch.FloatTensor([0.1435, 0.1870, 0.1692, 0.1165, 0.1949, 0.1204, 0.1728, 0.1372, 0.1620,\n",
        "         0.1540, 0.1987, 0.1057, 0.1482, 0.1192, 0.1590, 0.1929, 0.1158, 0.1907,\n",
        "         0.1345, 0.1307, 0.1665, 0.1698, 0.1797, 0.1657, 0.1520, 0.1537]).unsqueeze(0)\n",
        "      self.weights = self.weights.to(self.device)\n",
        "\n",
        "  def forward(self, pred, target):\n",
        "    if self.weight_type == 'dynamic':\n",
        "      self.weights = self.prepare_dynamic_weights(target)\n",
        "      self.weights = self.weights.to(self.device)\n",
        "    loss = (((pred - target)**2) * self.weights)\n",
        "    return loss.sum()\n",
        "\n",
        "  def prepare_dynamic_weights(self, target):\n",
        "    target_stats = torch.sum(target, dim=0).float().unsqueeze(dim=0).cpu()\n",
        "    weights = torch.zeros((1,26))\n",
        "    weights[target_stats != 0 ] = 1.0/torch.log(target_stats[target_stats != 0].data + 1.2)\n",
        "    weights[target_stats == 0] = 0.0001\n",
        "    return weights\n",
        "\n",
        "\n",
        "class ContinuousLoss_L2(nn.Module):\n",
        "  ''' Class to measure loss between continuous emotion dimension predictions and labels. Using l2 loss as base. '''\n",
        "  def __init__(self, margin=1):\n",
        "    super(ContinuousLoss_L2, self).__init__()\n",
        "    self.margin = margin\n",
        "\n",
        "  def forward(self, pred, target):\n",
        "    labs = torch.abs(pred - target)\n",
        "    loss = labs ** 2\n",
        "    loss[ (labs < self.margin) ] = 0.0\n",
        "    return loss.sum()\n",
        "\n",
        "\n",
        "class ContinuousLoss_SL1(nn.Module):\n",
        "  ''' Class to measure loss between continuous emotion dimension predictions and labels. Using smooth l1 loss as base. '''\n",
        "  def __init__(self, margin=1):\n",
        "    super(ContinuousLoss_SL1, self).__init__()\n",
        "    self.margin = margin\n",
        "\n",
        "  def forward(self, pred, target):\n",
        "    labs = torch.abs(pred - target)\n",
        "    loss = 0.5 * (labs ** 2)\n",
        "    loss[ (labs > self.margin) ] = labs[ (labs > self.margin) ] - 0.5\n",
        "    return loss.sum()\n",
        "\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd7pwOJu-pBd",
        "outputId": "322cb981-5e61-44b9-a9f6-39edc998c2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 . Evaluate Metric:"
      ],
      "metadata": {
        "id": "M6cv4IyH_9_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_scikit_ap(cat_preds, cat_labels):\n",
        "  ap = np.zeros(26, dtype=np.float32)\n",
        "  for i in range(26):\n",
        "    ap[i] = average_precision_score(cat_labels[i, :], cat_preds[i, :])\n",
        "  print ('ap', ap, ap.shape, ap.mean())\n",
        "  return ap.mean()\n",
        "\n",
        "\n",
        "def test_emotic_vad(cont_preds, cont_labels):\n",
        "  vad = np.zeros(3, dtype=np.float32)\n",
        "  for i in range(3):\n",
        "    vad[i] = np.mean(np.abs(cont_preds[i, :] - cont_labels[i, :]))\n",
        "  print ('vad', vad, vad.shape, vad.mean())\n",
        "  return vad.mean()\n",
        "\n",
        "\n",
        "def get_thresholds(cat_preds, cat_labels):\n",
        "  thresholds = np.zeros(26, dtype=np.float32)\n",
        "  for i in range(26):\n",
        "    p, r, t = precision_recall_curve(cat_labels[i, :], cat_preds[i, :])\n",
        "    for k in range(len(p)):\n",
        "      if p[k] == r[k]:\n",
        "        thresholds[i] = t[k]\n",
        "        break\n",
        "  np.save('./thresholds.npy', thresholds)\n",
        "  return thresholds\n",
        "\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNbGurZw8uLd",
        "outputId": "c91b31a2-56de-4f52-b1f6-feeabcf48b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VI. Model + Optimizer"
      ],
      "metadata": {
        "id": "ukfiUQKz1pKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue, define type of our experiment. If you want to predict Dicrete Emotions, let set **'isVADPrediction = False'**. Else if you want to predict VAD value, let set **'isVADPrediction = True'**"
      ],
      "metadata": {
        "id": "hbbOJqwe6p_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#determine Prediction type - Categorizes Prediction/VAD Prediction\n",
        "isVADPrediction = False"
      ],
      "metadata": {
        "id": "utZHlxIwO0GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Fusion(nn.Module):\n",
        "  ''' Fusion Model'''\n",
        "  def __init__(self, num_context_features, num_body_features, num_face_features):\n",
        "    super(Fusion,self).__init__()\n",
        "    self.num_context_features = num_context_features\n",
        "    self.num_body_features = num_body_features\n",
        "    self.num_face_features = num_face_features\n",
        "    self.fc1 = nn.Linear((self.num_context_features + self.num_body_features + self.num_face_features), 256)\n",
        "    self.bn1 = nn.BatchNorm1d(256)\n",
        "    self.d1 = nn.Dropout(p=0.5)\n",
        "    self.fc_cat = nn.Linear(256, 26)\n",
        "    self.fc_cont = nn.Linear(256, 3)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "  def forward(self, x_context, x_body, x_face):\n",
        "    context_features = x_context.view(-1, self.num_context_features)\n",
        "    body_features = x_body.view(-1, self.num_body_features)\n",
        "    face_features = x_face.view(-1, self.num_face_features)\n",
        "    fuse_features = torch.cat((context_features, body_features, face_features), 1)\n",
        "    fuse_out = self.fc1(fuse_features)\n",
        "    fuse_out = self.bn1(fuse_out)\n",
        "    fuse_out = self.relu(fuse_out)\n",
        "    fuse_out = self.d1(fuse_out)\n",
        "    cat_out = self.fc_cat(fuse_out)\n",
        "    cont_out = self.fc_cont(fuse_out)\n",
        "    if (isVADPrediction == False):\n",
        "        return cat_out\n",
        "    return cont_out\n",
        "\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCh0gv66-hud",
        "outputId": "cb8895a3-90ca-4792-9fed-ac8ca1f29db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6-3FTclWAGh",
        "outputId": "72e85f07-cff9-4ebe-d980-8fe38d8fcbc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ],
      "source": [
        "fusion_model = Fusion(num_context_features, num_body_features, num_face_features)\n",
        "model_context = nn.Sequential(*(list(model_context.children())[:-1]))\n",
        "model_body = nn.Sequential(*(list(model_body.children())[:-1]))\n",
        "model_face = model_face\n",
        "\n",
        "for param in fusion_model.parameters():\n",
        "  param.requires_grad = True\n",
        "for param in model_context.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in model_body.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in model_face.parameters():\n",
        "  param.requires_grad = False\n",
        "print ('completed cell')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s first define our device as the first visible cuda device if we have CUDA available:"
      ],
      "metadata": {
        "id": "aO-EmKL-4tzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "4ESNyf_i42NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRgM1Lt2kpzB",
        "outputId": "da07404e-3654-4338-8bc8-f97206041bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ],
      "source": [
        "# Define relevant variables\n",
        "learning_rate = 0.001\n",
        "weight_decay = 5e-4\n",
        "step_size = 7\n",
        "gamma = 0.1\n",
        "\n",
        "opt = optim.Adam((list(fusion_model.parameters()) + list(model_context.parameters()) + \\\n",
        "                  list(model_body.parameters()) + list(model_face.parameters())), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "scheduler = StepLR(opt, step_size=7, gamma=gamma)\n",
        "\n",
        "#Chose loss function for Discrete Emotion Prediction Trainning and Continous Emotion Prediction trainning\n",
        "disc_loss = DiscreteLoss('dynamic', device)\n",
        "cont_loss_L2 = ContinuousLoss_L2()\n",
        "\n",
        "print ('completed cell')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VII. Trainning + Testing Functions:"
      ],
      "metadata": {
        "id": "78NEK3P-8rjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discrete Emotion Prediction:**"
      ],
      "metadata": {
        "id": "8erWPRPp0fJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_disc(models, device, data_loader, num_images):\n",
        "    model_context, model_body, model_face, fusion_model = models\n",
        "    cat_preds = np.zeros((num_images, 26))\n",
        "    cat_labels = np.zeros((num_images, 26))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model_context.to(device)\n",
        "        model_body.to(device)\n",
        "        model_face.to(device)\n",
        "        fusion_model.to(device)\n",
        "        model_context.eval()\n",
        "        model_body.eval()\n",
        "        model_face.eval()\n",
        "        fusion_model.eval()\n",
        "\n",
        "        indx = 0\n",
        "        print ('starting testing')\n",
        "        for images_context, images_body, images_face, labels_cat, labels_cont in iter(data_loader):\n",
        "            images_context = images_context.to(device)\n",
        "            images_body = images_body.to(device)\n",
        "            images_face = images_face.to(device)\n",
        "            if (isBFER == False):\n",
        "                images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n",
        "\n",
        "            labels_cat = labels_cat.to(device)\n",
        "            labels_cont = labels_cont.to(device)\n",
        "\n",
        "\n",
        "            pred_context = model_context(images_context)\n",
        "            pred_body = model_body(images_body)\n",
        "            pred_face = model_face(images_face)\n",
        "            pred_cat = fusion_model(pred_context, pred_body, pred_face)\n",
        "\n",
        "            cat_preds[ indx : (indx + pred_cat.shape[0]), :] = pred_cat.to(\"cpu\").data.numpy()\n",
        "            cat_labels[ indx : (indx + labels_cat.shape[0]), :] = labels_cat.to(\"cpu\").data.numpy()\n",
        "            indx = indx + pred_cat.shape[0]\n",
        "\n",
        "    cat_preds = cat_preds.transpose()\n",
        "    cat_labels = cat_labels.transpose()\n",
        "    print ('completed testing')\n",
        "    ap_mean = test_scikit_ap(cat_preds, cat_labels)\n",
        "    return ap_mean\n",
        "\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "id": "l3vBcqbDyHgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d0b701-a951-4c3b-ea92-57e35bf22ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_disc(epochs, model_path, opt, scheduler, models, disc_loss, cont_loss, cat_loss_param=1.0, cont_loss_param=0.0, train_length = train_dataset.__len__(), val_length = val_dataset.__len__()):\n",
        "  if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path)\n",
        "\n",
        "  min_loss = np.inf\n",
        "  min_mae = np.inf\n",
        "\n",
        "  train_loss = list()\n",
        "  val_loss = list()\n",
        "  train_mae = list()\n",
        "  val_mae = list()\n",
        "\n",
        "  model_context, model_body, model_face, fusion_model = models\n",
        "\n",
        "  for e in range(epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    fusion_model.to(device)\n",
        "    model_context.to(device)\n",
        "    model_body.to(device)\n",
        "    model_face.to(device)\n",
        "\n",
        "    fusion_model.train()\n",
        "    model_context.train()\n",
        "    model_body.train()\n",
        "    model_face.train()\n",
        "\n",
        "    train_cat_preds = np.zeros((train_length, 26))\n",
        "    train_cat_labels = np.zeros((train_length, 26))\n",
        "    indx = 0\n",
        "\n",
        "    for images_context, images_body, images_face, labels_cat, labels_cont in iter(train_loader):\n",
        "      images_context = images_context.to(device)\n",
        "      images_body = images_body.to(device)\n",
        "      images_face = images_face.to(device)\n",
        "      if (isBFER == False):\n",
        "            images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n",
        "      labels_cat = labels_cat.to(device)\n",
        "\n",
        "      opt.zero_grad()\n",
        "\n",
        "      pred_context = model_context(images_context)\n",
        "      pred_body = model_body(images_body)\n",
        "      pred_face = model_face(images_face)\n",
        "\n",
        "      pred_cat = fusion_model(pred_context, pred_body, pred_face)\n",
        "      cat_loss_batch = disc_loss(pred_cat, labels_cat)\n",
        "      loss = (cat_loss_param * cat_loss_batch)\n",
        "      running_loss += loss.item()\n",
        "\n",
        "\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "      train_cat_preds[ indx : (indx + pred_cat.shape[0]), :] = pred_cat.to(\"cpu\").data.numpy()\n",
        "      train_cat_labels[ indx : (indx + labels_cat.shape[0]), :] = labels_cat.to(\"cpu\").data.numpy()\n",
        "      indx = indx + pred_cat.shape[0]\n",
        "\n",
        "    if e % 1 == 0:\n",
        "      print ('epoch = %d training loss = %.4f' %(e, running_loss))\n",
        "      train_loss.append(running_loss)\n",
        "      train_cat_preds = train_cat_preds.transpose()\n",
        "      train_cat_labels = train_cat_labels.transpose()\n",
        "      train_mae.append(test_scikit_ap(train_cat_preds, train_cat_labels))\n",
        "      print ('epoch = %d training AP = %.4f' %(e, train_mae[-1]))\n",
        "\n",
        "\n",
        "    running_loss = 0.0\n",
        "    fusion_model.eval()\n",
        "    model_context.eval()\n",
        "    model_body.eval()\n",
        "    model_face.eval()\n",
        "\n",
        "    val_cat_preds = np.zeros((val_length, 26))\n",
        "    val_cat_labels = np.zeros((val_length, 26))\n",
        "    indx = 0\n",
        "    with torch.no_grad():\n",
        "      for images_context, images_body, images_face, labels_cat, labels_cont in iter(val_loader):\n",
        "        images_context = images_context.to(device)\n",
        "        images_body = images_body.to(device)\n",
        "        images_face = images_face.to(device)\n",
        "        if (isBFER == False):\n",
        "            images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n",
        "        labels_cat = labels_cat.to(device)\n",
        "\n",
        "        pred_context = model_context(images_context)\n",
        "        pred_body = model_body(images_body)\n",
        "        pred_face = model_face(images_face)\n",
        "\n",
        "        pred_cat = fusion_model(pred_context, pred_body, pred_face)\n",
        "        cat_loss_batch = disc_loss(pred_cat, labels_cat)\n",
        "        loss =  (cat_loss_param * cat_loss_batch)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        val_cat_preds[ indx : (indx + pred_cat.shape[0]), :] = pred_cat.to(\"cpu\").data.numpy()\n",
        "        val_cat_labels[ indx : (indx + labels_cat.shape[0]), :] = labels_cat.to(\"cpu\").data.numpy()\n",
        "        indx = indx + pred_cat.shape[0]\n",
        "      if e % 1 == 0:\n",
        "        print ('epoch = %d validation loss = %.4f' %(e, running_loss))\n",
        "        val_loss.append(running_loss)\n",
        "        val_cat_preds = val_cat_preds.transpose()\n",
        "        val_cat_labels = val_cat_labels.transpose()\n",
        "        val_mae.append(test_scikit_ap(val_cat_preds, val_cat_labels))\n",
        "        print ('epoch = %d validation AP = %.4f' %(e, val_mae[-1]))\n",
        "\n",
        "    scheduler.step()\n",
        "    print('')\n",
        "    if val_loss[-1] < min_loss:\n",
        "        min_loss = val_loss[-1]\n",
        "        # saving models for lowest loss\n",
        "        print ('saving model at epoch e = %d' %(e))\n",
        "        fusion_model.to(\"cpu\")\n",
        "        model_context.to(\"cpu\")\n",
        "        model_body.to(\"cpu\")\n",
        "        model_face.to(\"cpu\")\n",
        "        torch.save(fusion_model, os.path.join(model_path, 'model_fusion.pth'))\n",
        "        torch.save(model_context, os.path.join(model_path, 'model_context.pth'))\n",
        "        torch.save(model_body, os.path.join(model_path, 'model_body.pth'))\n",
        "        torch.save(model_face, os.path.join(model_path, 'model_face.pth'))\n",
        "\n",
        "  print ('completed training')\n",
        "\n",
        "  #statistic graphic\n",
        "  f, [[ax1, ax2], [ax3, ax4]] = plt.subplots(2, 2, figsize = (15, 10))\n",
        "  f.suptitle('Multi-Branch Network for Imagery Emotion Prediction')\n",
        "  ax1.plot(range(0,len(train_loss)),train_loss, color='Blue')\n",
        "  ax2.plot(range(0,len(val_loss)),val_loss, color='Red')\n",
        "  ax1.legend(['train loss'])\n",
        "  ax2.legend(['val loss'])\n",
        "\n",
        "  ax3.plot(range(0,len(train_mae)),train_mae, color='Blue')\n",
        "  ax4.plot(range(0,len(val_mae)),val_mae, color='Red')\n",
        "  ax3.legend(['train mAP'])\n",
        "  ax4.legend(['val mAP'])\n",
        "\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "id": "gwCTxwLmyxcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480a5322-6088-473a-bcfe-77ce01858b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Continous Emotion Prediction:**\n"
      ],
      "metadata": {
        "id": "_p8lfIk-0unL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_cont(models, device, data_loader, num_images):\n",
        "    model_context, model_body, model_face, fusion_model = models\n",
        "    cont_preds = np.zeros((num_images, 3))\n",
        "    cont_labels = np.zeros((num_images, 3))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model_context.to(device)\n",
        "        model_body.to(device)\n",
        "        model_face.to(device)\n",
        "        fusion_model.to(device)\n",
        "        model_context.eval()\n",
        "        model_body.eval()\n",
        "        model_face.eval()\n",
        "        fusion_model.eval()\n",
        "\n",
        "        indx = 0\n",
        "        print ('starting testing')\n",
        "        for images_context, images_body, images_face, labels_cat, labels_cont in iter(data_loader):\n",
        "            images_context = images_context.to(device)\n",
        "            images_body = images_body.to(device)\n",
        "            images_face = images_face.to(device)\n",
        "            if (isBFER == False):\n",
        "              images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n",
        "\n",
        "\n",
        "            pred_context = model_context(images_context)\n",
        "            pred_body = model_body(images_body)\n",
        "            pred_face = model_face(images_face)\n",
        "            pred_cont = fusion_model(pred_context, pred_body, pred_face)\n",
        "\n",
        "            cont_preds[ indx : (indx + pred_cont.shape[0]), :] = pred_cont.to(\"cpu\").data.numpy() * 10\n",
        "            cont_labels[ indx : (indx + labels_cont.shape[0]), :] = labels_cont.to(\"cpu\").data.numpy() * 10\n",
        "            indx = indx + pred_cont.shape[0]\n",
        "\n",
        "    cont_preds = cont_preds.transpose()\n",
        "    cont_labels = cont_labels.transpose()\n",
        "\n",
        "    print ('completed testing')\n",
        "    vad_mean = test_emotic_vad(cont_preds, cont_labels)\n",
        "    return vad_mean\n",
        "\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dzNjDHa8-Is",
        "outputId": "893b07ed-0267-4d78-81bd-f81220d4a0f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cont(epochs, model_path, opt, scheduler, models, disc_loss, cont_loss, cat_loss_param=0, cont_loss_param=1.0, train_length = train_dataset.__len__(), val_length = val_dataset.__len__()):\n",
        "  if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path)\n",
        "\n",
        "  min_loss = np.inf\n",
        "\n",
        "  train_loss = list()\n",
        "  val_loss = list()\n",
        "  train_mae = list()\n",
        "  val_mae = list()\n",
        "  model_context, model_body, model_face, fusion_model = models\n",
        "\n",
        "  for e in range(epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    model_context.to(device)\n",
        "    model_body.to(device)\n",
        "    model_face.to(device)\n",
        "    fusion_model.to(device)\n",
        "\n",
        "    model_context.train()\n",
        "    model_body.train()\n",
        "    model_face.train()\n",
        "    fusion_model.train()\n",
        "\n",
        "    train_cont_preds = np.zeros((train_length, 3))\n",
        "    train_cont_labels = np.zeros((train_length, 3))\n",
        "    indx = 0\n",
        "\n",
        "    for images_context, images_body, images_face, labels_cat, labels_cont in iter(train_loader):\n",
        "      images_context = images_context.to(device)\n",
        "      images_body = images_body.to(device)\n",
        "      images_face = images_face.to(device)\n",
        "      if (isBFER == False):\n",
        "            images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n",
        "      labels_cat = labels_cat.to(device)\n",
        "      labels_cont = labels_cont.to(device)\n",
        "\n",
        "      opt.zero_grad()\n",
        "\n",
        "      pred_context = model_context(images_context)\n",
        "      pred_body = model_body(images_body)\n",
        "      pred_face = model_face(images_face)\n",
        "      pred_cont = fusion_model(pred_context, pred_body, pred_face)\n",
        "      cont_loss_batch = cont_loss(pred_cont * 10, labels_cont * 10)\n",
        "      loss = cont_loss_param * cont_loss_batch\n",
        "      running_loss += loss.item()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "      train_cont_preds[ indx : (indx + pred_cont.shape[0]), :] = pred_cont.to(\"cpu\").data.numpy() * 10\n",
        "      train_cont_labels[ indx : (indx + labels_cont.shape[0]), :] = labels_cont.to(\"cpu\").data.numpy() * 10\n",
        "      indx = indx + pred_cont.shape[0]\n",
        "\n",
        "    if e % 1 == 0:\n",
        "      print ('epoch = %d training loss = %.4f' %(e, running_loss))\n",
        "    train_loss.append(running_loss)\n",
        "    train_cont_preds = train_cont_preds.transpose()\n",
        "    train_cont_labels = train_cont_labels.transpose()\n",
        "    train_mae.append(test_emotic_vad(train_cont_preds, train_cont_labels))\n",
        "    print ('epoch = %d training MAE = %.4f' %(e, train_mae[-1]))\n",
        "\n",
        "    running_loss = 0.0\n",
        "    model_context.eval()\n",
        "    model_body.eval()\n",
        "    model_face.eval()\n",
        "    fusion_model.eval()\n",
        "\n",
        "    val_cont_preds = np.zeros((val_length, 3))\n",
        "    val_cont_labels = np.zeros((val_length, 3))\n",
        "    indx = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for images_context, images_body, images_face, labels_cat, labels_cont in iter(val_loader):\n",
        "        images_context = images_context.to(device)\n",
        "        images_body = images_body.to(device)\n",
        "        images_face = images_face.to(device)\n",
        "        if (isBFER == False):\n",
        "            images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n",
        "        labels_cat = labels_cat.to(device)\n",
        "        labels_cont = labels_cont.to(device)\n",
        "\n",
        "        pred_context = model_context(images_context)\n",
        "        pred_body = model_body(images_body)\n",
        "        pred_face = model_face(images_face)\n",
        "        pred_cont = fusion_model(pred_context, pred_body, pred_face)\n",
        "        cont_loss_batch = cont_loss(pred_cont * 10, labels_cont * 10)\n",
        "        loss = cont_loss_param * cont_loss_batch\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        val_cont_preds[ indx : (indx + pred_cont.shape[0]), :] = pred_cont.to(\"cpu\").data.numpy() * 10\n",
        "        val_cont_labels[ indx : (indx + labels_cont.shape[0]), :] = labels_cont.to(\"cpu\").data.numpy() * 10\n",
        "        indx = indx + pred_cont.shape[0]\n",
        "      if e % 1 == 0:\n",
        "        print ('epoch = %d validation loss = %.4f' %(e, running_loss))\n",
        "    val_loss.append(running_loss)\n",
        "    val_cont_preds = val_cont_preds.transpose()\n",
        "    val_cont_labels = val_cont_labels.transpose()\n",
        "    val_mae.append(test_emotic_vad(val_cont_preds, val_cont_labels))\n",
        "    print ('epoch = %d val MAE= %.4f' %(e, val_mae[-1]))\n",
        "    scheduler.step()\n",
        "\n",
        "    if val_loss[-1] < min_loss:\n",
        "        min_loss = val_loss[-1]\n",
        "        # saving models for lowest loss\n",
        "        print ('saving model at epoch e = %d' %(e))\n",
        "        fusion_model.to(\"cpu\")\n",
        "        model_context.to(\"cpu\")\n",
        "        model_body.to(\"cpu\")\n",
        "        model_face.to(\"cpu\")\n",
        "        torch.save(fusion_model, os.path.join(model_path, 'model_fusion.pth'))\n",
        "        torch.save(model_context, os.path.join(model_path, 'model_context.pth'))\n",
        "        torch.save(model_body, os.path.join(model_path, 'model_body.pth'))\n",
        "        torch.save(model_face, os.path.join(model_path, 'model_face.pth'))\n",
        "\n",
        "  print ('completed training')\n",
        "\n",
        "  #statistic graphic\n",
        "  f, [[ax1, ax2], [ax3, ax4]] = plt.subplots(2, 2, figsize = (15, 10))\n",
        "  f.suptitle('Multi-Branch Network for Imagery Emotion Prediction')\n",
        "  ax1.plot(range(0,len(train_loss)),train_loss, color='Blue')\n",
        "  ax2.plot(range(0,len(val_loss)),val_loss, color='Red')\n",
        "  ax1.legend(['train loss'])\n",
        "  ax2.legend(['val loss'])\n",
        "\n",
        "  ax3.plot(range(0,len(train_mae)),train_mae, color='Blue')\n",
        "  ax4.plot(range(0,len(val_mae)),val_mae, color='Red')\n",
        "  ax3.legend(['train MAE'])\n",
        "  ax4.legend(['val MAE'])\n",
        "\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIZgHaT99AYZ",
        "outputId": "9e99ddb3-d001-49ac-911f-2acf008f3142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VIII. Trainning:\n"
      ],
      "metadata": {
        "id": "koEJMH3G9DUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainning(epochs, model_path, opt, scheduler, models, disc_loss, cont_loss, cat_loss_param=1.0, cont_loss_param=0.0, train_length = train_dataset.__len__(), val_length = val_dataset.__len__()):\n",
        "  if (isVADPrediction):\n",
        "      train_cont(epochs, model_path, opt, scheduler, models, disc_loss, cont_loss, cat_loss_param=1.0, cont_loss_param=0.0, train_length = train_dataset.__len__(), val_length = val_dataset.__len__())\n",
        "  else:\n",
        "      train_disc(epochs, model_path, opt, scheduler, models, disc_loss, cont_loss, cat_loss_param=1.0, cont_loss_param=0.0, train_length = train_dataset.__len__(), val_length = val_dataset.__len__())"
      ],
      "metadata": {
        "id": "xyDR6MZ-2TZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define number of epochs and path to store model after trainning - (recommend at least 15 epochs for regression)\n",
        "epochs = 15\n",
        "path_to_store_model = \"./models\""
      ],
      "metadata": {
        "id": "HS_iI47FxcsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainning\n",
        "trainning(epochs, path_to_store_model, opt, scheduler, [model_context, model_body, model_face, fusion_model], disc_loss=disc_loss, cont_loss=cont_loss_L2, cat_loss_param=1.0, cont_loss_param=1.0)"
      ],
      "metadata": {
        "id": "Z2PZOlxt9G0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140e2064-9972-4dec-be33-353ea1ea2625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0 training loss = 30183.2933\n",
            "ap [0.06512713 0.0230436  0.02637557 0.30027354 0.0118363  0.23549156\n",
            " 0.02564059 0.08331157 0.02600695 0.03626565 0.00746735 0.5920181\n",
            " 0.03847943 0.26394403 0.0304147  0.00912461 0.33495495 0.01093677\n",
            " 0.08392297 0.10796772 0.02800897 0.01898289 0.01858565 0.01739594\n",
            " 0.03431687 0.03440329] (26,) 0.09478064\n",
            "epoch = 0 training AP = 0.0948\n",
            "epoch = 0 validation loss = 6721.0548\n",
            "ap [0.3902774  0.16532934 0.19938165 0.94885945 0.10245614 0.7844179\n",
            " 0.2122179  0.3622055  0.15807906 0.1740137  0.06208112 0.97505087\n",
            " 0.2198821  0.78310984 0.15865353 0.08910773 0.8159809  0.17247944\n",
            " 0.2566719  0.48135138 0.17235464 0.07436915 0.20000708 0.1559621\n",
            " 0.31217873 0.1213553 ] (26,) 0.32876283\n",
            "epoch = 0 validation AP = 0.3288\n",
            "\n",
            "saving model at epoch e = 0\n",
            "epoch = 1 training loss = 22124.2622\n",
            "ap [0.10795619 0.12273638 0.06672122 0.35443553 0.0432477  0.298983\n",
            " 0.08425109 0.09936243 0.03718231 0.04982024 0.00954957 0.6210844\n",
            " 0.0420312  0.31872407 0.04863939 0.01322745 0.40597165 0.02979865\n",
            " 0.09413957 0.13779207 0.07838495 0.03243553 0.06042216 0.02311965\n",
            " 0.04585789 0.04087905] (26,) 0.12564436\n",
            "epoch = 1 training AP = 0.1256\n",
            "epoch = 1 validation loss = 6581.2992\n",
            "ap [0.4287188  0.20180373 0.1986844  0.95159847 0.14899282 0.780109\n",
            " 0.24871467 0.3799222  0.1709416  0.19604674 0.05983124 0.9747457\n",
            " 0.24722263 0.7931542  0.15084215 0.08866739 0.8190392  0.15880658\n",
            " 0.2565634  0.5195958  0.1997448  0.07057077 0.20240706 0.12652534\n",
            " 0.35161597 0.11444055] (26,) 0.3399733\n",
            "epoch = 1 validation AP = 0.3400\n",
            "\n",
            "saving model at epoch e = 1\n",
            "epoch = 2 training loss = 21622.0376\n",
            "ap [0.13683605 0.13471267 0.08476331 0.3615381  0.04331815 0.3057415\n",
            " 0.1005017  0.10156927 0.04824638 0.05970281 0.01119674 0.6398876\n",
            " 0.04559202 0.3408883  0.07239147 0.01515041 0.43924683 0.03568614\n",
            " 0.10695863 0.1418611  0.09400751 0.03265446 0.06960665 0.02487811\n",
            " 0.05046354 0.04471278] (26,) 0.13623509\n",
            "epoch = 2 training AP = 0.1362\n",
            "epoch = 2 validation loss = 6530.8808\n",
            "ap [0.40162486 0.1671297  0.2219161  0.94910055 0.1756149  0.78952855\n",
            " 0.26142287 0.37804222 0.2054826  0.19993721 0.05755562 0.97458166\n",
            " 0.23098323 0.8016386  0.15382266 0.0777837  0.8220017  0.18036667\n",
            " 0.29454744 0.5127158  0.2560574  0.08775722 0.2310109  0.13058892\n",
            " 0.34442917 0.13486394] (26,) 0.34771168\n",
            "epoch = 2 validation AP = 0.3477\n",
            "\n",
            "saving model at epoch e = 2\n",
            "epoch = 3 training loss = 21114.4021\n",
            "ap [0.1452521  0.15388197 0.0978096  0.37213984 0.05626619 0.3266491\n",
            " 0.11876006 0.11348212 0.05865166 0.07302312 0.01080499 0.65062916\n",
            " 0.05013523 0.35702097 0.07871941 0.02231553 0.4572238  0.03632322\n",
            " 0.1131831  0.16486698 0.12516335 0.03590398 0.08938095 0.03142037\n",
            " 0.05926603 0.05297474] (26,) 0.1481249\n",
            "epoch = 3 training AP = 0.1481\n",
            "epoch = 3 validation loss = 6511.3388\n",
            "ap [0.4270591  0.20685585 0.24243125 0.95414627 0.18846251 0.79530287\n",
            " 0.26427904 0.3704386  0.20171505 0.22196472 0.05774892 0.9809255\n",
            " 0.23350702 0.8128958  0.17554967 0.07524553 0.81702876 0.18196413\n",
            " 0.30389607 0.4979814  0.24303898 0.08655782 0.24932754 0.14695281\n",
            " 0.35298222 0.1195439 ] (26,) 0.3541462\n",
            "epoch = 3 validation AP = 0.3541\n",
            "\n",
            "saving model at epoch e = 3\n",
            "epoch = 4 training loss = 20832.8525\n",
            "ap [0.15552618 0.14482082 0.10790057 0.37639955 0.06436998 0.33631933\n",
            " 0.15017064 0.11971208 0.06642541 0.07496953 0.01352641 0.6549269\n",
            " 0.05342197 0.36413574 0.09627478 0.02465537 0.46669668 0.04634434\n",
            " 0.11966594 0.17184286 0.13880232 0.06450492 0.08385452 0.02940661\n",
            " 0.06624941 0.0627228 ] (26,) 0.15590943\n",
            "epoch = 4 training AP = 0.1559\n",
            "epoch = 4 validation loss = 6499.4521\n",
            "ap [0.45229256 0.2317051  0.24096309 0.9508724  0.19897161 0.79157907\n",
            " 0.28115922 0.40948516 0.22117093 0.22753169 0.06266391 0.9802747\n",
            " 0.244733   0.8104534  0.17481364 0.09410601 0.8399334  0.19625004\n",
            " 0.30839738 0.5314287  0.24306946 0.08652907 0.26548678 0.14933667\n",
            " 0.36910665 0.1320996 ] (26,) 0.3651697\n",
            "epoch = 4 validation AP = 0.3652\n",
            "\n",
            "saving model at epoch e = 4\n",
            "epoch = 5 training loss = 20729.6468\n",
            "ap [0.17738922 0.15947495 0.11495556 0.38357696 0.07538581 0.3407028\n",
            " 0.155004   0.13030568 0.06938736 0.07701559 0.01772789 0.6649274\n",
            " 0.05657683 0.36273313 0.1266158  0.02451837 0.47240558 0.05838869\n",
            " 0.12328819 0.18028249 0.16681677 0.05823104 0.10891745 0.03445163\n",
            " 0.07611673 0.05763303] (26,) 0.16433956\n",
            "epoch = 5 training AP = 0.1643\n",
            "epoch = 5 validation loss = 6601.8694\n",
            "ap [0.40773642 0.21518008 0.21913388 0.95328146 0.18657616 0.79204965\n",
            " 0.26855448 0.4118963  0.19799368 0.20885216 0.05615321 0.9748061\n",
            " 0.26032332 0.8202835  0.15677847 0.1004732  0.8502766  0.18267658\n",
            " 0.32042995 0.526081   0.26382297 0.09015234 0.26242054 0.1704155\n",
            " 0.34331238 0.13058242] (26,) 0.36039397\n",
            "epoch = 5 validation AP = 0.3604\n",
            "\n",
            "epoch = 6 training loss = 20495.8300\n",
            "ap [0.1860184  0.17924938 0.12519269 0.39317408 0.07161464 0.33237627\n",
            " 0.14555004 0.13430852 0.06806257 0.0846122  0.01588603 0.6674991\n",
            " 0.05666926 0.371843   0.12811565 0.0367302  0.4826084  0.06044501\n",
            " 0.13809106 0.19081599 0.19847757 0.06368119 0.11976656 0.03735889\n",
            " 0.07415947 0.06060812] (26,) 0.17011207\n",
            "epoch = 6 training AP = 0.1701\n",
            "epoch = 6 validation loss = 6557.5603\n",
            "ap [0.4356544  0.21587944 0.21859823 0.9547482  0.17925394 0.79687965\n",
            " 0.25687325 0.42287502 0.21022372 0.22995715 0.06387712 0.97765094\n",
            " 0.26635176 0.8161505  0.17035712 0.10684275 0.8410015  0.18701136\n",
            " 0.30920187 0.5473923  0.26556364 0.09643478 0.28790632 0.13231134\n",
            " 0.33969393 0.13634837] (26,) 0.36403996\n",
            "epoch = 6 validation AP = 0.3640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IX. Testing:"
      ],
      "metadata": {
        "id": "VXcSmlCq9Pof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained model for testing\n",
        "model_path = path_to_store_model\n",
        "model_context = torch.load(os.path.join(model_path, 'model_context.pth'))\n",
        "model_body = torch.load(os.path.join(model_path, 'model_body.pth'))\n",
        "model_face = torch.load(os.path.join(model_path, 'model_face.pth'))\n",
        "fusion_model = torch.load(os.path.join(model_path, 'model_fusion.pth'))\n",
        "\n",
        "model_context.eval()\n",
        "model_body.eval()\n",
        "model_face.eval()\n",
        "fusion_model.eval()\n",
        "\n",
        "print ('completed cell')"
      ],
      "metadata": {
        "id": "sEkcC74z9LYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing\n",
        "if (isVADPrediction):\n",
        "    test_mae = test_cont([model_context, model_body, model_face, fusion_model], device, test_loader, test_dataset.__len__())\n",
        "    print ('testing MAE=%.4f' %(test_mae))\n",
        "else:\n",
        "    test_map = test_disc([model_context, model_body, model_face, fusion_model], device, test_loader, test_dataset.__len__())\n",
        "    print ('testing mAP=%.4f' %(test_map))"
      ],
      "metadata": {
        "id": "olEVAyE39T2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}