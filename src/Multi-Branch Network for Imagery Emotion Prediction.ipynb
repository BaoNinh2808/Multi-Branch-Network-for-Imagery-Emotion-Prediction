{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["R5R5aurA4GCt","mOtPSs-j5Lx7","WRgaNN-k43K0","Na07bDEI6tXj","B3sEJzsC46AU","64NB2FNbr7Gy","rVWB5vvjsDrG"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["<h1><center> Multi-Branch Network for Imagery Emotion Prediction </center></h1>\n","<center> Using various source information, including faces, bodies, and scene contexts to predict both discrete and continuous emotions in an image</center>"],"metadata":{"id":"qmEwEwwKI0KH"}},{"cell_type":"markdown","source":["<h1>Project context</h1>\n","\n","aaa\n","bbb\n","ccc\n","ddd"],"metadata":{"id":"EVD0xB-tLzvd"}},{"cell_type":"markdown","source":["# I. Connect to Google Drive:"],"metadata":{"id":"KjwY_LzQMQah"}},{"cell_type":"code","source":["# Linking Google drive to use preprocessed data\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')\n","#/content/drive/My Drive//"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0PDx6Y2MVYr","executionInfo":{"status":"ok","timestamp":1697909764513,"user_tz":-420,"elapsed":22722,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"23e28e0f-5a5e-4115-de3b-a516050246af"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# II. General Import:"],"metadata":{"id":"hhmiYqp1MZDb"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","from PIL import Image\n","import scipy.io\n","from sklearn.metrics import average_precision_score, precision_recall_curve\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchsummary import summary\n","from torchvision import transforms\n","import torchvision.models as models\n","from torch.optim.lr_scheduler import StepLR\n","\n","print ('completed cell')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HazWZ1jlMeJS","executionInfo":{"status":"ok","timestamp":1697909769409,"user_tz":-420,"elapsed":4898,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"875e79ca-230f-459c-fbcc-b3a44c0a674f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"code","source":["#define global variables\n","\n","isSwinT = False   #variable for checking if using SwinT backbone\n","isBFER = False     #variable for checking if using B-FER backbone\n","num_context_features = 0  #store number of features that Context Feature Extraction branch extract\n","num_body_features = 0     #store number of features that Body Feature Extraction branch extract\n","num_face_features = 0     #store number of features that Face Feature Extraction branch extract"],"metadata":{"id":"tbm3DxyfgoIE","executionInfo":{"status":"ok","timestamp":1697909769409,"user_tz":-420,"elapsed":11,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#III. MODEL"],"metadata":{"id":"XIoL9Yflagqw"}},{"cell_type":"markdown","source":["The behind image shows the architecture of our proposed **Multi-Branch Network (MBN)**. The network is divided into two main parts. The first part extracts features from the body, the face, and context of the image, referred to as **body image**, **face image**, and **context image**. It consists of three branches to exploit emotions from subjects and background. We remark that the face region is extracted from the body image. The second part is a fusion network combining the features extracted from the three branches to predict the discrete emotions and VAD values of each person in the image."],"metadata":{"id":"Z9bSb7yBaokj"}},{"cell_type":"markdown","source":["<img src = \"https://raw.githubusercontent.com/BaoNinh2808/Server-Client/main/Proposed%20Method.png\" width = \"90%\">"],"metadata":{"id":"g0k7pc6PbsVM"}},{"cell_type":"markdown","source":["Our proposed network consists of three feature extraction branches, utilizing different deep learning models trained on suitable datasets to efficiently make predictions on human and scene images.\n","\n","You can see the picture to know about what backbone you can choose.\n","\n","<img src = \"https://raw.githubusercontent.com/BaoNinh2808/Server-Client/main/model_options.png\" width = \"90%\">\n","\n"],"metadata":{"id":"GQvFS1bPcDlq"}},{"cell_type":"markdown","source":["**Let's Choose Backbone for Each Branch:** For each branch just choose one.\n","\n","If you run automatically all cell, we will assign backbone for you. The default is:  \n","*   Context Branch: Resnet-50(Places365)\n","*   Body Branch:    SwinT(Retrain on Emotic)\n","*   Face Branch:    B-FER\n","\n","The combination of these backbones also give the best result in all combinations."],"metadata":{"id":"IjgQu5Da3z3M"}},{"cell_type":"markdown","source":["## 1 . Body Branch:\n"],"metadata":{"id":"R5R5aurA4GCt"}},{"cell_type":"markdown","source":["### a. Resnet-18 (ImageNet weight):"],"metadata":{"id":"mOtPSs-j5Lx7"}},{"cell_type":"code","source":["model_body = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n","print (summary(model_body, (3,224,224), device=\"cpu\"))"],"metadata":{"id":"nuq52OK_5DYV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910901439,"user_tz":-420,"elapsed":507,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"da76f5bd-3be0-4c44-b2d0-131629348a79"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","       BasicBlock-11           [-1, 64, 56, 56]               0\n","           Conv2d-12           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-13           [-1, 64, 56, 56]             128\n","             ReLU-14           [-1, 64, 56, 56]               0\n","           Conv2d-15           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-16           [-1, 64, 56, 56]             128\n","             ReLU-17           [-1, 64, 56, 56]               0\n","       BasicBlock-18           [-1, 64, 56, 56]               0\n","           Conv2d-19          [-1, 128, 28, 28]          73,728\n","      BatchNorm2d-20          [-1, 128, 28, 28]             256\n","             ReLU-21          [-1, 128, 28, 28]               0\n","           Conv2d-22          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-23          [-1, 128, 28, 28]             256\n","           Conv2d-24          [-1, 128, 28, 28]           8,192\n","      BatchNorm2d-25          [-1, 128, 28, 28]             256\n","             ReLU-26          [-1, 128, 28, 28]               0\n","       BasicBlock-27          [-1, 128, 28, 28]               0\n","           Conv2d-28          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-29          [-1, 128, 28, 28]             256\n","             ReLU-30          [-1, 128, 28, 28]               0\n","           Conv2d-31          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-32          [-1, 128, 28, 28]             256\n","             ReLU-33          [-1, 128, 28, 28]               0\n","       BasicBlock-34          [-1, 128, 28, 28]               0\n","           Conv2d-35          [-1, 256, 14, 14]         294,912\n","      BatchNorm2d-36          [-1, 256, 14, 14]             512\n","             ReLU-37          [-1, 256, 14, 14]               0\n","           Conv2d-38          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-39          [-1, 256, 14, 14]             512\n","           Conv2d-40          [-1, 256, 14, 14]          32,768\n","      BatchNorm2d-41          [-1, 256, 14, 14]             512\n","             ReLU-42          [-1, 256, 14, 14]               0\n","       BasicBlock-43          [-1, 256, 14, 14]               0\n","           Conv2d-44          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-45          [-1, 256, 14, 14]             512\n","             ReLU-46          [-1, 256, 14, 14]               0\n","           Conv2d-47          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-48          [-1, 256, 14, 14]             512\n","             ReLU-49          [-1, 256, 14, 14]               0\n","       BasicBlock-50          [-1, 256, 14, 14]               0\n","           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n","      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n","             ReLU-53            [-1, 512, 7, 7]               0\n","           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n","           Conv2d-56            [-1, 512, 7, 7]         131,072\n","      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n","             ReLU-58            [-1, 512, 7, 7]               0\n","       BasicBlock-59            [-1, 512, 7, 7]               0\n","           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n","             ReLU-62            [-1, 512, 7, 7]               0\n","           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n","             ReLU-65            [-1, 512, 7, 7]               0\n","       BasicBlock-66            [-1, 512, 7, 7]               0\n","AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n","           Linear-68                 [-1, 1000]         513,000\n","================================================================\n","Total params: 11,689,512\n","Trainable params: 11,689,512\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 62.79\n","Params size (MB): 44.59\n","Estimated Total Size (MB): 107.96\n","----------------------------------------------------------------\n","None\n"]}]},{"cell_type":"code","source":["num_body_features = list(model_body.children())[-1].in_features"],"metadata":{"id":"flgg-Wd_wlnV","executionInfo":{"status":"ok","timestamp":1697910901439,"user_tz":-420,"elapsed":2,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":["### b. Resnet-50 (ImageNet weight)"],"metadata":{"id":"2jUvcq7a5Wqe"}},{"cell_type":"code","source":["model_body = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n","print (summary(model_body, (3,224,224), device=\"cpu\"))"],"metadata":{"id":"qF3Rga2u5vxc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910903465,"user_tz":-420,"elapsed":2028,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"413a27e2-23ed-489a-ffd7-34e2deec0620"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n","            ReLU-143          [-1, 512, 14, 14]               0\n","          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n","            ReLU-146            [-1, 512, 7, 7]               0\n","          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n","          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n","            ReLU-151           [-1, 2048, 7, 7]               0\n","      Bottleneck-152           [-1, 2048, 7, 7]               0\n","          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n","            ReLU-155            [-1, 512, 7, 7]               0\n","          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n","            ReLU-158            [-1, 512, 7, 7]               0\n","          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n","            ReLU-161           [-1, 2048, 7, 7]               0\n","      Bottleneck-162           [-1, 2048, 7, 7]               0\n","          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n","            ReLU-165            [-1, 512, 7, 7]               0\n","          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n","            ReLU-168            [-1, 512, 7, 7]               0\n","          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n","            ReLU-171           [-1, 2048, 7, 7]               0\n","      Bottleneck-172           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","          Linear-174                 [-1, 1000]       2,049,000\n","================================================================\n","Total params: 25,557,032\n","Trainable params: 25,557,032\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 286.56\n","Params size (MB): 97.49\n","Estimated Total Size (MB): 384.62\n","----------------------------------------------------------------\n","None\n"]}]},{"cell_type":"code","source":["num_body_features = list(model_body.children())[-1].in_features"],"metadata":{"id":"6xQgAuHewnMt","executionInfo":{"status":"ok","timestamp":1697910903466,"user_tz":-420,"elapsed":12,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":["### c. Resnet-50 (Emotic weight)"],"metadata":{"id":"Vmg6YIovjGem"}},{"cell_type":"code","source":["model_body = torch.load('/content/drive/MyDrive/VA-prediction/models/body_train_lr001_b24_crossEtropy/model1.pth')\n","print (summary(model_body, (3,128,128), device=\"cpu\"))"],"metadata":{"id":"Hn2SiP8_jO4E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910904867,"user_tz":-420,"elapsed":1411,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"659f8f8c-f44c-4429-e972-3290305b25b9"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 64, 64]           9,408\n","       BatchNorm2d-2           [-1, 64, 64, 64]             128\n","              ReLU-3           [-1, 64, 64, 64]               0\n","         MaxPool2d-4           [-1, 64, 32, 32]               0\n","            Conv2d-5           [-1, 64, 32, 32]           4,096\n","       BatchNorm2d-6           [-1, 64, 32, 32]             128\n","              ReLU-7           [-1, 64, 32, 32]               0\n","            Conv2d-8           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-9           [-1, 64, 32, 32]             128\n","             ReLU-10           [-1, 64, 32, 32]               0\n","           Conv2d-11          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-12          [-1, 256, 32, 32]             512\n","           Conv2d-13          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-14          [-1, 256, 32, 32]             512\n","             ReLU-15          [-1, 256, 32, 32]               0\n","       Bottleneck-16          [-1, 256, 32, 32]               0\n","           Conv2d-17           [-1, 64, 32, 32]          16,384\n","      BatchNorm2d-18           [-1, 64, 32, 32]             128\n","             ReLU-19           [-1, 64, 32, 32]               0\n","           Conv2d-20           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-21           [-1, 64, 32, 32]             128\n","             ReLU-22           [-1, 64, 32, 32]               0\n","           Conv2d-23          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-24          [-1, 256, 32, 32]             512\n","             ReLU-25          [-1, 256, 32, 32]               0\n","       Bottleneck-26          [-1, 256, 32, 32]               0\n","           Conv2d-27           [-1, 64, 32, 32]          16,384\n","      BatchNorm2d-28           [-1, 64, 32, 32]             128\n","             ReLU-29           [-1, 64, 32, 32]               0\n","           Conv2d-30           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-31           [-1, 64, 32, 32]             128\n","             ReLU-32           [-1, 64, 32, 32]               0\n","           Conv2d-33          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-34          [-1, 256, 32, 32]             512\n","             ReLU-35          [-1, 256, 32, 32]               0\n","       Bottleneck-36          [-1, 256, 32, 32]               0\n","           Conv2d-37          [-1, 128, 32, 32]          32,768\n","      BatchNorm2d-38          [-1, 128, 32, 32]             256\n","             ReLU-39          [-1, 128, 32, 32]               0\n","           Conv2d-40          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-41          [-1, 128, 16, 16]             256\n","             ReLU-42          [-1, 128, 16, 16]               0\n","           Conv2d-43          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-44          [-1, 512, 16, 16]           1,024\n","           Conv2d-45          [-1, 512, 16, 16]         131,072\n","      BatchNorm2d-46          [-1, 512, 16, 16]           1,024\n","             ReLU-47          [-1, 512, 16, 16]               0\n","       Bottleneck-48          [-1, 512, 16, 16]               0\n","           Conv2d-49          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-50          [-1, 128, 16, 16]             256\n","             ReLU-51          [-1, 128, 16, 16]               0\n","           Conv2d-52          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-53          [-1, 128, 16, 16]             256\n","             ReLU-54          [-1, 128, 16, 16]               0\n","           Conv2d-55          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-56          [-1, 512, 16, 16]           1,024\n","             ReLU-57          [-1, 512, 16, 16]               0\n","       Bottleneck-58          [-1, 512, 16, 16]               0\n","           Conv2d-59          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-60          [-1, 128, 16, 16]             256\n","             ReLU-61          [-1, 128, 16, 16]               0\n","           Conv2d-62          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-63          [-1, 128, 16, 16]             256\n","             ReLU-64          [-1, 128, 16, 16]               0\n","           Conv2d-65          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-66          [-1, 512, 16, 16]           1,024\n","             ReLU-67          [-1, 512, 16, 16]               0\n","       Bottleneck-68          [-1, 512, 16, 16]               0\n","           Conv2d-69          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-70          [-1, 128, 16, 16]             256\n","             ReLU-71          [-1, 128, 16, 16]               0\n","           Conv2d-72          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-73          [-1, 128, 16, 16]             256\n","             ReLU-74          [-1, 128, 16, 16]               0\n","           Conv2d-75          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-76          [-1, 512, 16, 16]           1,024\n","             ReLU-77          [-1, 512, 16, 16]               0\n","       Bottleneck-78          [-1, 512, 16, 16]               0\n","           Conv2d-79          [-1, 256, 16, 16]         131,072\n","      BatchNorm2d-80          [-1, 256, 16, 16]             512\n","             ReLU-81          [-1, 256, 16, 16]               0\n","           Conv2d-82            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-83            [-1, 256, 8, 8]             512\n","             ReLU-84            [-1, 256, 8, 8]               0\n","           Conv2d-85           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-86           [-1, 1024, 8, 8]           2,048\n","           Conv2d-87           [-1, 1024, 8, 8]         524,288\n","      BatchNorm2d-88           [-1, 1024, 8, 8]           2,048\n","             ReLU-89           [-1, 1024, 8, 8]               0\n","       Bottleneck-90           [-1, 1024, 8, 8]               0\n","           Conv2d-91            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-92            [-1, 256, 8, 8]             512\n","             ReLU-93            [-1, 256, 8, 8]               0\n","           Conv2d-94            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-95            [-1, 256, 8, 8]             512\n","             ReLU-96            [-1, 256, 8, 8]               0\n","           Conv2d-97           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n","             ReLU-99           [-1, 1024, 8, 8]               0\n","      Bottleneck-100           [-1, 1024, 8, 8]               0\n","          Conv2d-101            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-102            [-1, 256, 8, 8]             512\n","            ReLU-103            [-1, 256, 8, 8]               0\n","          Conv2d-104            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-105            [-1, 256, 8, 8]             512\n","            ReLU-106            [-1, 256, 8, 8]               0\n","          Conv2d-107           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-108           [-1, 1024, 8, 8]           2,048\n","            ReLU-109           [-1, 1024, 8, 8]               0\n","      Bottleneck-110           [-1, 1024, 8, 8]               0\n","          Conv2d-111            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-112            [-1, 256, 8, 8]             512\n","            ReLU-113            [-1, 256, 8, 8]               0\n","          Conv2d-114            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-115            [-1, 256, 8, 8]             512\n","            ReLU-116            [-1, 256, 8, 8]               0\n","          Conv2d-117           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-118           [-1, 1024, 8, 8]           2,048\n","            ReLU-119           [-1, 1024, 8, 8]               0\n","      Bottleneck-120           [-1, 1024, 8, 8]               0\n","          Conv2d-121            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-122            [-1, 256, 8, 8]             512\n","            ReLU-123            [-1, 256, 8, 8]               0\n","          Conv2d-124            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-125            [-1, 256, 8, 8]             512\n","            ReLU-126            [-1, 256, 8, 8]               0\n","          Conv2d-127           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-128           [-1, 1024, 8, 8]           2,048\n","            ReLU-129           [-1, 1024, 8, 8]               0\n","      Bottleneck-130           [-1, 1024, 8, 8]               0\n","          Conv2d-131            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-132            [-1, 256, 8, 8]             512\n","            ReLU-133            [-1, 256, 8, 8]               0\n","          Conv2d-134            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-135            [-1, 256, 8, 8]             512\n","            ReLU-136            [-1, 256, 8, 8]               0\n","          Conv2d-137           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-138           [-1, 1024, 8, 8]           2,048\n","            ReLU-139           [-1, 1024, 8, 8]               0\n","      Bottleneck-140           [-1, 1024, 8, 8]               0\n","          Conv2d-141            [-1, 512, 8, 8]         524,288\n","     BatchNorm2d-142            [-1, 512, 8, 8]           1,024\n","            ReLU-143            [-1, 512, 8, 8]               0\n","          Conv2d-144            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-145            [-1, 512, 4, 4]           1,024\n","            ReLU-146            [-1, 512, 4, 4]               0\n","          Conv2d-147           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-148           [-1, 2048, 4, 4]           4,096\n","          Conv2d-149           [-1, 2048, 4, 4]       2,097,152\n","     BatchNorm2d-150           [-1, 2048, 4, 4]           4,096\n","            ReLU-151           [-1, 2048, 4, 4]               0\n","      Bottleneck-152           [-1, 2048, 4, 4]               0\n","          Conv2d-153            [-1, 512, 4, 4]       1,048,576\n","     BatchNorm2d-154            [-1, 512, 4, 4]           1,024\n","            ReLU-155            [-1, 512, 4, 4]               0\n","          Conv2d-156            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-157            [-1, 512, 4, 4]           1,024\n","            ReLU-158            [-1, 512, 4, 4]               0\n","          Conv2d-159           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-160           [-1, 2048, 4, 4]           4,096\n","            ReLU-161           [-1, 2048, 4, 4]               0\n","      Bottleneck-162           [-1, 2048, 4, 4]               0\n","          Conv2d-163            [-1, 512, 4, 4]       1,048,576\n","     BatchNorm2d-164            [-1, 512, 4, 4]           1,024\n","            ReLU-165            [-1, 512, 4, 4]               0\n","          Conv2d-166            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-167            [-1, 512, 4, 4]           1,024\n","            ReLU-168            [-1, 512, 4, 4]               0\n","          Conv2d-169           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-170           [-1, 2048, 4, 4]           4,096\n","            ReLU-171           [-1, 2048, 4, 4]               0\n","      Bottleneck-172           [-1, 2048, 4, 4]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","          Linear-174                    [-1, 6]          12,294\n","================================================================\n","Total params: 23,520,326\n","Trainable params: 12,294\n","Non-trainable params: 23,508,032\n","----------------------------------------------------------------\n","Input size (MB): 0.19\n","Forward/backward pass size (MB): 93.58\n","Params size (MB): 89.72\n","Estimated Total Size (MB): 183.49\n","----------------------------------------------------------------\n","None\n"]}]},{"cell_type":"code","source":["num_body_features = list(model_body.children())[-1].in_features"],"metadata":{"id":"65pnN9b2wn98","executionInfo":{"status":"ok","timestamp":1697910904869,"user_tz":-420,"elapsed":14,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":["### d. SwinT (ImageNet weight)"],"metadata":{"id":"fmwzerRK5bDi"}},{"cell_type":"code","source":["model_body = models.swin_t(weights = 'DEFAULT')\n","print (summary(model_body, (3,128,128), device=\"cpu\"))\n","isSwinT = True"],"metadata":{"id":"ZP5ilA_E5769","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910905891,"user_tz":-420,"elapsed":1035,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"a825d119-34f3-4952-d98f-010e08a4caa2"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 96, 32, 32]           4,704\n","           Permute-2           [-1, 32, 32, 96]               0\n","         LayerNorm-3           [-1, 32, 32, 96]             192\n","         LayerNorm-4           [-1, 32, 32, 96]             192\n","ShiftedWindowAttention-5           [-1, 32, 32, 96]               0\n","   StochasticDepth-6           [-1, 32, 32, 96]               0\n","         LayerNorm-7           [-1, 32, 32, 96]             192\n","            Linear-8          [-1, 32, 32, 384]          37,248\n","              GELU-9          [-1, 32, 32, 384]               0\n","          Dropout-10          [-1, 32, 32, 384]               0\n","           Linear-11           [-1, 32, 32, 96]          36,960\n","          Dropout-12           [-1, 32, 32, 96]               0\n","  StochasticDepth-13           [-1, 32, 32, 96]               0\n","SwinTransformerBlock-14           [-1, 32, 32, 96]               0\n","        LayerNorm-15           [-1, 32, 32, 96]             192\n","ShiftedWindowAttention-16           [-1, 32, 32, 96]               0\n","  StochasticDepth-17           [-1, 32, 32, 96]               0\n","        LayerNorm-18           [-1, 32, 32, 96]             192\n","           Linear-19          [-1, 32, 32, 384]          37,248\n","             GELU-20          [-1, 32, 32, 384]               0\n","          Dropout-21          [-1, 32, 32, 384]               0\n","           Linear-22           [-1, 32, 32, 96]          36,960\n","          Dropout-23           [-1, 32, 32, 96]               0\n","  StochasticDepth-24           [-1, 32, 32, 96]               0\n","SwinTransformerBlock-25           [-1, 32, 32, 96]               0\n","        LayerNorm-26          [-1, 16, 16, 384]             768\n","           Linear-27          [-1, 16, 16, 192]          73,728\n","     PatchMerging-28          [-1, 16, 16, 192]               0\n","        LayerNorm-29          [-1, 16, 16, 192]             384\n","ShiftedWindowAttention-30          [-1, 16, 16, 192]               0\n","  StochasticDepth-31          [-1, 16, 16, 192]               0\n","        LayerNorm-32          [-1, 16, 16, 192]             384\n","           Linear-33          [-1, 16, 16, 768]         148,224\n","             GELU-34          [-1, 16, 16, 768]               0\n","          Dropout-35          [-1, 16, 16, 768]               0\n","           Linear-36          [-1, 16, 16, 192]         147,648\n","          Dropout-37          [-1, 16, 16, 192]               0\n","  StochasticDepth-38          [-1, 16, 16, 192]               0\n","SwinTransformerBlock-39          [-1, 16, 16, 192]               0\n","        LayerNorm-40          [-1, 16, 16, 192]             384\n","ShiftedWindowAttention-41          [-1, 16, 16, 192]               0\n","  StochasticDepth-42          [-1, 16, 16, 192]               0\n","        LayerNorm-43          [-1, 16, 16, 192]             384\n","           Linear-44          [-1, 16, 16, 768]         148,224\n","             GELU-45          [-1, 16, 16, 768]               0\n","          Dropout-46          [-1, 16, 16, 768]               0\n","           Linear-47          [-1, 16, 16, 192]         147,648\n","          Dropout-48          [-1, 16, 16, 192]               0\n","  StochasticDepth-49          [-1, 16, 16, 192]               0\n","SwinTransformerBlock-50          [-1, 16, 16, 192]               0\n","        LayerNorm-51            [-1, 8, 8, 768]           1,536\n","           Linear-52            [-1, 8, 8, 384]         294,912\n","     PatchMerging-53            [-1, 8, 8, 384]               0\n","        LayerNorm-54            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-55            [-1, 8, 8, 384]               0\n","  StochasticDepth-56            [-1, 8, 8, 384]               0\n","        LayerNorm-57            [-1, 8, 8, 384]             768\n","           Linear-58           [-1, 8, 8, 1536]         591,360\n","             GELU-59           [-1, 8, 8, 1536]               0\n","          Dropout-60           [-1, 8, 8, 1536]               0\n","           Linear-61            [-1, 8, 8, 384]         590,208\n","          Dropout-62            [-1, 8, 8, 384]               0\n","  StochasticDepth-63            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-64            [-1, 8, 8, 384]               0\n","        LayerNorm-65            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-66            [-1, 8, 8, 384]               0\n","  StochasticDepth-67            [-1, 8, 8, 384]               0\n","        LayerNorm-68            [-1, 8, 8, 384]             768\n","           Linear-69           [-1, 8, 8, 1536]         591,360\n","             GELU-70           [-1, 8, 8, 1536]               0\n","          Dropout-71           [-1, 8, 8, 1536]               0\n","           Linear-72            [-1, 8, 8, 384]         590,208\n","          Dropout-73            [-1, 8, 8, 384]               0\n","  StochasticDepth-74            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-75            [-1, 8, 8, 384]               0\n","        LayerNorm-76            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-77            [-1, 8, 8, 384]               0\n","  StochasticDepth-78            [-1, 8, 8, 384]               0\n","        LayerNorm-79            [-1, 8, 8, 384]             768\n","           Linear-80           [-1, 8, 8, 1536]         591,360\n","             GELU-81           [-1, 8, 8, 1536]               0\n","          Dropout-82           [-1, 8, 8, 1536]               0\n","           Linear-83            [-1, 8, 8, 384]         590,208\n","          Dropout-84            [-1, 8, 8, 384]               0\n","  StochasticDepth-85            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-86            [-1, 8, 8, 384]               0\n","        LayerNorm-87            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-88            [-1, 8, 8, 384]               0\n","  StochasticDepth-89            [-1, 8, 8, 384]               0\n","        LayerNorm-90            [-1, 8, 8, 384]             768\n","           Linear-91           [-1, 8, 8, 1536]         591,360\n","             GELU-92           [-1, 8, 8, 1536]               0\n","          Dropout-93           [-1, 8, 8, 1536]               0\n","           Linear-94            [-1, 8, 8, 384]         590,208\n","          Dropout-95            [-1, 8, 8, 384]               0\n","  StochasticDepth-96            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-97            [-1, 8, 8, 384]               0\n","        LayerNorm-98            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-99            [-1, 8, 8, 384]               0\n"," StochasticDepth-100            [-1, 8, 8, 384]               0\n","       LayerNorm-101            [-1, 8, 8, 384]             768\n","          Linear-102           [-1, 8, 8, 1536]         591,360\n","            GELU-103           [-1, 8, 8, 1536]               0\n","         Dropout-104           [-1, 8, 8, 1536]               0\n","          Linear-105            [-1, 8, 8, 384]         590,208\n","         Dropout-106            [-1, 8, 8, 384]               0\n"," StochasticDepth-107            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-108            [-1, 8, 8, 384]               0\n","       LayerNorm-109            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-110            [-1, 8, 8, 384]               0\n"," StochasticDepth-111            [-1, 8, 8, 384]               0\n","       LayerNorm-112            [-1, 8, 8, 384]             768\n","          Linear-113           [-1, 8, 8, 1536]         591,360\n","            GELU-114           [-1, 8, 8, 1536]               0\n","         Dropout-115           [-1, 8, 8, 1536]               0\n","          Linear-116            [-1, 8, 8, 384]         590,208\n","         Dropout-117            [-1, 8, 8, 384]               0\n"," StochasticDepth-118            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-119            [-1, 8, 8, 384]               0\n","       LayerNorm-120           [-1, 4, 4, 1536]           3,072\n","          Linear-121            [-1, 4, 4, 768]       1,179,648\n","    PatchMerging-122            [-1, 4, 4, 768]               0\n","       LayerNorm-123            [-1, 4, 4, 768]           1,536\n","ShiftedWindowAttention-124            [-1, 4, 4, 768]               0\n"," StochasticDepth-125            [-1, 4, 4, 768]               0\n","       LayerNorm-126            [-1, 4, 4, 768]           1,536\n","          Linear-127           [-1, 4, 4, 3072]       2,362,368\n","            GELU-128           [-1, 4, 4, 3072]               0\n","         Dropout-129           [-1, 4, 4, 3072]               0\n","          Linear-130            [-1, 4, 4, 768]       2,360,064\n","         Dropout-131            [-1, 4, 4, 768]               0\n"," StochasticDepth-132            [-1, 4, 4, 768]               0\n","SwinTransformerBlock-133            [-1, 4, 4, 768]               0\n","       LayerNorm-134            [-1, 4, 4, 768]           1,536\n","ShiftedWindowAttention-135            [-1, 4, 4, 768]               0\n"," StochasticDepth-136            [-1, 4, 4, 768]               0\n","       LayerNorm-137            [-1, 4, 4, 768]           1,536\n","          Linear-138           [-1, 4, 4, 3072]       2,362,368\n","            GELU-139           [-1, 4, 4, 3072]               0\n","         Dropout-140           [-1, 4, 4, 3072]               0\n","          Linear-141            [-1, 4, 4, 768]       2,360,064\n","         Dropout-142            [-1, 4, 4, 768]               0\n"," StochasticDepth-143            [-1, 4, 4, 768]               0\n","SwinTransformerBlock-144            [-1, 4, 4, 768]               0\n","       LayerNorm-145            [-1, 4, 4, 768]           1,536\n","         Permute-146            [-1, 768, 4, 4]               0\n","AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n","         Flatten-148                  [-1, 768]               0\n","          Linear-149                 [-1, 1000]         769,000\n","================================================================\n","Total params: 19,621,192\n","Trainable params: 19,621,192\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.19\n","Forward/backward pass size (MB): 76.33\n","Params size (MB): 74.85\n","Estimated Total Size (MB): 151.37\n","----------------------------------------------------------------\n","None\n"]}]},{"cell_type":"code","source":["num_body_features = list(model_body.children())[-1].in_features"],"metadata":{"id":"pLh3fmb0wotQ","executionInfo":{"status":"ok","timestamp":1697910905891,"user_tz":-420,"elapsed":3,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":["### e. SwinT (Emotic weight)"],"metadata":{"id":"XZHxYd1OjEmG"}},{"cell_type":"code","source":["model_body = torch.load(\"/content/drive/MyDrive/VA-prediction/models/SwinT_EMOTIC.pth\", map_location=lambda storage, loc: storage)\n","print (summary(model_body, (3,128,128), device=\"cpu\"))\n","isSwinT = True"],"metadata":{"id":"gFZfWxtIjfMM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910906984,"user_tz":-420,"elapsed":1095,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"ea3bc407-5b4b-4d26-b2d7-c026ba0ce42e"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 96, 32, 32]           4,704\n","           Permute-2           [-1, 32, 32, 96]               0\n","         LayerNorm-3           [-1, 32, 32, 96]             192\n","         LayerNorm-4           [-1, 32, 32, 96]             192\n","ShiftedWindowAttention-5           [-1, 32, 32, 96]               0\n","   StochasticDepth-6           [-1, 32, 32, 96]               0\n","         LayerNorm-7           [-1, 32, 32, 96]             192\n","            Linear-8          [-1, 32, 32, 384]          37,248\n","              GELU-9          [-1, 32, 32, 384]               0\n","          Dropout-10          [-1, 32, 32, 384]               0\n","           Linear-11           [-1, 32, 32, 96]          36,960\n","          Dropout-12           [-1, 32, 32, 96]               0\n","  StochasticDepth-13           [-1, 32, 32, 96]               0\n","SwinTransformerBlock-14           [-1, 32, 32, 96]               0\n","        LayerNorm-15           [-1, 32, 32, 96]             192\n","ShiftedWindowAttention-16           [-1, 32, 32, 96]               0\n","  StochasticDepth-17           [-1, 32, 32, 96]               0\n","        LayerNorm-18           [-1, 32, 32, 96]             192\n","           Linear-19          [-1, 32, 32, 384]          37,248\n","             GELU-20          [-1, 32, 32, 384]               0\n","          Dropout-21          [-1, 32, 32, 384]               0\n","           Linear-22           [-1, 32, 32, 96]          36,960\n","          Dropout-23           [-1, 32, 32, 96]               0\n","  StochasticDepth-24           [-1, 32, 32, 96]               0\n","SwinTransformerBlock-25           [-1, 32, 32, 96]               0\n","        LayerNorm-26          [-1, 16, 16, 384]             768\n","           Linear-27          [-1, 16, 16, 192]          73,728\n","     PatchMerging-28          [-1, 16, 16, 192]               0\n","        LayerNorm-29          [-1, 16, 16, 192]             384\n","ShiftedWindowAttention-30          [-1, 16, 16, 192]               0\n","  StochasticDepth-31          [-1, 16, 16, 192]               0\n","        LayerNorm-32          [-1, 16, 16, 192]             384\n","           Linear-33          [-1, 16, 16, 768]         148,224\n","             GELU-34          [-1, 16, 16, 768]               0\n","          Dropout-35          [-1, 16, 16, 768]               0\n","           Linear-36          [-1, 16, 16, 192]         147,648\n","          Dropout-37          [-1, 16, 16, 192]               0\n","  StochasticDepth-38          [-1, 16, 16, 192]               0\n","SwinTransformerBlock-39          [-1, 16, 16, 192]               0\n","        LayerNorm-40          [-1, 16, 16, 192]             384\n","ShiftedWindowAttention-41          [-1, 16, 16, 192]               0\n","  StochasticDepth-42          [-1, 16, 16, 192]               0\n","        LayerNorm-43          [-1, 16, 16, 192]             384\n","           Linear-44          [-1, 16, 16, 768]         148,224\n","             GELU-45          [-1, 16, 16, 768]               0\n","          Dropout-46          [-1, 16, 16, 768]               0\n","           Linear-47          [-1, 16, 16, 192]         147,648\n","          Dropout-48          [-1, 16, 16, 192]               0\n","  StochasticDepth-49          [-1, 16, 16, 192]               0\n","SwinTransformerBlock-50          [-1, 16, 16, 192]               0\n","        LayerNorm-51            [-1, 8, 8, 768]           1,536\n","           Linear-52            [-1, 8, 8, 384]         294,912\n","     PatchMerging-53            [-1, 8, 8, 384]               0\n","        LayerNorm-54            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-55            [-1, 8, 8, 384]               0\n","  StochasticDepth-56            [-1, 8, 8, 384]               0\n","        LayerNorm-57            [-1, 8, 8, 384]             768\n","           Linear-58           [-1, 8, 8, 1536]         591,360\n","             GELU-59           [-1, 8, 8, 1536]               0\n","          Dropout-60           [-1, 8, 8, 1536]               0\n","           Linear-61            [-1, 8, 8, 384]         590,208\n","          Dropout-62            [-1, 8, 8, 384]               0\n","  StochasticDepth-63            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-64            [-1, 8, 8, 384]               0\n","        LayerNorm-65            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-66            [-1, 8, 8, 384]               0\n","  StochasticDepth-67            [-1, 8, 8, 384]               0\n","        LayerNorm-68            [-1, 8, 8, 384]             768\n","           Linear-69           [-1, 8, 8, 1536]         591,360\n","             GELU-70           [-1, 8, 8, 1536]               0\n","          Dropout-71           [-1, 8, 8, 1536]               0\n","           Linear-72            [-1, 8, 8, 384]         590,208\n","          Dropout-73            [-1, 8, 8, 384]               0\n","  StochasticDepth-74            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-75            [-1, 8, 8, 384]               0\n","        LayerNorm-76            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-77            [-1, 8, 8, 384]               0\n","  StochasticDepth-78            [-1, 8, 8, 384]               0\n","        LayerNorm-79            [-1, 8, 8, 384]             768\n","           Linear-80           [-1, 8, 8, 1536]         591,360\n","             GELU-81           [-1, 8, 8, 1536]               0\n","          Dropout-82           [-1, 8, 8, 1536]               0\n","           Linear-83            [-1, 8, 8, 384]         590,208\n","          Dropout-84            [-1, 8, 8, 384]               0\n","  StochasticDepth-85            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-86            [-1, 8, 8, 384]               0\n","        LayerNorm-87            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-88            [-1, 8, 8, 384]               0\n","  StochasticDepth-89            [-1, 8, 8, 384]               0\n","        LayerNorm-90            [-1, 8, 8, 384]             768\n","           Linear-91           [-1, 8, 8, 1536]         591,360\n","             GELU-92           [-1, 8, 8, 1536]               0\n","          Dropout-93           [-1, 8, 8, 1536]               0\n","           Linear-94            [-1, 8, 8, 384]         590,208\n","          Dropout-95            [-1, 8, 8, 384]               0\n","  StochasticDepth-96            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-97            [-1, 8, 8, 384]               0\n","        LayerNorm-98            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-99            [-1, 8, 8, 384]               0\n"," StochasticDepth-100            [-1, 8, 8, 384]               0\n","       LayerNorm-101            [-1, 8, 8, 384]             768\n","          Linear-102           [-1, 8, 8, 1536]         591,360\n","            GELU-103           [-1, 8, 8, 1536]               0\n","         Dropout-104           [-1, 8, 8, 1536]               0\n","          Linear-105            [-1, 8, 8, 384]         590,208\n","         Dropout-106            [-1, 8, 8, 384]               0\n"," StochasticDepth-107            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-108            [-1, 8, 8, 384]               0\n","       LayerNorm-109            [-1, 8, 8, 384]             768\n","ShiftedWindowAttention-110            [-1, 8, 8, 384]               0\n"," StochasticDepth-111            [-1, 8, 8, 384]               0\n","       LayerNorm-112            [-1, 8, 8, 384]             768\n","          Linear-113           [-1, 8, 8, 1536]         591,360\n","            GELU-114           [-1, 8, 8, 1536]               0\n","         Dropout-115           [-1, 8, 8, 1536]               0\n","          Linear-116            [-1, 8, 8, 384]         590,208\n","         Dropout-117            [-1, 8, 8, 384]               0\n"," StochasticDepth-118            [-1, 8, 8, 384]               0\n","SwinTransformerBlock-119            [-1, 8, 8, 384]               0\n","       LayerNorm-120           [-1, 4, 4, 1536]           3,072\n","          Linear-121            [-1, 4, 4, 768]       1,179,648\n","    PatchMerging-122            [-1, 4, 4, 768]               0\n","       LayerNorm-123            [-1, 4, 4, 768]           1,536\n","ShiftedWindowAttention-124            [-1, 4, 4, 768]               0\n"," StochasticDepth-125            [-1, 4, 4, 768]               0\n","       LayerNorm-126            [-1, 4, 4, 768]           1,536\n","          Linear-127           [-1, 4, 4, 3072]       2,362,368\n","            GELU-128           [-1, 4, 4, 3072]               0\n","         Dropout-129           [-1, 4, 4, 3072]               0\n","          Linear-130            [-1, 4, 4, 768]       2,360,064\n","         Dropout-131            [-1, 4, 4, 768]               0\n"," StochasticDepth-132            [-1, 4, 4, 768]               0\n","SwinTransformerBlock-133            [-1, 4, 4, 768]               0\n","       LayerNorm-134            [-1, 4, 4, 768]           1,536\n","ShiftedWindowAttention-135            [-1, 4, 4, 768]               0\n"," StochasticDepth-136            [-1, 4, 4, 768]               0\n","       LayerNorm-137            [-1, 4, 4, 768]           1,536\n","          Linear-138           [-1, 4, 4, 3072]       2,362,368\n","            GELU-139           [-1, 4, 4, 3072]               0\n","         Dropout-140           [-1, 4, 4, 3072]               0\n","          Linear-141            [-1, 4, 4, 768]       2,360,064\n","         Dropout-142            [-1, 4, 4, 768]               0\n"," StochasticDepth-143            [-1, 4, 4, 768]               0\n","SwinTransformerBlock-144            [-1, 4, 4, 768]               0\n","       LayerNorm-145            [-1, 4, 4, 768]           1,536\n","         Permute-146            [-1, 768, 4, 4]               0\n","AdaptiveAvgPool2d-147            [-1, 768, 1, 1]               0\n","         Flatten-148                  [-1, 768]               0\n","          Linear-149                    [-1, 6]           4,614\n","================================================================\n","Total params: 18,856,806\n","Trainable params: 4,614\n","Non-trainable params: 18,852,192\n","----------------------------------------------------------------\n","Input size (MB): 0.19\n","Forward/backward pass size (MB): 76.32\n","Params size (MB): 71.93\n","Estimated Total Size (MB): 148.44\n","----------------------------------------------------------------\n","None\n"]}]},{"cell_type":"code","source":["num_body_features = list(model_body.children())[-1].in_features"],"metadata":{"id":"oQyCQXxHwpS6","executionInfo":{"status":"ok","timestamp":1697910906984,"user_tz":-420,"elapsed":6,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":["## 2 . Context Branch:"],"metadata":{"id":"WRgaNN-k43K0"}},{"cell_type":"markdown","source":["### a. Resnet-18 (Places365 weight)"],"metadata":{"id":"Na07bDEI6tXj"}},{"cell_type":"code","source":["# Get Resnet18 model trained on places dataset.\n","store_path = \"./places\"\n","if not os.path.exists(store_path):\n","    os.mkdir(store_path)\n","\n","file_path = \"./places/resnet18_places365.pth.tar\"\n","if not os.path.exists(file_path):\n","    !wget http://places2.csail.mit.edu/models_places365/resnet18_places365.pth.tar -O ./places/resnet18_places365.pth.tar"],"metadata":{"id":"uZuctwQp47OB","executionInfo":{"status":"ok","timestamp":1697910906984,"user_tz":-420,"elapsed":5,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["# the architecture to use\n","arch = 'resnet18'\n","model_weight = os.path.join('./places', 'resnet18_places365.pth.tar')\n","\n","# create the network architecture\n","model = models.__dict__[arch](num_classes=365)\n","\n","#model_weight = '%s_places365.pth.tar' % arch\n","\n","checkpoint = torch.load(model_weight, map_location=lambda storage, loc: storage) # model trained in GPU could be deployed in CPU machine like this!\n","state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()} # the data parallel layer will add 'module' before each layer name\n","model.load_state_dict(state_dict)\n","model.eval()\n","\n","model.cpu()\n","torch.save(model.state_dict(), './places/resnet18_state_dict.pth')\n","print ('completed cell')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NE68e7nF6xtq","executionInfo":{"status":"ok","timestamp":1697910907644,"user_tz":-420,"elapsed":664,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"f800cd83-a61a-4770-8844-9dda1090a708"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"code","source":["model_path_places = './places'\n","\n","model_context = models.__dict__[arch](num_classes=365)\n","context_state_dict = torch.load(os.path.join(model_path_places, 'resnet18_state_dict.pth'))\n","model_context.load_state_dict(context_state_dict)\n","print (summary(model_context, (3,224,224), device=\"cpu\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U6O7y5I866ux","executionInfo":{"status":"ok","timestamp":1697910907645,"user_tz":-420,"elapsed":3,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"e2b2bd38-d6a4-4288-eee6-9a846a97977c"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","       BasicBlock-11           [-1, 64, 56, 56]               0\n","           Conv2d-12           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-13           [-1, 64, 56, 56]             128\n","             ReLU-14           [-1, 64, 56, 56]               0\n","           Conv2d-15           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-16           [-1, 64, 56, 56]             128\n","             ReLU-17           [-1, 64, 56, 56]               0\n","       BasicBlock-18           [-1, 64, 56, 56]               0\n","           Conv2d-19          [-1, 128, 28, 28]          73,728\n","      BatchNorm2d-20          [-1, 128, 28, 28]             256\n","             ReLU-21          [-1, 128, 28, 28]               0\n","           Conv2d-22          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-23          [-1, 128, 28, 28]             256\n","           Conv2d-24          [-1, 128, 28, 28]           8,192\n","      BatchNorm2d-25          [-1, 128, 28, 28]             256\n","             ReLU-26          [-1, 128, 28, 28]               0\n","       BasicBlock-27          [-1, 128, 28, 28]               0\n","           Conv2d-28          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-29          [-1, 128, 28, 28]             256\n","             ReLU-30          [-1, 128, 28, 28]               0\n","           Conv2d-31          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-32          [-1, 128, 28, 28]             256\n","             ReLU-33          [-1, 128, 28, 28]               0\n","       BasicBlock-34          [-1, 128, 28, 28]               0\n","           Conv2d-35          [-1, 256, 14, 14]         294,912\n","      BatchNorm2d-36          [-1, 256, 14, 14]             512\n","             ReLU-37          [-1, 256, 14, 14]               0\n","           Conv2d-38          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-39          [-1, 256, 14, 14]             512\n","           Conv2d-40          [-1, 256, 14, 14]          32,768\n","      BatchNorm2d-41          [-1, 256, 14, 14]             512\n","             ReLU-42          [-1, 256, 14, 14]               0\n","       BasicBlock-43          [-1, 256, 14, 14]               0\n","           Conv2d-44          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-45          [-1, 256, 14, 14]             512\n","             ReLU-46          [-1, 256, 14, 14]               0\n","           Conv2d-47          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-48          [-1, 256, 14, 14]             512\n","             ReLU-49          [-1, 256, 14, 14]               0\n","       BasicBlock-50          [-1, 256, 14, 14]               0\n","           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n","      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n","             ReLU-53            [-1, 512, 7, 7]               0\n","           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n","           Conv2d-56            [-1, 512, 7, 7]         131,072\n","      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n","             ReLU-58            [-1, 512, 7, 7]               0\n","       BasicBlock-59            [-1, 512, 7, 7]               0\n","           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n","             ReLU-62            [-1, 512, 7, 7]               0\n","           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n","      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n","             ReLU-65            [-1, 512, 7, 7]               0\n","       BasicBlock-66            [-1, 512, 7, 7]               0\n","AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n","           Linear-68                  [-1, 365]         187,245\n","================================================================\n","Total params: 11,363,757\n","Trainable params: 11,363,757\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 62.79\n","Params size (MB): 43.35\n","Estimated Total Size (MB): 106.71\n","----------------------------------------------------------------\n","None\n"]}]},{"cell_type":"code","source":["num_context_features = list(model_context.children())[-1].in_features"],"metadata":{"id":"Fc2NBN0QwsKR","executionInfo":{"status":"ok","timestamp":1697910907645,"user_tz":-420,"elapsed":3,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":["### b. Resnet-50 (Places365 weight)"],"metadata":{"id":"jW9owD416_92"}},{"cell_type":"code","source":["# Get Resnet50 model trained on places dataset\n","store_path = \"./places\"\n","if not os.path.exists(store_path):\n","    os.mkdir(store_path)\n","\n","file_path = \"./places/resnet50_places365.pth.tar\"\n","if not os.path.exists(file_path):\n","    !wget http://places2.csail.mit.edu/models_places365/resnet50_places365.pth.tar -O ./places/resnet50_places365.pth.tar"],"metadata":{"id":"-F0nw0wX7GqI","executionInfo":{"status":"ok","timestamp":1697910907645,"user_tz":-420,"elapsed":2,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","source":["# the architecture to use\n","arch50 = 'resnet50'\n","model_weight = os.path.join('./places', 'resnet50_places365.pth.tar')\n","\n","# create the network architecture\n","model = models.__dict__[arch50](num_classes=365)\n","\n","#model_weight = '%s_places365.pth.tar' % arch\n","\n","checkpoint = torch.load(model_weight, map_location=lambda storage, loc: storage) # model trained in GPU could be deployed in CPU machine like this!\n","state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()} # the data parallel layer will add 'module' before each layer name\n","model.load_state_dict(state_dict)\n","model.eval()\n","\n","model.cpu()\n","torch.save(model.state_dict(), './places/resnet50_state_dict.pth')\n","print ('completed cell')"],"metadata":{"id":"Tz9HaS3G7Iqu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910909390,"user_tz":-420,"elapsed":1747,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"0d517ce9-3371-4477-eba5-4ace7fb92e2b"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"code","source":["model_path_places = './places'\n","\n","model_context = models.__dict__[arch50](num_classes=365)\n","context_state_dict = torch.load(os.path.join(model_path_places, 'resnet50_state_dict.pth'))\n","model_context.load_state_dict(context_state_dict)\n","\n","print (summary(model_context, (3,224,224), device=\"cpu\"))"],"metadata":{"id":"fbeTq5Z87MLT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910911005,"user_tz":-420,"elapsed":1005,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"d87243fc-0a51-4c12-96ae-c31eee90b534"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n","            ReLU-143          [-1, 512, 14, 14]               0\n","          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n","            ReLU-146            [-1, 512, 7, 7]               0\n","          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n","          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n","            ReLU-151           [-1, 2048, 7, 7]               0\n","      Bottleneck-152           [-1, 2048, 7, 7]               0\n","          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n","            ReLU-155            [-1, 512, 7, 7]               0\n","          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n","            ReLU-158            [-1, 512, 7, 7]               0\n","          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n","            ReLU-161           [-1, 2048, 7, 7]               0\n","      Bottleneck-162           [-1, 2048, 7, 7]               0\n","          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n","            ReLU-165            [-1, 512, 7, 7]               0\n","          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n","            ReLU-168            [-1, 512, 7, 7]               0\n","          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n","            ReLU-171           [-1, 2048, 7, 7]               0\n","      Bottleneck-172           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","          Linear-174                  [-1, 365]         747,885\n","================================================================\n","Total params: 24,255,917\n","Trainable params: 24,255,917\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 286.55\n","Params size (MB): 92.53\n","Estimated Total Size (MB): 379.66\n","----------------------------------------------------------------\n","None\n"]}]},{"cell_type":"code","source":["num_context_features = list(model_context.children())[-1].in_features"],"metadata":{"id":"gR_rwDhXwwTh","executionInfo":{"status":"ok","timestamp":1697910911005,"user_tz":-420,"elapsed":6,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":["## 3 . Face Branch:\n","The key to predicting emotion in a human image is facial expression. we employ two pre-trained models on the FER-2013 dataset by [Shangeth](https://github.com/shangeth/Facial-Emotion-Recognition-PyTorch-ONNX) and\n","[Balmukund](https://www.kaggle.com/code/balmukund/fer-2013-pytorch-implementation?fbclid=IwAR3xaZrtY7-RDZiXHGcjf6ytJ5Nk4wMDxGhsQs0pg2R0ul7GNv7lgS3ePI8), denoted by S-FER and B-FER, respectively.\n"],"metadata":{"id":"B3sEJzsC46AU"}},{"cell_type":"markdown","metadata":{"id":"64NB2FNbr7Gy"},"source":["### a. S-FER"]},{"cell_type":"code","execution_count":111,"metadata":{"id":"NEy2A7Chi6Q_","executionInfo":{"status":"ok","timestamp":1697910911005,"user_tz":-420,"elapsed":6,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"outputs":[],"source":["face_model_path = \"/content/drive/MyDrive/VA-prediction/models/FER_trained_model.pt\""]},{"cell_type":"code","execution_count":112,"metadata":{"id":"OgH099-1jSyK","executionInfo":{"status":"ok","timestamp":1697910911005,"user_tz":-420,"elapsed":5,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","\n","class Face_Emotion_CNN(nn.Module):\n","  def __init__(self):\n","    super(Face_Emotion_CNN, self).__init__()\n","    self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n","    self.cnn2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n","    self.cnn3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n","    self.cnn4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n","    self.cnn5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n","    self.cnn6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n","    self.cnn7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3)\n","    self.relu = nn.ReLU()\n","    self.pool1 = nn.MaxPool2d(2, 1)\n","    self.pool2 = nn.MaxPool2d(2, 2)\n","    self.cnn1_bn = nn.BatchNorm2d(8)\n","    self.cnn2_bn = nn.BatchNorm2d(16)\n","    self.cnn3_bn = nn.BatchNorm2d(32)\n","    self.cnn4_bn = nn.BatchNorm2d(64)\n","    self.cnn5_bn = nn.BatchNorm2d(128)\n","    self.cnn6_bn = nn.BatchNorm2d(256)\n","    self.cnn7_bn = nn.BatchNorm2d(256)\n","    self.fc1 = nn.Linear(1024, 512)\n","    self.fc2 = nn.Linear(512, 256)\n","    self.fc3 = nn.Linear(256, 7)\n","    self.dropout = nn.Dropout(0.3)\n","    self.log_softmax = nn.LogSoftmax(dim=1)\n","\n","  def forward(self, x):\n","    x = self.relu(self.pool1(self.cnn1_bn(self.cnn1(x))))\n","    x = self.relu(self.pool1(self.cnn2_bn(self.dropout(self.cnn2(x)))))\n","    x = self.relu(self.pool1(self.cnn3_bn(self.cnn3(x))))\n","    x = self.relu(self.pool1(self.cnn4_bn(self.dropout(self.cnn4(x)))))\n","    x = self.relu(self.pool2(self.cnn5_bn(self.cnn5(x))))\n","    x = self.relu(self.pool2(self.cnn6_bn(self.dropout(self.cnn6(x)))))\n","    x = self.relu(self.pool2(self.cnn7_bn(self.dropout(self.cnn7(x)))))\n","\n","    x = x.view(x.size(0), -1)\n","\n","    x = self.relu(self.dropout(self.fc1(x)))\n","    x = self.relu(self.dropout(self.fc2(x)))\n","    x = self.log_softmax(self.fc3(x))\n","    return x\n","\n","  def count_parameters(self):\n","    return sum(p.numel() for p in self.parameters() if p.requires_grad)"]},{"cell_type":"code","execution_count":113,"metadata":{"id":"DtHvLP0vjYEw","executionInfo":{"status":"ok","timestamp":1697910911006,"user_tz":-420,"elapsed":6,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"outputs":[],"source":["def load_trained_model(model_path):\n","    model = Face_Emotion_CNN()\n","    model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage), strict=False)\n","    return model"]},{"cell_type":"code","execution_count":114,"metadata":{"id":"1nYpOWFCY5mX","executionInfo":{"status":"ok","timestamp":1697910911006,"user_tz":-420,"elapsed":6,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"outputs":[],"source":["model_face = load_trained_model(face_model_path)"]},{"cell_type":"code","execution_count":115,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1697910911006,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"},"user_tz":-420},"id":"Hu-ejjUZlfwY","outputId":"52224d77-2fe8-47a7-e313-5f36e3f071b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 46, 46]              80\n","       BatchNorm2d-2            [-1, 8, 46, 46]              16\n","         MaxPool2d-3            [-1, 8, 45, 45]               0\n","              ReLU-4            [-1, 8, 45, 45]               0\n","            Conv2d-5           [-1, 16, 43, 43]           1,168\n","           Dropout-6           [-1, 16, 43, 43]               0\n","       BatchNorm2d-7           [-1, 16, 43, 43]              32\n","         MaxPool2d-8           [-1, 16, 42, 42]               0\n","              ReLU-9           [-1, 16, 42, 42]               0\n","           Conv2d-10           [-1, 32, 40, 40]           4,640\n","      BatchNorm2d-11           [-1, 32, 40, 40]              64\n","        MaxPool2d-12           [-1, 32, 39, 39]               0\n","             ReLU-13           [-1, 32, 39, 39]               0\n","           Conv2d-14           [-1, 64, 37, 37]          18,496\n","          Dropout-15           [-1, 64, 37, 37]               0\n","      BatchNorm2d-16           [-1, 64, 37, 37]             128\n","        MaxPool2d-17           [-1, 64, 36, 36]               0\n","             ReLU-18           [-1, 64, 36, 36]               0\n","           Conv2d-19          [-1, 128, 34, 34]          73,856\n","      BatchNorm2d-20          [-1, 128, 34, 34]             256\n","        MaxPool2d-21          [-1, 128, 17, 17]               0\n","             ReLU-22          [-1, 128, 17, 17]               0\n","           Conv2d-23          [-1, 256, 15, 15]         295,168\n","          Dropout-24          [-1, 256, 15, 15]               0\n","      BatchNorm2d-25          [-1, 256, 15, 15]             512\n","        MaxPool2d-26            [-1, 256, 7, 7]               0\n","             ReLU-27            [-1, 256, 7, 7]               0\n","           Conv2d-28            [-1, 256, 5, 5]         590,080\n","          Dropout-29            [-1, 256, 5, 5]               0\n","      BatchNorm2d-30            [-1, 256, 5, 5]             512\n","        MaxPool2d-31            [-1, 256, 2, 2]               0\n","             ReLU-32            [-1, 256, 2, 2]               0\n","           Linear-33                  [-1, 512]         524,800\n","          Dropout-34                  [-1, 512]               0\n","             ReLU-35                  [-1, 512]               0\n","           Linear-36                  [-1, 256]         131,328\n","          Dropout-37                  [-1, 256]               0\n","             ReLU-38                  [-1, 256]               0\n","           Linear-39                    [-1, 7]           1,799\n","       LogSoftmax-40                    [-1, 7]               0\n","================================================================\n","Total params: 1,642,935\n","Trainable params: 1,642,935\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 10.92\n","Params size (MB): 6.27\n","Estimated Total Size (MB): 17.20\n","----------------------------------------------------------------\n","None\n"]}],"source":["print(summary(model_face, (1, 48,48), device=\"cpu\"))"]},{"cell_type":"code","execution_count":116,"metadata":{"id":"_5VggX-XlpGo","executionInfo":{"status":"ok","timestamp":1697910911006,"user_tz":-420,"elapsed":5,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"outputs":[],"source":["class Face_Emotion_CNN_new(nn.Module):\n","  def __init__(self):\n","    super(Face_Emotion_CNN_new, self).__init__()\n","    self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n","    self.cnn2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n","    self.cnn3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n","    self.cnn4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n","    self.cnn5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n","    self.cnn6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n","    self.cnn7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3)\n","    self.relu = nn.ReLU()\n","    self.pool1 = nn.MaxPool2d(2, 1)\n","    self.pool2 = nn.MaxPool2d(2, 2)\n","    self.cnn1_bn = nn.BatchNorm2d(8)\n","    self.cnn2_bn = nn.BatchNorm2d(16)\n","    self.cnn3_bn = nn.BatchNorm2d(32)\n","    self.cnn4_bn = nn.BatchNorm2d(64)\n","    self.cnn5_bn = nn.BatchNorm2d(128)\n","    self.cnn6_bn = nn.BatchNorm2d(256)\n","    self.cnn7_bn = nn.BatchNorm2d(256)\n","    self.fc1 = nn.Linear(1024, 512)\n","    self.fc2 = nn.Linear(512, 256)\n","    self.dropout = nn.Dropout(0.3)\n","\n","  def forward(self, x):\n","    x = self.relu(self.pool1(self.cnn1_bn(self.cnn1(x))))\n","    x = self.relu(self.pool1(self.cnn2_bn(self.dropout(self.cnn2(x)))))\n","    x = self.relu(self.pool1(self.cnn3_bn(self.cnn3(x))))\n","    x = self.relu(self.pool1(self.cnn4_bn(self.dropout(self.cnn4(x)))))\n","    x = self.relu(self.pool2(self.cnn5_bn(self.cnn5(x))))\n","    x = self.relu(self.pool2(self.cnn6_bn(self.dropout(self.cnn6(x)))))\n","    x = self.relu(self.pool2(self.cnn7_bn(self.dropout(self.cnn7(x)))))\n","\n","    x = x.view(x.size(0), -1)\n","\n","    x = self.relu(self.dropout(self.fc1(x)))\n","    x = self.fc2(x)\n","    return x\n","\n","  def count_parameters(self):\n","    return sum(p.numel() for p in self.parameters() if p.requires_grad)"]},{"cell_type":"code","execution_count":117,"metadata":{"id":"VTYPiX2li1s1","executionInfo":{"status":"ok","timestamp":1697910911006,"user_tz":-420,"elapsed":5,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"outputs":[],"source":["state_dict = model_face.state_dict()\n","del state_dict['fc3.weight']\n","del state_dict['fc3.bias']"]},{"cell_type":"code","execution_count":118,"metadata":{"id":"Iv_n-ClblX8H","executionInfo":{"status":"ok","timestamp":1697910911006,"user_tz":-420,"elapsed":5,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"outputs":[],"source":["model_face = Face_Emotion_CNN_new()"]},{"cell_type":"code","execution_count":119,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1697910911006,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"},"user_tz":-420},"id":"ptzfSZAMnOvh","outputId":"2ed6f722-46a1-404b-9ec1-6f4e9e1bfba1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":119}],"source":["model_face.load_state_dict(state_dict)"]},{"cell_type":"code","execution_count":120,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":479,"status":"ok","timestamp":1697910911482,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"},"user_tz":-420},"id":"kix2MSADrajH","outputId":"7916635f-2769-42b1-948b-97ccea2d6b53"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 46, 46]              80\n","       BatchNorm2d-2            [-1, 8, 46, 46]              16\n","         MaxPool2d-3            [-1, 8, 45, 45]               0\n","              ReLU-4            [-1, 8, 45, 45]               0\n","            Conv2d-5           [-1, 16, 43, 43]           1,168\n","           Dropout-6           [-1, 16, 43, 43]               0\n","       BatchNorm2d-7           [-1, 16, 43, 43]              32\n","         MaxPool2d-8           [-1, 16, 42, 42]               0\n","              ReLU-9           [-1, 16, 42, 42]               0\n","           Conv2d-10           [-1, 32, 40, 40]           4,640\n","      BatchNorm2d-11           [-1, 32, 40, 40]              64\n","        MaxPool2d-12           [-1, 32, 39, 39]               0\n","             ReLU-13           [-1, 32, 39, 39]               0\n","           Conv2d-14           [-1, 64, 37, 37]          18,496\n","          Dropout-15           [-1, 64, 37, 37]               0\n","      BatchNorm2d-16           [-1, 64, 37, 37]             128\n","        MaxPool2d-17           [-1, 64, 36, 36]               0\n","             ReLU-18           [-1, 64, 36, 36]               0\n","           Conv2d-19          [-1, 128, 34, 34]          73,856\n","      BatchNorm2d-20          [-1, 128, 34, 34]             256\n","        MaxPool2d-21          [-1, 128, 17, 17]               0\n","             ReLU-22          [-1, 128, 17, 17]               0\n","           Conv2d-23          [-1, 256, 15, 15]         295,168\n","          Dropout-24          [-1, 256, 15, 15]               0\n","      BatchNorm2d-25          [-1, 256, 15, 15]             512\n","        MaxPool2d-26            [-1, 256, 7, 7]               0\n","             ReLU-27            [-1, 256, 7, 7]               0\n","           Conv2d-28            [-1, 256, 5, 5]         590,080\n","          Dropout-29            [-1, 256, 5, 5]               0\n","      BatchNorm2d-30            [-1, 256, 5, 5]             512\n","        MaxPool2d-31            [-1, 256, 2, 2]               0\n","             ReLU-32            [-1, 256, 2, 2]               0\n","           Linear-33                  [-1, 512]         524,800\n","          Dropout-34                  [-1, 512]               0\n","             ReLU-35                  [-1, 512]               0\n","           Linear-36                  [-1, 256]         131,328\n","================================================================\n","Total params: 1,641,136\n","Trainable params: 1,641,136\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 10.92\n","Params size (MB): 6.26\n","Estimated Total Size (MB): 17.19\n","----------------------------------------------------------------\n","None\n"]}],"source":["print(summary(model_face, (1, 48,48), device=\"cpu\"))"]},{"cell_type":"code","source":["num_face_features = 256"],"metadata":{"id":"t_W9c1RbwyJr","executionInfo":{"status":"ok","timestamp":1697910911482,"user_tz":-420,"elapsed":3,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":121,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rVWB5vvjsDrG"},"source":["### b. B-FER"]},{"cell_type":"code","source":["isBFER = True"],"metadata":{"id":"1M_akG9NmHp_","executionInfo":{"status":"ok","timestamp":1697910911482,"user_tz":-420,"elapsed":3,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","execution_count":123,"metadata":{"id":"w6BSXEZUspA_","executionInfo":{"status":"ok","timestamp":1697910911483,"user_tz":-420,"elapsed":3,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self, dropout):\n","        super(Net, self).__init__()\n","        dropout_value = dropout\n","        # Input Block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            # nn.Dropout(dropout_value)\n","        )\n","\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            # nn.Dropout(dropout_value)\n","        )\n","\n","        # TRANSITION BLOCK 1\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 24 RF=7\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(128),\n","            # nn.Dropout(dropout_value)\n","        )\n","\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(256),\n","        )\n","\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(1, 1), padding=1 , bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(512),\n","            # nn.Dropout(dropout_value)\n","        )\n","\n","        # TRANSITION BLOCK 2\n","        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 12 RF=20\n","\n","        # CONVOLUTION BLOCK 2\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(1024),\n","            # nn.Dropout(dropout_value)\n","        )\n","\n","        self.convblock7 = nn.Sequential(\n","            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(1024),\n","            # nn.Dropout(dropout_value)\n","        )\n","\n","        # TRANSITION BLOCK 3\n","        self.pool3 = nn.MaxPool2d(2, 2) # output_size =6 RF=32\n","\n","        self.convblock8 = nn.Sequential(\n","             nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=(3, 3), padding=1, bias=False),\n","             nn.ReLU(),\n","             nn.BatchNorm2d(512),\n","             # nn.Dropout(dropout_value)\n","         )\n","\n","        self.convblock9 = nn.Sequential(\n","             nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3, 3), padding=0, bias=False),\n","             nn.ReLU(),\n","             nn.BatchNorm2d(256),\n","             # nn.Dropout(dropout_value)\n","         )\n","        # self.pool2 = nn.MaxPool2d(2, 2) # output_size = 2\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=4)\n","        )\n","        self.convblock10 = nn.Sequential(\n","            nn.Conv2d(in_channels=256, out_channels=7, kernel_size=(1, 1), padding=0, bias=False)\n","        )\n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.pool1(x)\n","        x = self.convblock3(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","        x = self.pool2(x)\n","        x = self.convblock6(x)\n","        x = self.convblock7(x)\n","        x = self.pool3(x)\n","        x = self.convblock8(x)\n","        x = self.convblock9(x)\n","        x = self.gap(x)\n","        x = self.convblock10(x)\n","        x = x.view(-1, 7)\n","        return F.log_softmax(x, dim=-1)"]},{"cell_type":"code","execution_count":124,"metadata":{"id":"S6U_ZCGFsJzb","executionInfo":{"status":"ok","timestamp":1697910911483,"user_tz":-420,"elapsed":3,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"outputs":[],"source":["model_face = Net(1.0)"]},{"cell_type":"code","execution_count":125,"metadata":{"id":"Met5dkWRsJoj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910912041,"user_tz":-420,"elapsed":561,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"8420ecd4-544e-4cd9-c209-7ea342144b17"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":125}],"source":["model_face.load_state_dict(torch.load(\"/content/drive/MyDrive/VA-prediction/models/FER_2013_Kaggle.pth\", map_location=lambda storage, loc: storage), strict=False)"]},{"cell_type":"code","execution_count":126,"metadata":{"id":"sqod4vYRtQzO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910912042,"user_tz":-420,"elapsed":5,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"656ec859-d781-4912-e731-ef36fca15d60"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 48, 48]             864\n","              ReLU-2           [-1, 32, 48, 48]               0\n","       BatchNorm2d-3           [-1, 32, 48, 48]              64\n","            Conv2d-4           [-1, 64, 48, 48]          18,432\n","              ReLU-5           [-1, 64, 48, 48]               0\n","       BatchNorm2d-6           [-1, 64, 48, 48]             128\n","         MaxPool2d-7           [-1, 64, 24, 24]               0\n","            Conv2d-8          [-1, 128, 24, 24]          73,728\n","              ReLU-9          [-1, 128, 24, 24]               0\n","      BatchNorm2d-10          [-1, 128, 24, 24]             256\n","           Conv2d-11          [-1, 256, 24, 24]         294,912\n","             ReLU-12          [-1, 256, 24, 24]               0\n","      BatchNorm2d-13          [-1, 256, 24, 24]             512\n","           Conv2d-14          [-1, 512, 26, 26]         131,072\n","             ReLU-15          [-1, 512, 26, 26]               0\n","      BatchNorm2d-16          [-1, 512, 26, 26]           1,024\n","        MaxPool2d-17          [-1, 512, 13, 13]               0\n","           Conv2d-18         [-1, 1024, 13, 13]       4,718,592\n","             ReLU-19         [-1, 1024, 13, 13]               0\n","      BatchNorm2d-20         [-1, 1024, 13, 13]           2,048\n","           Conv2d-21         [-1, 1024, 13, 13]       9,437,184\n","             ReLU-22         [-1, 1024, 13, 13]               0\n","      BatchNorm2d-23         [-1, 1024, 13, 13]           2,048\n","        MaxPool2d-24           [-1, 1024, 6, 6]               0\n","           Conv2d-25            [-1, 512, 6, 6]       4,718,592\n","             ReLU-26            [-1, 512, 6, 6]               0\n","      BatchNorm2d-27            [-1, 512, 6, 6]           1,024\n","           Conv2d-28            [-1, 256, 4, 4]       1,179,648\n","             ReLU-29            [-1, 256, 4, 4]               0\n","      BatchNorm2d-30            [-1, 256, 4, 4]             512\n","        AvgPool2d-31            [-1, 256, 1, 1]               0\n","           Conv2d-32              [-1, 7, 1, 1]           1,792\n","================================================================\n","Total params: 20,582,432\n","Trainable params: 20,582,432\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.03\n","Forward/backward pass size (MB): 27.71\n","Params size (MB): 78.52\n","Estimated Total Size (MB): 106.25\n","----------------------------------------------------------------\n","None\n"]}],"source":["print(summary(model_face, (3, 48,48), device=\"cpu\"))"]},{"cell_type":"code","execution_count":127,"metadata":{"id":"TA1SLRCwtdjV","executionInfo":{"status":"ok","timestamp":1697910912042,"user_tz":-420,"elapsed":3,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"outputs":[],"source":["model_face = nn.Sequential(*(list(model_face.children())[:-1]))"]},{"cell_type":"code","execution_count":128,"metadata":{"id":"QuHhoYddtjyx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910912906,"user_tz":-420,"elapsed":867,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"3e4010b2-2834-45d6-c2fa-7a9a3ce14e95"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 48, 48]             864\n","              ReLU-2           [-1, 32, 48, 48]               0\n","       BatchNorm2d-3           [-1, 32, 48, 48]              64\n","            Conv2d-4           [-1, 64, 48, 48]          18,432\n","              ReLU-5           [-1, 64, 48, 48]               0\n","       BatchNorm2d-6           [-1, 64, 48, 48]             128\n","         MaxPool2d-7           [-1, 64, 24, 24]               0\n","            Conv2d-8          [-1, 128, 24, 24]          73,728\n","              ReLU-9          [-1, 128, 24, 24]               0\n","      BatchNorm2d-10          [-1, 128, 24, 24]             256\n","           Conv2d-11          [-1, 256, 24, 24]         294,912\n","             ReLU-12          [-1, 256, 24, 24]               0\n","      BatchNorm2d-13          [-1, 256, 24, 24]             512\n","           Conv2d-14          [-1, 512, 26, 26]         131,072\n","             ReLU-15          [-1, 512, 26, 26]               0\n","      BatchNorm2d-16          [-1, 512, 26, 26]           1,024\n","        MaxPool2d-17          [-1, 512, 13, 13]               0\n","           Conv2d-18         [-1, 1024, 13, 13]       4,718,592\n","             ReLU-19         [-1, 1024, 13, 13]               0\n","      BatchNorm2d-20         [-1, 1024, 13, 13]           2,048\n","           Conv2d-21         [-1, 1024, 13, 13]       9,437,184\n","             ReLU-22         [-1, 1024, 13, 13]               0\n","      BatchNorm2d-23         [-1, 1024, 13, 13]           2,048\n","        MaxPool2d-24           [-1, 1024, 6, 6]               0\n","           Conv2d-25            [-1, 512, 6, 6]       4,718,592\n","             ReLU-26            [-1, 512, 6, 6]               0\n","      BatchNorm2d-27            [-1, 512, 6, 6]           1,024\n","           Conv2d-28            [-1, 256, 4, 4]       1,179,648\n","             ReLU-29            [-1, 256, 4, 4]               0\n","      BatchNorm2d-30            [-1, 256, 4, 4]             512\n","        AvgPool2d-31            [-1, 256, 1, 1]               0\n","================================================================\n","Total params: 20,580,640\n","Trainable params: 20,580,640\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.03\n","Forward/backward pass size (MB): 27.71\n","Params size (MB): 78.51\n","Estimated Total Size (MB): 106.24\n","----------------------------------------------------------------\n","None\n"]}],"source":["print(summary(model_face, (3, 48,48), device=\"cpu\"))"]},{"cell_type":"code","source":["num_face_features = 256"],"metadata":{"id":"RrcuvpF1w6GL","executionInfo":{"status":"ok","timestamp":1697910912906,"user_tz":-420,"elapsed":6,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":129,"outputs":[]},{"cell_type":"markdown","source":["# IV. Dataset:\n","\n","In this paper, we use the EMOTIC dataset - a database of images of people in real environments, annotated with their apparent emotions. The images are annotated with an extended list of 26 emotion categories combined with the three common continuous dimensions Valence, Arousal and Dominance.\n","\n","It consists of approximately 23,500 images collected from websites, social media, and other public datasets. Each image contains one or many people, and each person is labeled with Gender (Male or Female), Age (adult, kid, or teenager), and VAD (valence-arousal-dominance) values ranging from 0 to 10 and labeled to some of 26 discrete emotion categories. The 26 discrete emotion categories include: *Peace, Affection, Esteem, Anticipation, Engagement, Confidence, Happiness, Pleasure, Excitement, Surprise, Sympathy, Doubt/Confusion, Disconnection, Fatigue, Embarrassment, Yearning, Disapproval, Aversion, Annoyance, Anger, Sensitivity, Sadness, Disquietment, Fear, Pain, Suffering.*"],"metadata":{"id":"fRVTvEUAM0_h"}},{"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/BaoNinh2808/Server-Client/main/Dataset_Sample.png\" width=\"50%\" height=\"50%\"/>"],"metadata":{"id":"izyCyxuTznWQ"}},{"cell_type":"markdown","source":["## 1 . Data Normalization:"],"metadata":{"id":"UqQsZv0u2xej"}},{"cell_type":"code","source":["context_mean = [0.4690646, 0.4407227, 0.40508908]\n","context_std = [0.2514227, 0.24312855, 0.24266963]\n","\n","body_mean = [0.43832874, 0.3964344, 0.3706214]\n","body_std = [0.24784276, 0.23621225, 0.2323653]\n","\n","if (isSwinT):\n","  body_mean = [0.485, 0.456, 0.406]\n","  body_std = [0.229, 0.224, 0.225]\n","\n","face_mean = [0.507395516207, 0.507395516207, 0.507395516207]\n","face_std = [0.255128989415, 0.255128989415, 0.255128989415]\n","\n","context_norm = [context_mean, context_std]\n","body_norm = [body_mean, body_std]\n","face_norm = [face_mean, face_std]\n","\n","train_transform = transforms.Compose([transforms.ToPILImage(),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n","                                      transforms.ToTensor()])\n","\n","test_transform = transforms.Compose([transforms.ToPILImage(),\n","                                     transforms.ToTensor()])\n","\n","face_train_transform = transforms.Compose([transforms.ToPILImage(),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n","                                      transforms.ToTensor()])\n","\n","face_test_transform = transforms.Compose([transforms.ToPILImage(),\n","                                     transforms.ToTensor()])\n","\n","if (isSwinT):\n","    train_transform = transforms.Compose([transforms.ToPILImage(),\n","                                      transforms.Resize(size=[232], interpolation=transforms.InterpolationMode.BICUBIC),\n","                                      transforms.CenterCrop(size=[224]),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n","                                      transforms.ToTensor()])\n","\n","\n","    test_transform = transforms.Compose([transforms.ToPILImage(),\n","                                     transforms.Resize(size=[232], interpolation=transforms.InterpolationMode.BICUBIC),\n","                                      transforms.CenterCrop(size=[224]),\n","                                     transforms.ToTensor()])"],"metadata":{"id":"wt0PrScX2w4H","executionInfo":{"status":"ok","timestamp":1697909815295,"user_tz":-420,"elapsed":17,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["## 2 . Create Class for Preprocessing Data:"],"metadata":{"id":"DCkTATsr2Csg"}},{"cell_type":"code","source":["class Emotic_PreDataset(Dataset):\n","  ''' Custom Emotic dataset class. Use preprocessed data stored in npy files. '''\n","  def __init__(self, x_context, x_body, x_face, y_cat, y_cont, context_transform, body_transform, face_transform, context_norm, body_norm, face_norm):\n","    super(Emotic_PreDataset,self).__init__()\n","    self.x_context = x_context\n","    self.x_body = x_body\n","    self.x_face = x_face\n","    self.y_cat = y_cat\n","    self.y_cont = y_cont\n","    self.context_transform = context_transform\n","    self.body_transform = body_transform\n","    self.face_transform = face_transform\n","    self.context_norm = transforms.Normalize(context_norm[0], context_norm[1])  # Normalizing the context image with context mean and context std\n","    self.body_norm = transforms.Normalize(body_norm[0], body_norm[1])           # Normalizing the body image with body mean and body std\n","    self.face_norm = transforms.Normalize(face_norm[0], face_norm[1])           # Normalizing the face image with face mean and face std\n","  def __len__(self):\n","    return len(self.y_cont)\n","\n","  def __getitem__(self, index):\n","    image_context = self.x_context[index]\n","    image_body = self.x_body[index]\n","    image_face = self.x_face[index]\n","    cat_label = self.y_cat[index]\n","    cont_label = self.y_cont[index]\n","    # , torch.tensor(cat_label, dtype=torch.float32)\n","    return self.context_norm(self.context_transform(image_context)), self.body_norm(self.body_transform(image_body)), self.face_norm(self.face_transform(image_face)), torch.tensor(cat_label, dtype=torch.float32),  torch.tensor(cont_label, dtype=torch.float32)/10.0\n","\n","print ('completed cell')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UG3hFf5B2H02","executionInfo":{"status":"ok","timestamp":1697909815295,"user_tz":-420,"elapsed":16,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"50977d47-903c-4f4f-9225-11a6b6f3e305"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"markdown","source":["## 3 . Preprocess and Load Data:"],"metadata":{"id":"UKjZvzwu2IYW"}},{"cell_type":"code","source":["# # Change data_src variable as per your drive\n","data_src = '/content/drive/MyDrive/VA-prediction/dataset'\n","\n","#train\n","train_context = np.load(os.path.join(data_src,'pre', 'train_context_arr.npy'))\n","train_body = np.load(os.path.join(data_src,'pre','train_body_arr.npy'))\n","\n","train_cat = np.load(os.path.join(data_src,'pre','train_cat_arr.npy'))\n","train_cont = np.load(os.path.join(data_src,'pre','train_cont_arr.npy'))\n","\n","\n","#val\n","val_context = np.load(os.path.join(data_src,'pre','val_context_arr.npy'))\n","val_body = np.load(os.path.join(data_src,'pre','val_body_arr.npy'))\n","\n","val_cat = np.load(os.path.join(data_src,'pre','val_cat_arr.npy'))\n","val_cont = np.load(os.path.join(data_src,'pre','val_cont_arr.npy'))\n","\n","\n","#test\n","test_context = np.load(os.path.join(data_src,'pre','test_context_arr.npy'))\n","test_body = np.load(os.path.join(data_src,'pre','test_body_arr.npy'))\\\n","\n","test_cat = np.load(os.path.join(data_src,'pre','test_cat_arr.npy'))\n","test_cont = np.load(os.path.join(data_src,'pre','test_cont_arr.npy'))\n","\n","#Face data\n","train_face =  np.stack((np.load(os.path.join(data_src,'pre','train_face_arr.npy')),) * 3, axis=-1)\n","val_face = np.stack((np.load(os.path.join(data_src,'pre','val_face_arr.npy')),) * 3, axis=-1)\n","test_face = np.stack((np.load(os.path.join(data_src,'pre','test_face_arr.npy')),) * 3, axis=-1)\n","\n","# Categorical emotion classes\n","cat = ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion', 'Confidence', 'Disapproval', 'Disconnection',\n","       'Disquietment', 'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem', 'Excitement', 'Fatigue', 'Fear',\n","       'Happiness', 'Pain', 'Peace', 'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise', 'Sympathy', 'Yearning']\n","\n","cat2ind = {}\n","ind2cat = {}\n","for idx, emotion in enumerate(cat):\n","  cat2ind[emotion] = idx\n","  ind2cat[idx] = emotion\n","\n","print ('train ', 'context ', train_context.shape, 'body', train_body.shape, 'cat ', train_cat.shape, 'cont', train_cont.shape)\n","print ('val ', 'context ', val_context.shape, 'body', val_body.shape, 'cat ', val_cat.shape, 'cont', val_cont.shape)\n","print ('test ', 'context ', test_context.shape, 'body', test_body.shape, 'cat ', test_cat.shape, 'cont', test_cont.shape)\n","print ('completed cell')"],"metadata":{"id":"nabGochbOhoP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697909969346,"user_tz":-420,"elapsed":154065,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"6e0abb6f-9492-45d4-871e-64d85366465b"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["train  context  (23266, 224, 224, 3) body (23266, 128, 128, 3) cat  (23266, 26) cont (23266, 3)\n","val  context  (3315, 224, 224, 3) body (3315, 128, 128, 3) cat  (3315, 26) cont (3315, 3)\n","test  context  (7203, 224, 224, 3) body (7203, 128, 128, 3) cat  (7203, 26) cont (7203, 3)\n","completed cell\n"]}]},{"cell_type":"code","source":["batch_size = 26\n","\n","train_dataset = Emotic_PreDataset(train_context, train_body, train_face, train_cat, train_cont, \\\n","                                  train_transform, train_transform, face_train_transform, context_norm, body_norm, face_norm)\n","val_dataset = Emotic_PreDataset(val_context, val_body, val_face, val_cat, val_cont, \\\n","                                train_transform, train_transform, face_train_transform, context_norm, body_norm, face_norm)\n","test_dataset = Emotic_PreDataset(test_context, test_body, test_face, test_cat, test_cont, \\\n","                                 test_transform, test_transform, face_test_transform, context_norm, body_norm, face_norm)\n","\n","train_loader = DataLoader(train_dataset, batch_size, shuffle=True, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n","\n","print ('train loader ', len(train_loader), 'val loader ', len(val_loader), 'test', len(test_loader))\n","print ('completed cell')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4XX-8np2LEc","executionInfo":{"status":"ok","timestamp":1697909969347,"user_tz":-420,"elapsed":7,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"c0576647-89b9-4f3e-e083-4497ce8c2b91"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["train loader  894 val loader  128 test 278\n","completed cell\n"]}]},{"cell_type":"markdown","source":["# IV. Loss Function & Evaluate Metric:"],"metadata":{"id":"m3qa_SsH_1ao"}},{"cell_type":"markdown","source":["## 1 . Loss Function:"],"metadata":{"id":"frTQfdMb_7Jx"}},{"cell_type":"code","source":["class DiscreteLoss(nn.Module):\n","  ''' Class to measure loss between categorical emotion predictions and labels.'''\n","  def __init__(self, weight_type='mean', device=torch.device('cpu')):\n","    super(DiscreteLoss, self).__init__()\n","    self.weight_type = weight_type\n","    self.device = device\n","    if self.weight_type == 'mean':\n","      self.weights = torch.ones((1,26))/26.0\n","      self.weights = self.weights.to(self.device)\n","    elif self.weight_type == 'static':\n","      self.weights = torch.FloatTensor([0.1435, 0.1870, 0.1692, 0.1165, 0.1949, 0.1204, 0.1728, 0.1372, 0.1620,\n","         0.1540, 0.1987, 0.1057, 0.1482, 0.1192, 0.1590, 0.1929, 0.1158, 0.1907,\n","         0.1345, 0.1307, 0.1665, 0.1698, 0.1797, 0.1657, 0.1520, 0.1537]).unsqueeze(0)\n","      self.weights = self.weights.to(self.device)\n","\n","  def forward(self, pred, target):\n","    if self.weight_type == 'dynamic':\n","      self.weights = self.prepare_dynamic_weights(target)\n","      self.weights = self.weights.to(self.device)\n","    loss = (((pred - target)**2) * self.weights)\n","    return loss.sum()\n","\n","  def prepare_dynamic_weights(self, target):\n","    target_stats = torch.sum(target, dim=0).float().unsqueeze(dim=0).cpu()\n","    weights = torch.zeros((1,26))\n","    weights[target_stats != 0 ] = 1.0/torch.log(target_stats[target_stats != 0].data + 1.2)\n","    weights[target_stats == 0] = 0.0001\n","    return weights\n","\n","\n","class ContinuousLoss_L2(nn.Module):\n","  ''' Class to measure loss between continuous emotion dimension predictions and labels. Using l2 loss as base. '''\n","  def __init__(self, margin=1):\n","    super(ContinuousLoss_L2, self).__init__()\n","    self.margin = margin\n","\n","  def forward(self, pred, target):\n","    labs = torch.abs(pred - target)\n","    loss = labs ** 2\n","    loss[ (labs < self.margin) ] = 0.0\n","    return loss.sum()\n","\n","\n","class ContinuousLoss_SL1(nn.Module):\n","  ''' Class to measure loss between continuous emotion dimension predictions and labels. Using smooth l1 loss as base. '''\n","  def __init__(self, margin=1):\n","    super(ContinuousLoss_SL1, self).__init__()\n","    self.margin = margin\n","\n","  def forward(self, pred, target):\n","    labs = torch.abs(pred - target)\n","    loss = 0.5 * (labs ** 2)\n","    loss[ (labs > self.margin) ] = labs[ (labs > self.margin) ] - 0.5\n","    return loss.sum()\n","\n","print ('completed cell')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bd7pwOJu-pBd","executionInfo":{"status":"ok","timestamp":1697909969347,"user_tz":-420,"elapsed":4,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"81999f03-a1dd-4374-d5e9-7963801b6117"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"markdown","source":["## 2 . Evaluate Metric:"],"metadata":{"id":"M6cv4IyH_9_c"}},{"cell_type":"code","source":["def test_scikit_ap(cat_preds, cat_labels):\n","  ap = np.zeros(26, dtype=np.float32)\n","  for i in range(26):\n","    ap[i] = average_precision_score(cat_labels[i, :], cat_preds[i, :])\n","  print ('ap', ap, ap.shape, ap.mean())\n","  return ap.mean()\n","\n","\n","def test_emotic_vad(cont_preds, cont_labels):\n","  vad = np.zeros(3, dtype=np.float32)\n","  for i in range(3):\n","    vad[i] = np.mean(np.abs(cont_preds[i, :] - cont_labels[i, :]))\n","  print ('vad', vad, vad.shape, vad.mean())\n","  return vad.mean()\n","\n","\n","def get_thresholds(cat_preds, cat_labels):\n","  thresholds = np.zeros(26, dtype=np.float32)\n","  for i in range(26):\n","    p, r, t = precision_recall_curve(cat_labels[i, :], cat_preds[i, :])\n","    for k in range(len(p)):\n","      if p[k] == r[k]:\n","        thresholds[i] = t[k]\n","        break\n","  np.save('./thresholds.npy', thresholds)\n","  return thresholds\n","\n","print ('completed cell')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNbGurZw8uLd","executionInfo":{"status":"ok","timestamp":1697909970403,"user_tz":-420,"elapsed":1059,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"fefd3873-b44a-419b-8a1a-9837aedb66ae"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"markdown","source":["# VI. Model + Optimizer"],"metadata":{"id":"ukfiUQKz1pKX"}},{"cell_type":"markdown","source":["Continue, define type of our experiment. If you want to predict Dicrete Emotions, let set **'isVADPrediction = False'**. Else if you want to predict VAD value, let set **'isVADPrediction = True'**"],"metadata":{"id":"hbbOJqwe6p_j"}},{"cell_type":"code","source":["#determine Prediction type - Categorizes Prediction/VAD Prediction\n","isVADPrediction = False"],"metadata":{"id":"utZHlxIwO0GQ","executionInfo":{"status":"ok","timestamp":1697910757656,"user_tz":-420,"elapsed":475,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["class Fusion(nn.Module):\n","  ''' Fusion Model'''\n","  def __init__(self, num_context_features, num_body_features, num_face_features):\n","    super(Fusion,self).__init__()\n","    self.num_context_features = num_context_features\n","    self.num_body_features = num_body_features\n","    self.num_face_features = num_face_features\n","    self.fc1 = nn.Linear((self.num_context_features + self.num_body_features + self.num_face_features), 256)\n","    self.bn1 = nn.BatchNorm1d(256)\n","    self.d1 = nn.Dropout(p=0.5)\n","    self.fc_cat = nn.Linear(256, 26)\n","    self.fc_cont = nn.Linear(256, 3)\n","    self.relu = nn.ReLU()\n","\n","\n","  def forward(self, x_context, x_body, x_face):\n","    context_features = x_context.view(-1, self.num_context_features)\n","    body_features = x_body.view(-1, self.num_body_features)\n","    face_features = x_face.view(-1, self.num_face_features)\n","    fuse_features = torch.cat((context_features, body_features, face_features), 1)\n","    fuse_out = self.fc1(fuse_features)\n","    fuse_out = self.bn1(fuse_out)\n","    fuse_out = self.relu(fuse_out)\n","    fuse_out = self.d1(fuse_out)\n","    cat_out = self.fc_cat(fuse_out)\n","    cont_out = self.fc_cont(fuse_out)\n","    if (isVADPrediction == False):\n","        return cat_out\n","    return cont_out\n","\n","print ('completed cell')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cCh0gv66-hud","executionInfo":{"status":"ok","timestamp":1697910762844,"user_tz":-420,"elapsed":2,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"039aba9f-96f9-4bb4-c69f-9282c759bb65"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"code","execution_count":130,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1697910912906,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"},"user_tz":-420},"id":"I6-3FTclWAGh","outputId":"6fc489d9-7fbe-43bd-96ec-df8265ca05be"},"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}],"source":["fusion_model = Fusion(num_context_features, num_body_features, num_face_features)\n","model_context = nn.Sequential(*(list(model_context.children())[:-1]))\n","model_body = nn.Sequential(*(list(model_body.children())[:-1]))\n","model_face = model_face\n","\n","for param in fusion_model.parameters():\n","  param.requires_grad = True\n","for param in model_context.parameters():\n","  param.requires_grad = False\n","for param in model_body.parameters():\n","  param.requires_grad = False\n","for param in model_face.parameters():\n","  param.requires_grad = False\n","print ('completed cell')"]},{"cell_type":"markdown","source":["Let’s first define our device as the first visible cuda device if we have CUDA available:"],"metadata":{"id":"aO-EmKL-4tzr"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"4ESNyf_i42NC","executionInfo":{"status":"ok","timestamp":1697910913551,"user_tz":-420,"elapsed":2,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":131,"outputs":[]},{"cell_type":"code","execution_count":132,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1697910914106,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"},"user_tz":-420},"id":"oRgM1Lt2kpzB","outputId":"c48143ba-d2eb-4f5b-fd8b-0dc238592a4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}],"source":["# Define relevant variables\n","learning_rate = 0.001\n","weight_decay = 5e-4\n","step_size = 7\n","gamma = 0.1\n","\n","opt = optim.Adam((list(fusion_model.parameters()) + list(model_context.parameters()) + \\\n","                  list(model_body.parameters()) + list(model_face.parameters())), lr=learning_rate, weight_decay=weight_decay)\n","\n","scheduler = StepLR(opt, step_size=7, gamma=gamma)\n","\n","#Chose loss function for Discrete Emotion Prediction Trainning and Continous Emotion Prediction trainning\n","disc_loss = DiscreteLoss('dynamic', device)\n","cont_loss_L2 = ContinuousLoss_L2()\n","\n","print ('completed cell')"]},{"cell_type":"markdown","source":["# VII. Trainning + Testing Functions:"],"metadata":{"id":"78NEK3P-8rjx"}},{"cell_type":"markdown","source":["**Discrete Emotion Prediction:**"],"metadata":{"id":"8erWPRPp0fJk"}},{"cell_type":"code","source":["def test_disc(models, device, data_loader, num_images):\n","    model_context, model_body, model_face, fusion_model = models\n","    cat_preds = np.zeros((num_images, 26))\n","    cat_labels = np.zeros((num_images, 26))\n","\n","    with torch.no_grad():\n","        model_context.to(device)\n","        model_body.to(device)\n","        model_face.to(device)\n","        fusion_model.to(device)\n","        model_context.eval()\n","        model_body.eval()\n","        model_face.eval()\n","        fusion_model.eval()\n","\n","        indx = 0\n","        print ('starting testing')\n","        for images_context, images_body, images_face, labels_cat, labels_cont in iter(data_loader):\n","            images_context = images_context.to(device)\n","            images_body = images_body.to(device)\n","            images_face = images_face.to(device)\n","            if (isBFER == False):\n","                images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n","\n","            labels_cat = labels_cat.to(device)\n","            labels_cont = labels_cont.to(device)\n","\n","\n","            pred_context = model_context(images_context)\n","            pred_body = model_body(images_body)\n","            pred_face = model_face(images_face)\n","            pred_cat = fusion_model(pred_context, pred_body, pred_face)\n","\n","            cat_preds[ indx : (indx + pred_cat.shape[0]), :] = pred_cat.to(\"cpu\").data.numpy()\n","            cat_labels[ indx : (indx + labels_cat.shape[0]), :] = labels_cat.to(\"cpu\").data.numpy()\n","            indx = indx + pred_cat.shape[0]\n","\n","    cat_preds = cat_preds.transpose()\n","    cat_labels = cat_labels.transpose()\n","    print ('completed testing')\n","    ap_mean = test_scikit_ap(cat_preds, cat_labels)\n","    return ap_mean\n","\n","print ('completed cell')"],"metadata":{"id":"l3vBcqbDyHgZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910544926,"user_tz":-420,"elapsed":9,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"3920cf66-fba8-4cbd-d8b9-2a09b883d1e6"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"code","source":["def train_disc(epochs, model_path, opt, scheduler, models, disc_loss, cont_loss, cat_loss_param=1.0, cont_loss_param=0.0, train_length = train_dataset.__len__(), val_length = val_dataset.__len__()):\n","  if not os.path.exists(model_path):\n","    os.makedirs(model_path)\n","\n","  min_loss = np.inf\n","  min_mae = np.inf\n","\n","  train_loss = list()\n","  val_loss = list()\n","  train_mae = list()\n","  val_mae = list()\n","\n","  model_context, model_body, model_face, fusion_model = models\n","\n","  for e in range(epochs):\n","    running_loss = 0.0\n","\n","    fusion_model.to(device)\n","    model_context.to(device)\n","    model_body.to(device)\n","    model_face.to(device)\n","\n","    fusion_model.train()\n","    model_context.train()\n","    model_body.train()\n","    model_face.train()\n","\n","    train_cat_preds = np.zeros((train_length, 26))\n","    train_cat_labels = np.zeros((train_length, 26))\n","    indx = 0\n","\n","    for images_context, images_body, images_face, labels_cat, labels_cont in iter(train_loader):\n","      images_context = images_context.to(device)\n","      images_body = images_body.to(device)\n","      images_face = images_face.to(device)\n","      if (isBFER == False):\n","            images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n","      labels_cat = labels_cat.to(device)\n","\n","      opt.zero_grad()\n","\n","      pred_context = model_context(images_context)\n","      pred_body = model_body(images_body)\n","      pred_face = model_face(images_face)\n","\n","      pred_cat = fusion_model(pred_context, pred_body, pred_face)\n","      cat_loss_batch = disc_loss(pred_cat, labels_cat)\n","      loss = (cat_loss_param * cat_loss_batch)\n","      running_loss += loss.item()\n","\n","\n","      loss.backward()\n","      opt.step()\n","\n","      train_cat_preds[ indx : (indx + pred_cat.shape[0]), :] = pred_cat.to(\"cpu\").data.numpy()\n","      train_cat_labels[ indx : (indx + labels_cat.shape[0]), :] = labels_cat.to(\"cpu\").data.numpy()\n","      indx = indx + pred_cat.shape[0]\n","\n","    if e % 1 == 0:\n","      print ('epoch = %d training loss = %.4f' %(e, running_loss))\n","      train_loss.append(running_loss)\n","      train_cat_preds = train_cat_preds.transpose()\n","      train_cat_labels = train_cat_labels.transpose()\n","      train_mae.append(test_scikit_ap(train_cat_preds, train_cat_labels))\n","      print ('epoch = %d training AP = %.4f' %(e, train_mae[-1]))\n","\n","\n","    running_loss = 0.0\n","    fusion_model.eval()\n","    model_context.eval()\n","    model_body.eval()\n","    model_face.eval()\n","\n","    val_cat_preds = np.zeros((val_length, 26))\n","    val_cat_labels = np.zeros((val_length, 26))\n","    indx = 0\n","    with torch.no_grad():\n","      for images_context, images_body, images_face, labels_cat, labels_cont in iter(val_loader):\n","        images_context = images_context.to(device)\n","        images_body = images_body.to(device)\n","        images_face = images_face.to(device)\n","        if (isBFER == False):\n","            images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n","        labels_cat = labels_cat.to(device)\n","\n","        pred_context = model_context(images_context)\n","        pred_body = model_body(images_body)\n","        pred_face = model_face(images_face)\n","\n","        pred_cat = fusion_model(pred_context, pred_body, pred_face)\n","        cat_loss_batch = disc_loss(pred_cat, labels_cat)\n","        loss =  (cat_loss_param * cat_loss_batch)\n","        running_loss += loss.item()\n","\n","        val_cat_preds[ indx : (indx + pred_cat.shape[0]), :] = pred_cat.to(\"cpu\").data.numpy()\n","        val_cat_labels[ indx : (indx + labels_cat.shape[0]), :] = labels_cat.to(\"cpu\").data.numpy()\n","        indx = indx + pred_cat.shape[0]\n","      if e % 1 == 0:\n","        print ('epoch = %d validation loss = %.4f' %(e, running_loss))\n","        val_loss.append(running_loss)\n","        val_cat_preds = val_cat_preds.transpose()\n","        val_cat_labels = val_cat_labels.transpose()\n","        val_mae.append(test_scikit_ap(val_cat_preds, val_cat_labels))\n","        print ('epoch = %d validation AP = %.4f' %(e, val_mae[-1]))\n","\n","    scheduler.step()\n","    print('')\n","    if val_loss[-1] < min_loss:\n","        min_loss = val_loss[-1]\n","        # saving models for lowest loss\n","        print ('saving model at epoch e = %d' %(e))\n","        fusion_model.to(\"cpu\")\n","        model_context.to(\"cpu\")\n","        model_body.to(\"cpu\")\n","        model_face.to(\"cpu\")\n","        torch.save(fusion_model, os.path.join(model_path, 'model_fusion.pth'))\n","        torch.save(model_context, os.path.join(model_path, 'model_context.pth'))\n","        torch.save(model_body, os.path.join(model_path, 'model_body.pth'))\n","        torch.save(model_face, os.path.join(model_path, 'model_face.pth'))\n","\n","  print ('completed training')\n","\n","  #statistic graphic\n","  f, [[ax1, ax2], [ax3, ax4]] = plt.subplots(2, 2, figsize = (15, 10))\n","  f.suptitle('Multi-Branch Network for Imagery Emotion Prediction')\n","  ax1.plot(range(0,len(train_loss)),train_loss, color='Blue')\n","  ax2.plot(range(0,len(val_loss)),val_loss, color='Red')\n","  ax1.legend(['train loss'])\n","  ax2.legend(['val loss'])\n","\n","  ax3.plot(range(0,len(train_mae)),train_mae, color='Blue')\n","  ax4.plot(range(0,len(val_mae)),val_mae, color='Red')\n","  ax3.legend(['train mAP'])\n","  ax4.legend(['val mAP'])\n","\n","print ('completed cell')"],"metadata":{"id":"gwCTxwLmyxcx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697909970405,"user_tz":-420,"elapsed":40,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"4c8374e5-6704-482d-a0ea-da55d3c6fc5a"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"markdown","source":["**Continous Emotion Prediction:**\n"],"metadata":{"id":"_p8lfIk-0unL"}},{"cell_type":"code","source":["def test_cont(models, device, data_loader, num_images):\n","    model_context, model_body, model_face, fusion_model = models\n","    cont_preds = np.zeros((num_images, 3))\n","    cont_labels = np.zeros((num_images, 3))\n","\n","    with torch.no_grad():\n","        model_context.to(device)\n","        model_body.to(device)\n","        model_face.to(device)\n","        fusion_model.to(device)\n","        model_context.eval()\n","        model_body.eval()\n","        model_face.eval()\n","        fusion_model.eval()\n","\n","        indx = 0\n","        print ('starting testing')\n","        for images_context, images_body, images_face, labels_cat, labels_cont in iter(data_loader):\n","            images_context = images_context.to(device)\n","            images_body = images_body.to(device)\n","            images_face = images_face.to(device)\n","            if (isBFER == False):\n","              images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n","\n","\n","            pred_context = model_context(images_context)\n","            pred_body = model_body(images_body)\n","            pred_face = model_face(images_face)\n","            pred_cont = fusion_model(pred_context, pred_body, pred_face)\n","\n","            cont_preds[ indx : (indx + pred_cont.shape[0]), :] = pred_cont.to(\"cpu\").data.numpy() * 10\n","            cont_labels[ indx : (indx + labels_cont.shape[0]), :] = labels_cont.to(\"cpu\").data.numpy() * 10\n","            indx = indx + pred_cont.shape[0]\n","\n","    cont_preds = cont_preds.transpose()\n","    cont_labels = cont_labels.transpose()\n","\n","    print ('completed testing')\n","    vad_mean = test_emotic_vad(cont_preds, cont_labels)\n","    return vad_mean\n","\n","print ('completed cell')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3dzNjDHa8-Is","executionInfo":{"status":"ok","timestamp":1697909970406,"user_tz":-420,"elapsed":34,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"40f925d2-7341-4f23-f8a7-aa5c4da89216"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"code","source":["def train_cont(epochs, model_path, opt, scheduler, models, disc_loss, cont_loss, cat_loss_param=0, cont_loss_param=1.0, train_length = train_dataset.__len__(), val_length = val_dataset.__len__()):\n","  if not os.path.exists(model_path):\n","    os.makedirs(model_path)\n","\n","  min_loss = np.inf\n","\n","  train_loss = list()\n","  val_loss = list()\n","  train_mae = list()\n","  val_mae = list()\n","  model_context, model_body, model_face, fusion_model = models\n","\n","  for e in range(epochs):\n","    running_loss = 0.0\n","\n","    model_context.to(device)\n","    model_body.to(device)\n","    model_face.to(device)\n","    fusion_model.to(device)\n","\n","    model_context.train()\n","    model_body.train()\n","    model_face.train()\n","    fusion_model.train()\n","\n","    train_cont_preds = np.zeros((train_length, 3))\n","    train_cont_labels = np.zeros((train_length, 3))\n","    indx = 0\n","\n","    for images_context, images_body, images_face, labels_cat, labels_cont in iter(train_loader):\n","      images_context = images_context.to(device)\n","      images_body = images_body.to(device)\n","      images_face = images_face.to(device)\n","      if (isBFER == False):\n","            images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n","      labels_cat = labels_cat.to(device)\n","      labels_cont = labels_cont.to(device)\n","\n","      opt.zero_grad()\n","\n","      pred_context = model_context(images_context)\n","      pred_body = model_body(images_body)\n","      pred_face = model_face(images_face)\n","      pred_cont = fusion_model(pred_context, pred_body, pred_face)\n","      cont_loss_batch = cont_loss(pred_cont * 10, labels_cont * 10)\n","      loss = cont_loss_param * cont_loss_batch\n","      running_loss += loss.item()\n","      loss.backward()\n","      opt.step()\n","\n","      train_cont_preds[ indx : (indx + pred_cont.shape[0]), :] = pred_cont.to(\"cpu\").data.numpy() * 10\n","      train_cont_labels[ indx : (indx + labels_cont.shape[0]), :] = labels_cont.to(\"cpu\").data.numpy() * 10\n","      indx = indx + pred_cont.shape[0]\n","\n","    if e % 1 == 0:\n","      print ('epoch = %d training loss = %.4f' %(e, running_loss))\n","    train_loss.append(running_loss)\n","    train_cont_preds = train_cont_preds.transpose()\n","    train_cont_labels = train_cont_labels.transpose()\n","    train_mae.append(test_emotic_vad(train_cont_preds, train_cont_labels))\n","    print ('epoch = %d training MAE = %.4f' %(e, train_mae[-1]))\n","\n","    running_loss = 0.0\n","    model_context.eval()\n","    model_body.eval()\n","    model_face.eval()\n","    fusion_model.eval()\n","\n","    val_cont_preds = np.zeros((val_length, 3))\n","    val_cont_labels = np.zeros((val_length, 3))\n","    indx = 0\n","\n","    with torch.no_grad():\n","      for images_context, images_body, images_face, labels_cat, labels_cont in iter(val_loader):\n","        images_context = images_context.to(device)\n","        images_body = images_body.to(device)\n","        images_face = images_face.to(device)\n","        if (isBFER == False):\n","            images_face = torch.mean(images_face, dim=1, keepdim=True).to(device)\n","        labels_cat = labels_cat.to(device)\n","        labels_cont = labels_cont.to(device)\n","\n","        pred_context = model_context(images_context)\n","        pred_body = model_body(images_body)\n","        pred_face = model_face(images_face)\n","        pred_cont = fusion_model(pred_context, pred_body, pred_face)\n","        cont_loss_batch = cont_loss(pred_cont * 10, labels_cont * 10)\n","        loss = cont_loss_param * cont_loss_batch\n","        running_loss += loss.item()\n","\n","        val_cont_preds[ indx : (indx + pred_cont.shape[0]), :] = pred_cont.to(\"cpu\").data.numpy() * 10\n","        val_cont_labels[ indx : (indx + labels_cont.shape[0]), :] = labels_cont.to(\"cpu\").data.numpy() * 10\n","        indx = indx + pred_cont.shape[0]\n","      if e % 1 == 0:\n","        print ('epoch = %d validation loss = %.4f' %(e, running_loss))\n","    val_loss.append(running_loss)\n","    val_cont_preds = val_cont_preds.transpose()\n","    val_cont_labels = val_cont_labels.transpose()\n","    val_mae.append(test_emotic_vad(val_cont_preds, val_cont_labels))\n","    print ('epoch = %d val MAE= %.4f' %(e, val_mae[-1]))\n","    scheduler.step()\n","\n","    if val_loss[-1] < min_loss:\n","        min_loss = val_loss[-1]\n","        # saving models for lowest loss\n","        print ('saving model at epoch e = %d' %(e))\n","        fusion_model.to(\"cpu\")\n","        model_context.to(\"cpu\")\n","        model_body.to(\"cpu\")\n","        model_face.to(\"cpu\")\n","        torch.save(fusion_model, os.path.join(model_path, 'model_fusion.pth'))\n","        torch.save(model_context, os.path.join(model_path, 'model_context.pth'))\n","        torch.save(model_body, os.path.join(model_path, 'model_body.pth'))\n","        torch.save(model_face, os.path.join(model_path, 'model_face.pth'))\n","\n","  print ('completed training')\n","\n","  #statistic graphic\n","  f, [[ax1, ax2], [ax3, ax4]] = plt.subplots(2, 2, figsize = (15, 10))\n","  f.suptitle('Multi-Branch Network for Imagery Emotion Prediction')\n","  ax1.plot(range(0,len(train_loss)),train_loss, color='Blue')\n","  ax2.plot(range(0,len(val_loss)),val_loss, color='Red')\n","  ax1.legend(['train loss'])\n","  ax2.legend(['val loss'])\n","\n","  ax3.plot(range(0,len(train_mae)),train_mae, color='Blue')\n","  ax4.plot(range(0,len(val_mae)),val_mae, color='Red')\n","  ax3.legend(['train MAE'])\n","  ax4.legend(['val MAE'])\n","\n","print ('completed cell')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kIZgHaT99AYZ","executionInfo":{"status":"ok","timestamp":1697909970406,"user_tz":-420,"elapsed":26,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"90f8a11e-4131-412f-b5ac-bb828b2dc47d"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"markdown","source":["# VIII. Trainning:\n"],"metadata":{"id":"koEJMH3G9DUx"}},{"cell_type":"code","source":["def trainning(epochs, model_path, opt, scheduler, models, disc_loss, cont_loss, cat_loss_param=1.0, cont_loss_param=0.0, train_length = train_dataset.__len__(), val_length = val_dataset.__len__()):\n","  if (isVADPrediction):\n","      train_cont(epochs, model_path, opt, scheduler, models, disc_loss, cont_loss, cat_loss_param=1.0, cont_loss_param=0.0, train_length = train_dataset.__len__(), val_length = val_dataset.__len__())\n","  else:\n","      train_disc(epochs, model_path, opt, scheduler, models, disc_loss, cont_loss, cat_loss_param=1.0, cont_loss_param=0.0, train_length = train_dataset.__len__(), val_length = val_dataset.__len__())"],"metadata":{"id":"xyDR6MZ-2TZv","executionInfo":{"status":"ok","timestamp":1697910927003,"user_tz":-420,"elapsed":3,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["#define number of epochs and path to store model after trainning - (recommend at least 15 epochs for regression)\n","epochs = 1\n","path_to_store_model = \"./models\""],"metadata":{"id":"HS_iI47FxcsS","executionInfo":{"status":"ok","timestamp":1697910928153,"user_tz":-420,"elapsed":4,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}}},"execution_count":134,"outputs":[]},{"cell_type":"code","source":["#trainning\n","trainning(epochs, path_to_store_model, opt, scheduler, [model_context, model_body, model_face, fusion_model], disc_loss=disc_loss, cont_loss=cont_loss_L2, cat_loss_param=1.0, cont_loss_param=1.0)"],"metadata":{"id":"Z2PZOlxt9G0J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# IX. Testing:"],"metadata":{"id":"VXcSmlCq9Pof"}},{"cell_type":"code","source":["# Load trained model for testing\n","model_path = path_to_store_model\n","model_context = torch.load(os.path.join(model_path, 'model_context.pth'))\n","model_body = torch.load(os.path.join(model_path, 'model_body.pth'))\n","model_face = torch.load(os.path.join(model_path, 'model_face.pth'))\n","fusion_model = torch.load(os.path.join(model_path, 'model_fusion.pth'))\n","\n","model_context.eval()\n","model_body.eval()\n","model_face.eval()\n","fusion_model.eval()\n","\n","print ('completed cell')"],"metadata":{"id":"sEkcC74z9LYA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910791933,"user_tz":-420,"elapsed":1979,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"91a800f0-9ed0-4e4d-85b7-232ebea01b01"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["completed cell\n"]}]},{"cell_type":"code","source":["#testing\n","if (isVADPrediction):\n","    test_mae = test_cont([model_context, model_body, model_face, fusion_model], device, test_loader, test_dataset.__len__())\n","    print ('testing MAE=%.4f' %(test_mae))\n","else:\n","    test_map = test_disc([model_context, model_body, model_face, fusion_model], device, test_loader, test_dataset.__len__())\n","    print ('testing mAP=%.4f' %(test_map))"],"metadata":{"id":"olEVAyE39T2Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697910645928,"user_tz":-420,"elapsed":93435,"user":{"displayName":"21_0004 Ninh Quốc Bảo","userId":"15510183796249817637"}},"outputId":"7e923a4f-08d7-4c2f-a3b8-3a757dc86871"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["starting testing\n","completed testing\n","ap [0.2920199  0.11064112 0.14707923 0.5522721  0.0583308  0.73740953\n"," 0.1299824  0.24145244 0.17172313 0.1765055  0.02029791 0.8611955\n"," 0.1432784  0.6885479  0.0925881  0.0419534  0.70323604 0.05236943\n"," 0.22835895 0.4108984  0.15388381 0.0500508  0.17935905 0.07206114\n"," 0.1101446  0.07119898] (26,) 0.2498784\n","testing mAP=0.2499\n"]}]}]}